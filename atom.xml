<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>木子</title>
  <icon>https://blog.k8s.li/icon.png</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.k8s.li/"/>
  <updated>2021-04-16T16:00:00.000Z</updated>
  <id>https://blog.k8s.li/</id>
  
  <author>
    <name>木子</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何使用 registry 存储的特性</title>
    <link href="https://blog.k8s.li/skopeo-to-registry.html"/>
    <id>https://blog.k8s.li/skopeo-to-registry.html</id>
    <published>2021-04-16T16:00:00.000Z</published>
    <updated>2021-04-16T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="苦命打包工具人😭"><a href="#苦命打包工具人😭" class="headerlink" title="苦命打包工具人😭"></a>苦命打包工具人😭</h2><p>目前在负责公司 PaaS toB 产品的打包发布工作（苦命发版+打包工具人😣）。日常的一项工作就是跑完自动化打包流水线，再将打出来的安装包更新到 QA 测试环境中。因为打包环境和测试环境分布在两个不同的机房，产品的安装包需要跨公网从打包机器上同步到 QA 环境中，因此产品安装包的大小就决定着两者间同步的耗时。优化和减少产品安装包的大小就成为了提升流水线效率的途径之一。最近做的一项工作就是将产品补丁包的大小减少 30%～60%，大大节省了补丁包上传下载和安装的耗时，提升了产品打包流水线的效率。因此今天就总结一下从中学到的一点人生经验 👓。</p><h2 id="再次优化"><a href="#再次优化" class="headerlink" title="再次优化"></a>再次优化</h2><p>因为产品所有的组件都是容器化的形式部署的，所以产品的补丁包中最主要的就是镜像文件以及一些部署脚本，想要优化和见减小补丁包基本上等同于减小这些镜像的大小。众所周知 docker 镜像是由一层一层的 layer + 镜像的元数据信息构成的，其中镜像的元数据信息就是镜像的 image config + manifests，这些都是 json 格式的文本内容，相对于镜像的 layer 的大小，这些文本内容往往可以忽略不计。</p><p>其实去年的时候已经做过了一次优化，将补丁包镜像打包的方式由原来的 docker save 的方式替换成了 skopeo copy 到目录的方式，优化的效果就是：将补丁包的大小减少了 60%～80%；流水线的速度提升了 5 倍；补丁包安装速度也提升了 5 倍。这项优化的原理可以参考我之前的博客 <a href="https://blog.k8s.li/Exploring-container-image.html">深入浅出容器镜像的一生</a>。虽然第一次已经有了这么明显的优化，但咱仍然觉得还有可以优化的空间。</p><p>经过第一次优化之后，产品补丁包中镜像存在的形式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root/kube <span class="comment"># tree images -h</span></span><br><span class="line">images</span><br><span class="line">├── [4.0K]  kube-apiserver:v1.20.5</span><br><span class="line">│   ├── [707K]  742efefc8a44179dcc376b969cb5e3f8afff66f87ab618a15164638ad07bf722</span><br><span class="line">│   ├── [ 28M]  98d681774b176bb2fd6b3499377d63ff4b1b040886dd9d3641bb93840815a1e7</span><br><span class="line">│   ├── [2.6K]  d7e24aeb3b10210bf6a2dc39f77c1ea835b22af06dfd2933c06e0421ed6d35ac</span><br><span class="line">│   ├── [642K]  fefd475334af8255ba693de12951b5176a2853c2f0d5d2b053e188a1f3b611d9</span><br><span class="line">│   ├── [ 949]  manifest.json</span><br><span class="line">│   └── [  33]  version</span><br><span class="line">├── [4.0K]  kube-controller-manager:v1.20.5</span><br><span class="line">│   ├── [ 27M]  454a7944c47b608efb657a1bef7f4093f63ceb2db14fd78c5ecd2a08333da7cf</span><br><span class="line">│   ├── [2.6K]  6f0c3da8c99e99bbe82920a35653f286bd8130f0662884e77fa9fcdca079c07f</span><br><span class="line">│   ├── [707K]  742efefc8a44179dcc376b969cb5e3f8afff66f87ab618a15164638ad07bf722</span><br><span class="line">│   ├── [642K]  fefd475334af8255ba693de12951b5176a2853c2f0d5d2b053e188a1f3b611d9</span><br><span class="line">│   ├── [ 949]  manifest.json</span><br><span class="line">│   └── [  33]  version</span><br><span class="line">└── [4.0K]  kube-scheduler:v1.20.5</span><br><span class="line">    ├── [ 12M]  565677e452d17c4e2841250bbf0cc010d906fbf7877569bb2d69bfb4e68db1b5</span><br><span class="line">    ├── [707K]  742efefc8a44179dcc376b969cb5e3f8afff66f87ab618a15164638ad07bf722</span><br><span class="line">    ├── [2.6K]  8d13f1db8bfb498afb0caff6bf3f8c599ecc2ace74275f69886067f6af8ffdf6</span><br><span class="line">    ├── [642K]  fefd475334af8255ba693de12951b5176a2853c2f0d5d2b053e188a1f3b611d9</span><br><span class="line">    ├── [ 949]  manifest.json</span><br><span class="line">    └── [  33]  version</span><br></pre></td></tr></table></figure><p>仔细分析可以发现这样打包出来的镜像要比它们在 registry 中的所占存储空间要大一些，这是因为每一个镜像存储目录下都保存在该镜像的所有 layer ，不能像 registry 存储那样可以复用相同的 layer。比如 <code>kube-apiserver</code>  <code>kube-controller-manager</code> <code>kube-scheduler</code> 这三个镜像都是使用的 <code>k8s.gcr.io/build-image/go-runner</code> 这个 base 镜像。在 registry 中，它只需要存储一份 <code>go-runner</code> base 镜像即可。而使用 skopeo copy 存储在目录中时，就需要分别存储一份这个 base 镜像了。</p><p>从文件名和文件大小也可以大致推断出 <code>707K</code> 大小的 742efefc8a 就是 <code>go-runner</code> 镜像的跟文件系统；<code>642K</code> 大小的 fefd47533 就是 go-runner 的二进制文件；<code>2.x</code> 左右大小的应该就是镜像的 image config 文件；剩下那个十几二十几 M 的就是  <code>kube-apiserver</code>  <code>kube-controller-manager</code> <code>kube-scheduler</code>  的二进制文件；manifest.json 文件就是镜像在 registry 存储中的 manifest 。</p><ul><li>使用 find 来统计这些文件的数量，经过去重之后可以发现镜像的 layer 文件和 config 文件总数量从原来的 12 个减少到 8 个。做一个简单的加法计算也就是：3 个 image config 文件 + 3 个二进制文件 + 1 个 base 镜像 layer 文件 + 1 个 go-runner 二进制文件，这不正好就是 8 嘛😂</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root/kube <span class="comment"># find images -type f | grep -Eo "\b[a-f0-9]&#123;64&#125;\b" | wc</span></span><br><span class="line">12</span><br><span class="line">root@debian:/root/kube <span class="comment"># find images -type f | grep -Eo "\b[a-f0-9]&#123;64&#125;\b" | sort -u | wc -l</span></span><br><span class="line">8</span><br></pre></td></tr></table></figure><p>既然补丁包中的镜像文件有一些相同的 layer，那么去重这些相同的 layer 文件岂不就能减少补丁包的大小了？于是就拿了一个历史的补丁包测试一下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root $ du -sh images</span><br><span class="line">3.3Gimages</span><br><span class="line">root@debian:/root $ find images -<span class="built_in">type</span> f ! -name <span class="string">'version'</span> ! -name <span class="string">'manifest.json'</span> | wc -l</span><br><span class="line">279</span><br><span class="line">root@debian:/root $ mkdir -p images2</span><br><span class="line">root@debian:/root $ find images -<span class="built_in">type</span> f -<span class="built_in">exec</span> mv &#123;&#125; images2 \;</span><br><span class="line">root@debian:/root $ du -sh images2</span><br><span class="line">1.3Gimages2</span><br><span class="line">root@debian:/root $ $ find images2 -<span class="built_in">type</span> f ! -name <span class="string">'version'</span> ! -name <span class="string">'manifest.json'</span> | wc -l</span><br><span class="line">187</span><br></pre></td></tr></table></figure><p>没有对比就没有伤害，经过测试之后发现：补丁包中镜像文件的总数量由原来的 279 个减小至 187 个，总大小从原来的 3.3G 减小到 1.3G，减小了 60%！当时兴奋得我拍案叫绝，如获珍宝。其实这得益于我们产品组件使用的 base 镜像基本上是相同的，因此可以去除掉很多相同的 base 镜像 layer 文件。</p><p>既然找到了减小补丁包中镜像大小的思路，那么只要找到一种方式来去重这些镜像 layer 就可以了。首先想到的就是使用 registry 存储：根据 registry 存储的特性，镜像在 registry 中是可以复用相同的 layer 的。所以大体的思路就是将这些补丁包中的镜像转换为 registry 存储的格式，在安装的时候再将 registry 存储的格式转换为 skopeo copy 支持的 dir 格式。</p><h2 id="构建-skopeo-dir-镜像存储"><a href="#构建-skopeo-dir-镜像存储" class="headerlink" title="构建 skopeo dir 镜像存储"></a>构建 skopeo dir 镜像存储</h2><ul><li>为了方便演示，需要找个合适的镜像列表，看了一下 <a href="https://github.com/kubesphere/ks-installer" target="_blank" rel="noopener">ks-installer</a> 项目中有个镜像列表，看样子比较合适那就用它吧😃</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root <span class="comment"># curl -L -O https://github.com/kubesphere/ks-installer/releases/download/v3.0.0/images-list.txt</span></span><br></pre></td></tr></table></figure><ul><li>首先将镜像使用 skopeo sync 同步到本地目录，并统计一下镜像的大小和文件的数量</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root <span class="comment"># for img in $(cat cat images-list.txt | grep -v "#");do skopeo sync --insecure-policy --src docker --dest dir $&#123;img&#125; images; done</span></span><br><span class="line"></span><br><span class="line">root@debian:/root <span class="comment"># tree images -d -L 1</span></span><br><span class="line">images</span><br><span class="line">├── alpine:3.10.4</span><br><span class="line">├── busybox:1.31.1</span><br><span class="line">├── calico</span><br><span class="line">├── coredns</span><br><span class="line">├── csiplugin</span><br><span class="line">├── docker:19.03</span><br><span class="line">├── elastic</span><br><span class="line">├── fluent</span><br><span class="line">├── haproxy:2.0.4</span><br><span class="line">├── istio</span><br><span class="line">├── jaegertracing</span><br><span class="line">├── java:openjdk-8-jre-alpine</span><br><span class="line">├── jenkins</span><br><span class="line">├── jimmidyson</span><br><span class="line">├── joosthofman</span><br><span class="line">├── kubesphere</span><br><span class="line">├── minio</span><br><span class="line">├── mirrorgooglecontainers</span><br><span class="line">├── mysql:8.0.11</span><br><span class="line">├── nginx:1.14-alpine</span><br><span class="line">├── nginxdemos</span><br><span class="line">├── openpitrix</span><br><span class="line">├── osixia</span><br><span class="line">├── perl:latest</span><br><span class="line">├── prom</span><br><span class="line">├── redis:5.0.5-alpine</span><br><span class="line">└── wordpress:4.8-apache</span><br></pre></td></tr></table></figure><ul><li>使用 skopeo sync 将镜像同步到本地 images 目录后，统计可得所有镜像的大小为 11G、总的文件为 1264 个。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root <span class="comment"># du -sh images</span></span><br><span class="line">11Gimages</span><br><span class="line">root@debian:/root <span class="comment"># find images -type f ! -name "version" | wc -l</span></span><br><span class="line">1264</span><br></pre></td></tr></table></figure><h2 id="转换成-registry-存储目录"><a href="#转换成-registry-存储目录" class="headerlink" title="转换成 registry 存储目录"></a>转换成 registry 存储目录</h2><p>根据下图所示的 registry 存储结构，我们要将镜像的 layer、image config、manifests 这三种文件根据它们的 sha256 值存放到 blobs/sha256 目录下，然后再在 repositories 目录下创建相应link 文件，这样就可以将镜像转换成 registry 存储的格式了。</p><p><img src="https://p.k8s.li/registry-storage.jpeg" alt=""></p><p>为方便演示我们先以单个镜像为例，将 <code>images/alpine:3.10.4</code> 这个镜像在转换成 docker registry 存储目录的形式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root <span class="comment"># tree -h images/alpine:3.10.4</span></span><br><span class="line">images/alpine:3.10.4</span><br><span class="line">└── [4.0K]  alpine:3.10.4</span><br><span class="line">    ├── [2.7M]  4167d3e149762ea326c26fc2fd4e36fdeb7d4e639408ad30f37b8f25ac285a98</span><br><span class="line">    ├── [1.5K]  af341ccd2df8b0e2d67cf8dd32e087bfda4e5756ebd1c76bbf3efa0dc246590e</span><br><span class="line">    ├── [ 528]  manifest.json</span><br><span class="line">    └── [  33]  version</span><br></pre></td></tr></table></figure><p> 根据镜像文件大小我们可以得知： <code>2.7M</code> 大小的 <code>4167d3e1497……</code> 文件就是镜像的 layer 文件，由于 alpine 是一个 base 镜像，该 layer 就是 alpine 的根文件系统；<code>1.5K</code> 大小的 <code>af341ccd2……</code> 显而易见就是镜像的 images config 文件；<code>manifest.json</code> 文件则是镜像在 registry 存储中的 manifest.json 文件。</p><ul><li>先创建该镜像在 registry 存储中的目录结构</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root <span class="comment"># mkdir -p docker/registry/v2/&#123;blobs/sha256,repositories/alpine&#125;</span></span><br><span class="line">root@debian:/root <span class="comment"># tree docker</span></span><br><span class="line">docker</span><br><span class="line">└── registry</span><br><span class="line">    └── v2</span><br><span class="line">        ├── blobs</span><br><span class="line">        │   └── sha256</span><br><span class="line">        └── repositories</span><br><span class="line">            └── alpine</span><br></pre></td></tr></table></figure><ul><li>构建镜像 layer 的 link 文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grep -Eo <span class="string">"\b[a-f0-9]&#123;64&#125;\b"</span> images/alpine:3.10.4/manifest.json | sort -u | xargs -L1 -I &#123;&#125; mkdir -p docker/registry/v2/repositories/alpine/_layers/sha256/&#123;&#125;</span><br><span class="line"></span><br><span class="line">grep -Eo <span class="string">"\b[a-f0-9]&#123;64&#125;\b"</span> images/alpine:3.10.4/manifest.json | sort -u | xargs -L1 -I &#123;&#125; sh -c <span class="string">"echo -n 'sha256:&#123;&#125;' &gt; docker/registry/v2/repositories/alpine/_layers/sha256/&#123;&#125;/link"</span></span><br></pre></td></tr></table></figure><ul><li>构建镜像 tag 的 link 文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">manifests_sha256=$(sha256sum images/alpine:3.10.4/manifest.json | awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line">mkdir -p docker/registry/v2/repositories/alpine/_manifests/revisions/sha256/<span class="variable">$&#123;manifests_sha256&#125;</span></span><br><span class="line"><span class="built_in">echo</span> -n <span class="string">"sha256:<span class="variable">$&#123;manifests_sha256&#125;</span>"</span> &gt; docker/registry/v2/repositories/alpine/_manifests/revisions/sha256/<span class="variable">$&#123;manifests_sha256&#125;</span>/link</span><br><span class="line"></span><br><span class="line">mkdir -p docker/registry/v2/repositories/alpine/_manifests/tags/3.10.4/index/sha256/<span class="variable">$&#123;manifests_sha256&#125;</span></span><br><span class="line"><span class="built_in">echo</span> -n <span class="string">"sha256:<span class="variable">$&#123;manifests_sha256&#125;</span>"</span> &gt; docker/registry/v2/repositories/alpine/_manifests/tags/3.10.4/index/sha256/<span class="variable">$&#123;manifests_sha256&#125;</span>/link</span><br><span class="line"></span><br><span class="line">mkdir -p docker/registry/v2/repositories/alpine/_manifests/tags/3.10.4/current</span><br><span class="line"><span class="built_in">echo</span> -n <span class="string">"sha256:<span class="variable">$&#123;manifests_sha256&#125;</span>"</span> &gt; docker/registry/v2/repositories/alpine/_manifests/tags/3.10.4/current/link</span><br></pre></td></tr></table></figure><ul><li>构建镜像的 blobs 目录</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p docker/registry/v2/blobs/sha256/<span class="variable">$&#123;manifests_sha256:0:2&#125;</span>/<span class="variable">$&#123;manifests_sha256&#125;</span></span><br><span class="line">ln -f images/alpine:3.10.4/manifest.json docker/registry/v2/blobs/sha256/<span class="variable">$&#123;manifests_sha256:0:2&#125;</span>/<span class="variable">$&#123;manifests_sha256&#125;</span>/data</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> $(grep -Eo <span class="string">"\b[a-f0-9]&#123;64&#125;\b"</span> images/alpine:3.10.4/manifest.json); <span class="keyword">do</span></span><br><span class="line">    mkdir -p docker/registry/v2/blobs/sha256/<span class="variable">$&#123;layer:0:2&#125;</span>/<span class="variable">$&#123;layer&#125;</span></span><br><span class="line">    ln -f  images/alpine:3.10.4/<span class="variable">$&#123;layer&#125;</span> docker/registry/v2/blobs/sha256/<span class="variable">$&#123;layer:0:2&#125;</span>/<span class="variable">$&#123;layer&#125;</span>/data</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><ul><li>最终得到的 registry 存储目录如下</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">docker</span><br><span class="line">└── registry</span><br><span class="line">    └── v2</span><br><span class="line">        ├── blobs</span><br><span class="line">        │   └── sha256</span><br><span class="line">        │       ├── 41</span><br><span class="line">        │       │   └── 4167d3e149762ea326c26fc2fd4e36fdeb7d4e639408ad30f37b8f25ac285a98</span><br><span class="line">        │       │       └── data</span><br><span class="line">        │       ├── af</span><br><span class="line">        │       │   └── af341ccd2df8b0e2d67cf8dd32e087bfda4e5756ebd1c76bbf3efa0dc246590e</span><br><span class="line">        │       │       └── data</span><br><span class="line">        │       └── de</span><br><span class="line">        │           └── de78803598bc4c940fc4591d412bffe488205d5d953f94751c6308deeaaa7eb8</span><br><span class="line">        │               └── data</span><br><span class="line">        └── repositories</span><br><span class="line">            └── alpine</span><br><span class="line">                ├── _layers</span><br><span class="line">                │   └── sha256</span><br><span class="line">                │       ├── 4167d3e149762ea326c26fc2fd4e36fdeb7d4e639408ad30f37b8f25ac285a98</span><br><span class="line">                │       │   └── link</span><br><span class="line">                │       └── af341ccd2df8b0e2d67cf8dd32e087bfda4e5756ebd1c76bbf3efa0dc246590e</span><br><span class="line">                │           └── link</span><br><span class="line">                └── _manifests</span><br><span class="line">                    ├── revisions</span><br><span class="line">                    │   └── sha256</span><br><span class="line">                    │       └── de78803598bc4c940fc4591d412bffe488205d5d953f94751c6308deeaaa7eb8</span><br><span class="line">                    │           └── link</span><br><span class="line">                    └── tags</span><br><span class="line">                        └── 3.10.4</span><br><span class="line">                            ├── current</span><br><span class="line">                            │   └── link</span><br><span class="line">                            └── index</span><br><span class="line">                                └── sha256</span><br><span class="line">                                    └── de78803598bc4c940fc4591d412bffe488205d5d953f94751c6308deeaaa7eb8</span><br><span class="line">                                        └── link</span><br></pre></td></tr></table></figure><ul><li>测试是否正常，本地 docker run 一个 registry 容器，将刚刚转换的 registry 存储目录挂载到容器的 /var/lib/registry，然后再使用 docker pull 的方式拉取镜像，在使用 docker run 测试一下能否正常使用。经过验证之后确实可以使用，那就说明这样的转换是没有问题的😊。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root <span class="comment"># docker pull localhost/alpine:3.10.4</span></span><br><span class="line">3.10.4: Pulling from alpine</span><br><span class="line">4167d3e14976: Pull complete</span><br><span class="line">Digest: sha256:de78803598bc4c940fc4591d412bffe488205d5d953f94751c6308deeaaa7eb8</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> localhost/alpine:3.10.4</span><br><span class="line">root@debian:/root <span class="comment"># docker run --rm -it localhost/alpine:3.10.4 cat /etc/os-release</span></span><br><span class="line">NAME=<span class="string">"Alpine Linux"</span></span><br><span class="line">ID=alpine</span><br><span class="line">VERSION_ID=3.10.4</span><br><span class="line">PRETTY_NAME=<span class="string">"Alpine Linux v3.10"</span></span><br><span class="line">HOME_URL=<span class="string">"https://alpinelinux.org/"</span></span><br><span class="line">BUG_REPORT_URL=<span class="string">"https://bugs.alpinelinux.org/"</span></span><br></pre></td></tr></table></figure><ul><li>将上述步骤整合成一个 shell 脚本，内容如下</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">set</span> -eo pipefail</span><br><span class="line"></span><br><span class="line">IMAGES_DIR=<span class="string">"images"</span></span><br><span class="line">REGISTRY_DIR=<span class="string">"docker"</span></span><br><span class="line"></span><br><span class="line">rm -rf <span class="variable">$&#123;REGISTRY_DIR&#125;</span></span><br><span class="line">BLOBS_PATH=<span class="string">"<span class="variable">$&#123;REGISTRY_DIR&#125;</span>/registry/v2/blobs"</span></span><br><span class="line">REPO_PATH=<span class="string">"<span class="variable">$&#123;REGISTRY_DIR&#125;</span>/registry/v2/repositories"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image <span class="keyword">in</span> $(find <span class="variable">$&#123;IMAGES_DIR&#125;</span> -<span class="built_in">type</span> f | sed -n <span class="string">'s|/manifest.json||p'</span> | sort -u); <span class="keyword">do</span></span><br><span class="line">    image_name=$(<span class="built_in">echo</span> <span class="variable">$&#123;image%%:*&#125;</span> | sed <span class="string">"s|<span class="variable">$&#123;IMAGES_DIR&#125;</span>/||g"</span>)</span><br><span class="line">    image_tag=<span class="variable">$&#123;image##*:&#125;</span>; mfs=<span class="string">"<span class="variable">$&#123;image&#125;</span>/manifest.json"</span></span><br><span class="line">    mfs_sha256=$(sha256sum <span class="variable">$&#123;image&#125;</span>/manifest.json | awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line">    mkdir -p <span class="variable">$&#123;BLOBS_PATH&#125;</span>/sha256/<span class="variable">$&#123;mfs_sha256:0:2&#125;</span>/<span class="variable">$&#123;mfs_sha256&#125;</span></span><br><span class="line">    ln -f <span class="variable">$&#123;mfs&#125;</span> <span class="variable">$&#123;BLOBS_PATH&#125;</span>/sha256/<span class="variable">$&#123;mfs_sha256:0:2&#125;</span>/<span class="variable">$&#123;mfs_sha256&#125;</span>/data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># make image repositories dir</span></span><br><span class="line">    mkdir -p <span class="variable">$&#123;REPO_PATH&#125;</span>/<span class="variable">$&#123;image_name&#125;</span>/&#123;_layers,_manifests/revisions&#125;/sha256</span><br><span class="line">    mkdir -p <span class="variable">$&#123;REPO_PATH&#125;</span>/<span class="variable">$&#123;image_name&#125;</span>/_manifests/revisions/sha256/<span class="variable">$&#123;mfs_sha256&#125;</span></span><br><span class="line">    mkdir -p <span class="variable">$&#123;REPO_PATH&#125;</span>/<span class="variable">$&#123;image_name&#125;</span>/_manifests/tags/<span class="variable">$&#123;image_tag&#125;</span>/&#123;current,index/sha256&#125;</span><br><span class="line">    mkdir -p <span class="variable">$&#123;REPO_PATH&#125;</span>/<span class="variable">$&#123;image_name&#125;</span>/_manifests/tags/<span class="variable">$&#123;image_tag&#125;</span>/index/sha256/<span class="variable">$&#123;mfs_sha256&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># create image tag manifest link file</span></span><br><span class="line">    <span class="built_in">echo</span> -n <span class="string">"sha256:<span class="variable">$&#123;mfs_sha256&#125;</span>"</span> &gt; <span class="variable">$&#123;REPO_PATH&#125;</span>/<span class="variable">$&#123;image_name&#125;</span>/_manifests/tags/<span class="variable">$&#123;image_tag&#125;</span>/current/link</span><br><span class="line">    <span class="built_in">echo</span> -n <span class="string">"sha256:<span class="variable">$&#123;mfs_sha256&#125;</span>"</span> &gt; <span class="variable">$&#123;REPO_PATH&#125;</span>/<span class="variable">$&#123;image_name&#125;</span>/_manifests/revisions/sha256/<span class="variable">$&#123;mfs_sha256&#125;</span>/link</span><br><span class="line">    <span class="built_in">echo</span> -n <span class="string">"sha256:<span class="variable">$&#123;mfs_sha256&#125;</span>"</span> &gt; <span class="variable">$&#123;REPO_PATH&#125;</span>/<span class="variable">$&#123;image_name&#125;</span>/_manifests/tags/<span class="variable">$&#123;image_tag&#125;</span>/index/sha256/<span class="variable">$&#123;mfs_sha256&#125;</span>/link</span><br><span class="line"></span><br><span class="line">    <span class="comment"># link image layers file to registry blobs file</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> $(grep -Eo <span class="string">"\b[a-f0-9]&#123;64&#125;\b"</span> <span class="variable">$&#123;mfs&#125;</span>); <span class="keyword">do</span></span><br><span class="line">        mkdir -p <span class="variable">$&#123;BLOBS_PATH&#125;</span>/sha256/<span class="variable">$&#123;layer:0:2&#125;</span>/<span class="variable">$&#123;layer&#125;</span></span><br><span class="line">        mkdir -p <span class="variable">$&#123;REPO_PATH&#125;</span>/<span class="variable">$&#123;image_name&#125;</span>/_layers/sha256/<span class="variable">$&#123;layer&#125;</span></span><br><span class="line">        <span class="built_in">echo</span> -n <span class="string">"sha256:<span class="variable">$&#123;layer&#125;</span>"</span> &gt; <span class="variable">$&#123;REPO_PATH&#125;</span>/<span class="variable">$&#123;image_name&#125;</span>/_layers/sha256/<span class="variable">$&#123;layer&#125;</span>/link</span><br><span class="line">        ln -f <span class="variable">$&#123;image&#125;</span>/<span class="variable">$&#123;layer&#125;</span> <span class="variable">$&#123;BLOBS_PATH&#125;</span>/sha256/<span class="variable">$&#123;layer:0:2&#125;</span>/<span class="variable">$&#123;layer&#125;</span>/data</span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><ul><li>使用该脚本对 images 中所有镜像进行一下转换，最终得到的 registry 存储大小为 8.3 G，比之前减少了 2.7G。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@debian:/root <span class="comment"># du -sh docker</span></span><br><span class="line">8.3Gdocker</span><br><span class="line">root@debian:/root <span class="comment"># find docker -type f -name "data" | wc -l</span></span><br><span class="line">1046</span><br></pre></td></tr></table></figure><h2 id="再还原回-Dir-格式"><a href="#再还原回-Dir-格式" class="headerlink" title="再还原回 Dir 格式"></a>再还原回 Dir 格式</h2><p>经过上述步骤一番折腾之后，将补丁包中镜像文件的总大小的确实减少了很多，但同时又引入了另一个问题：skopeo 无法直接使用 registry 存储的格式。因此我们还需要再做一次转换，将镜像由 registry 存储的格式还原回 skopeo 所支持的 dir 格式。至于还原的原理和方法我在 <a href="https://blog.k8s.li/docker-registry-to-harbor.html">docker registry 迁移至 harbor</a> 中有详细地介绍，感兴趣的小伙伴可以再去看一下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">REGISTRY_DOMAIN=<span class="string">"harbor.k8s.li"</span></span><br><span class="line">REGISTRY_PATH=<span class="string">"/var/lib/registry"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到 registry 存储主目录下</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;REGISTRY_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">gen_skopeo_dir</span></span>() &#123;</span><br><span class="line">   <span class="comment"># 定义 registry 存储的 blob 目录 和 repositories 目录，方便后面使用</span></span><br><span class="line">    BLOB_DIR=<span class="string">"docker/registry/v2/blobs/sha256"</span></span><br><span class="line">    REPO_DIR=<span class="string">"docker/registry/v2/repositories"</span></span><br><span class="line">    <span class="comment"># 定义生成 skopeo 目录</span></span><br><span class="line">    SKOPEO_DIR=<span class="string">"docker/skopeo"</span></span><br><span class="line">    <span class="comment"># 通过 find 出 current 文件夹可以得到所有带 tag 的镜像，因为一个 tag 对应一个 current 目录</span></span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> $(find <span class="variable">$&#123;REPO_DIR&#125;</span> -<span class="built_in">type</span> d -name <span class="string">"current"</span>); <span class="keyword">do</span></span><br><span class="line">        <span class="comment"># 根据镜像的 tag 提取镜像的名字</span></span><br><span class="line">        name=$(<span class="built_in">echo</span> <span class="variable">$&#123;image&#125;</span> | awk -F <span class="string">'/'</span> <span class="string">'&#123;print $5"/"$6":"$9&#125;'</span>)</span><br><span class="line">        link=$(cat <span class="variable">$&#123;image&#125;</span>/link | sed <span class="string">'s/sha256://'</span>)</span><br><span class="line">        mfs=<span class="string">"<span class="variable">$&#123;BLOB_DIR&#125;</span>/<span class="variable">$&#123;link:0:2&#125;</span>/<span class="variable">$&#123;link&#125;</span>/data"</span></span><br><span class="line">        <span class="comment"># 创建镜像的硬链接需要的目录</span></span><br><span class="line">        mkdir -p <span class="string">"<span class="variable">$&#123;SKOPEO_DIR&#125;</span>/<span class="variable">$&#123;name&#125;</span>"</span></span><br><span class="line">        <span class="comment"># 硬链接镜像的 manifests 文件到目录的 manifest 文件</span></span><br><span class="line">        ln <span class="variable">$&#123;mfs&#125;</span> <span class="variable">$&#123;SKOPEO_DIR&#125;</span>/<span class="variable">$&#123;name&#125;</span>/manifest.json</span><br><span class="line">        <span class="comment"># 使用正则匹配出所有的 sha256 值，然后排序去重</span></span><br><span class="line">        layers=$(grep -Eo <span class="string">"\b[a-f0-9]&#123;64&#125;\b"</span> <span class="variable">$&#123;mfs&#125;</span> | sort -u)</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> <span class="variable">$&#123;layers&#125;</span>; <span class="keyword">do</span></span><br><span class="line">          <span class="comment"># 硬链接 registry 存储目录里的镜像 layer 和 images config 到镜像的 dir 目录</span></span><br><span class="line">            ln <span class="variable">$&#123;BLOB_DIR&#125;</span>/<span class="variable">$&#123;layer:0:2&#125;</span>/<span class="variable">$&#123;layer&#125;</span>/data <span class="variable">$&#123;SKOPEO_DIR&#125;</span>/<span class="variable">$&#123;name&#125;</span>/<span class="variable">$&#123;layer&#125;</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">sync_image</span></span>() &#123;</span><br><span class="line">    <span class="comment"># 使用 skopeo sync 将 dir 格式的镜像同步到 harbor</span></span><br><span class="line">    <span class="keyword">for</span> project <span class="keyword">in</span> $(ls <span class="variable">$&#123;SKOPEO_DIR&#125;</span>); <span class="keyword">do</span></span><br><span class="line">        skopeo sync --insecure-policy --src-tls-verify=<span class="literal">false</span> --dest-tls-verify=<span class="literal">false</span> \</span><br><span class="line">        --src dir --dest docker <span class="variable">$&#123;SKOPEO_DIR&#125;</span>/<span class="variable">$&#123;project&#125;</span> <span class="variable">$&#123;REGISTRY_DOMAIN&#125;</span>/<span class="variable">$&#123;project&#125;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gen_skopeo_dir</span><br><span class="line">sync_image</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;苦命打包工具人😭&quot;&gt;&lt;a
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://blog.k8s.li/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="registry" scheme="https://blog.k8s.li/tags/registry/"/>
    
      <category term="image" scheme="https://blog.k8s.li/tags/image/"/>
    
  </entry>
  
  <entry>
    <title>python-gitlab CLI 使用记录</title>
    <link href="https://blog.k8s.li/gitlab-cli.html"/>
    <id>https://blog.k8s.li/gitlab-cli.html</id>
    <published>2021-03-22T16:00:00.000Z</published>
    <updated>2021-03-19T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="开倒车-🚗-？"><a href="#开倒车-🚗-？" class="headerlink" title="开倒车 🚗 ？"></a>开倒车 🚗 ？</h2><p>年后这几周花了两周左右的时间将我司的 GitHub 代码迁移到内部的 Gitlab。影响最大的就是我们产品的发布流水线，需要适配 Gitlab 和内网环境的一些服务。基本上整个产品打包发布的流水线代码全部重写了一遍，可累坏咱了🥺。当时心里还认为代码迁移至 Gitlab 纯属倒车行为😅，不过等到所有的适配修改完毕后忽然发现 Gitlab 真香！</p><p>归根结底内网的 Gitlab 网络状况十倍百倍与 GitHub 不止。众所周知在学习<strong>墙国</strong>，GitHub 直连的速度和稳定性差的一批。也正因此之前在 GitHub 上的流水线经常会被网络抖动所干扰，有时侯 fetch 一个 repo 十几二十分钟！迁移到内网 Gitlab 之后，那速度简直飞起！以往最少十几分钟的流水线现在只需要不到五分钟就能完成😂。</p><p>于是今天就写篇博客记录一下当时折腾 Gitlab 时收获的一点人生经验👓</p><blockquote><p>我今天是作为一个长者给你们讲的，我不是新闻工作者，但是我见得太多了，我有这个必要告诉你们一点人生的经验</p></blockquote><h2 id="Gitlab"><a href="#Gitlab" class="headerlink" title="Gitlab"></a>Gitlab</h2><p>在折腾的过程中使用到的有关 Gitlab 的文档和工具：</p><ul><li><a href="https://about.gitlab.com/topics/version-control/what-is-gitlab-workflow/" target="_blank" rel="noopener">Gitlab workflow</a>：了解一下 Gitlab 的工作流，不同于 GitHub 的 PR，在 Gitlab 中使用的是 MR 的方式；</li><li><a href="https://docs.gitlab.com/ee/api/README.html" target="_blank" rel="noopener">Gitlab API</a>：Gitlab API 的官方文档，了解它在使用下下面这些工具时候会得心应手。</li><li><a href="https://python-gitlab.readthedocs.io/en/stable/api-objects.html" target="_blank" rel="noopener">python-gitlab</a> API client：使用 Python 实现的 Gitlab API client，用它来完成一些特定需求工具的开发，比如根据 tag 或者 branch获取 repo 中指定的文件或目录；</li><li><a href="https://python-gitlab.readthedocs.io/" target="_blank" rel="noopener">python-gitlab</a> CLI：基于 <a href="https://python-gitlab.readthedocs.io/en/stable/api-objects.html" target="_blank" rel="noopener">python-gitlab</a> API client 封装成的命令行工具，因为是 CLI 工具所以可以很方便地集成在一些流水线的脚本中；</li><li><a href="https://github.com/xanzy/go-gitlab" target="_blank" rel="noopener">go-gitlab</a> API client：使用 Golang 实现的 Gitlab API client。由于发布流水线中的一个阶段就是根据一个 list 来收集其他 repo 中的特定文件和目录，使用的工具是 golang 写的，为了减少代码修改量就使用了 go-gitlab 而不是 python-gitlab。</li></ul><h2 id="Gitlab-workflow"><a href="#Gitlab-workflow" class="headerlink" title="Gitlab workflow"></a><a href="https://about.gitlab.com/topics/version-control/what-is-gitlab-workflow/" target="_blank" rel="noopener">Gitlab workflow</a></h2><h3 id="PR"><a href="#PR" class="headerlink" title="PR"></a>PR</h3><p>在 GitHub 上我们一般使用 PR 的方式来完成代码合并工作，流程如下：</p><ul><li>成员 Fork 原始仓库，将 Fork 出来的仓库 clone 到本地</li><li>在本地创建新分支，并基于新分支进行修改和提交，推送新分支到 Fork 的仓库</li><li>基于 Fork 仓库中的新分支向原始仓库的目标分支发起 Pull Request</li><li>在 PR 的评论中 @ 审查者，请求 review 修改</li><li>审查者收到请求邮件，审查代码，并在建议处直接做出评论</li><li>提交者根据建议，继续提交改动，并对意见作出回应</li><li>审查者无异议后，在 PR 的评论中 @ 管理员，请求合入代码，管理员接受 PR，代码合入主分支</li></ul><h3 id="MR"><a href="#MR" class="headerlink" title="MR"></a>MR</h3><p>但是到了 Gitlab 之后我们就使用 MR 的方式来完成代码合并工作，流程如下：</p><ul><li>成员 Clone 原始仓库到本地，基于要修改的分支，创建新的分支</li><li>本地修改和提交，推送新分支到原始仓库</li><li>在原始仓库中基于新分支向目标保护分支发起 Merge Request</li><li>审核者 review 代码，管理员 Merge 代码</li></ul><p>相比来讲 MR 和方式更适合团队内部的协作开发，PR 的方式适合开源项目的协作开发。</p><h2 id="Gitlab-API"><a href="#Gitlab-API" class="headerlink" title="Gitlab API"></a><a href="https://docs.gitlab.com/ee/api/README.html" target="_blank" rel="noopener">Gitlab</a> API</h2><blockquote><p>The main GitLab API is a <a href="http://spec.openapis.org/oas/v3.0.3" target="_blank" rel="noopener">REST</a> API. Because of this, the documentation in this section assumes that you’re familiar with REST concepts.</p></blockquote><p>参照官方文档 <a href="https://docs.gitlab.com/ee/api/api_resources.html" target="_blank" rel="noopener">API resources</a> 可知，共有 Projects 、Groups、Standalone 这三种 API 分组。</p><ul><li>Projects： 对应的就是与 repo 相关的 API ，比如 tag、commit、branch 、MR、Issue 这一类型；</li><li>Groups： 对应类似于 GitHub 上的 Organizations，一般来讲公司里的 repo 都会按照团队来划分组织，同一团队里的 repo 会放在 gitlab 同一个 Groups  下，而不是以个人为单位存放 repo；</li><li>Standalone：则是除了 Projects 和 Groups 之外的 API 资源，如 user</li></ul><p>而我们多数情况下使用的是 Projects 相关的 API，通过它来对 repo 进行增删改查。简单介绍完 Gitlab API 类型之后，本文会介绍几种使用 Gitlab API 的工具。在使用这些工具的过程中，如果遇到一些错误可以通过 <a href="https://docs.gitlab.com/ee/api/README.html#status-codes" target="_blank" rel="noopener">Status codes</a> API 返回状态码来排查问题。</p><h2 id="python-gitlab-CLI"><a href="#python-gitlab-CLI" class="headerlink" title="python-gitlab CLI"></a><a href="https://python-gitlab.readthedocs.io/" target="_blank" rel="noopener">python-gitlab</a> CLI</h2><p>这是一个使用 <a href="https://python-gitlab.readthedocs.io/en/stable/api-objects.html" target="_blank" rel="noopener">python-gitlab</a> API client 封装好的 gitlab 命令行工具，可以使用它来完成绝大多数 Gitlab API 所支持的操作。因为之前的流水线中有很多操作是访问的 GitHub，比如提交 PR、获取 repo tag、查看 PR labels 等，都是写在 Jenkinsfile 调用各种脚本和工具来完成的。 切换到了 Gitlab，自然也需要一个工具来完成上述操作了。那么 python-gitlab CLI 这个工具无疑是不二之选，甚至比之前的工具更方便。因为迄今为止还没有见到过 GitHub 能有像 python-gitlab 这样的工具。总之，对于使用 Gitlab 的人来讲，要对 repo 完成一些自动化处理的工作，强烈推荐使用这个 CLI 工具，它可以很方便地集成在流水线中。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>python-gitlab CLI 依赖 Python 2.7 或者 3.4+，2021 年啦，就不要使用 Python2.7 啦😊。本地安装好 python3 和 pip3 后使用如下命令安装即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在这里使用清华的 pypi 源来加速安装，毕竟是墙🧱国</span></span><br><span class="line">$ sudo pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple requests PyYAML python-gitlab</span><br></pre></td></tr></table></figure><p>由于使用这个工具的场景大多数是在 Jenkins 所创建的 slave pod 中执行的，所以也可以构建一个 docker 镜像， <code>Dockerfile</code> 如下</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> debian:buster</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt update \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apt install -y --no-install-recommends \</span></span><br><span class="line"><span class="bash">        git \</span></span><br><span class="line"><span class="bash">        python3 \</span></span><br><span class="line"><span class="bash">        python3-pip \</span></span><br><span class="line"><span class="bash">        jq \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm -rf /var/lib/apt/lists/* \</span></span><br><span class="line"><span class="bash">    &amp;&amp; pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple requests PyYAML python-gitlab</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> python-gitlab.cfg /etc/python-gitlab.cfg</span></span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>Gitlab CLI 工具需要使用一个 <code>python-gitlab.cfg</code> 配置文件用于连接 Gitlab 服务器以及完成一些鉴权认证，配置文件格式为 <code>ini</code> 如下：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[global]</span></span><br><span class="line"><span class="attr">default</span> = gitlab.com</span><br><span class="line"><span class="attr">ssl_verify</span> = <span class="literal">true</span></span><br><span class="line"><span class="attr">timeout</span> = <span class="number">5</span></span><br><span class="line"><span class="attr">per_page</span> = <span class="number">100</span></span><br><span class="line"><span class="attr">api_version</span> = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="section">[gitlab.com]</span></span><br><span class="line"><span class="attr">url</span> = https://gitlab.com</span><br><span class="line"><span class="attr">private_token</span> = xxxxxxxxx</span><br></pre></td></tr></table></figure><ul><li>全局的连接参数</li></ul><table><thead><tr><th>Option</th><th>Possible values</th><th>Description</th></tr></thead><tbody><tr><td><code>ssl_verify</code></td><td><code>True</code> 或 <code>False</code></td><td>是否开启 SSL 加密验证</td></tr><tr><td><code>timeout</code></td><td>证书</td><td>连接超时时间</td></tr><tr><td><code>api_version</code></td><td><code>4</code></td><td>API 的版本，默认为 4 即可，参考 <a href="https://docs.gitlab.com/ee/api/v3_to_v4.html" target="_blank" rel="noopener">API V3 to API V4</a></td></tr><tr><td><code>per_page</code></td><td>1 ～ 100</td><td>每次返回的元素数量，Gitlab 的最大限制为 100。可以通过 <code>--all</code> 参数获取所有的元素</td></tr></tbody></table><ul><li>自定义 GitLab server 参数</li></ul><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody><tr><td><code>url</code></td><td>GitLab server 的 URL</td></tr><tr><td><code>private_token</code></td><td>通过访问 gitlab 服务器的 <a href="https://gitlab.com/-/profile/personal_access_tokens" target="_blank" rel="noopener">-/profile/personal_access_tokens</a> 来生成 token</td></tr><tr><td><code>oauth_token</code></td><td></td></tr><tr><td><code>job_token</code></td><td></td></tr><tr><td><code>api_version</code></td><td>API 的版本，默认为 4 即可，也可以不用定义，使用全局参数</td></tr><tr><td><code>http_username</code></td><td>Gitlab 用户名，不推荐使用它来连接 Gitlab 服务器</td></tr><tr><td><code>http_password</code></td><td>Gitlab 密码，不推荐使用它来连接 Gitlab 服务器</td></tr></tbody></table><p>将文件保存在 <code>~/.python-gitlab.cfg</code> 或者 <code>/etc/python-gitlab.cfg</code> ，也可以使用环境变量 <code>PYTHON_GITLAB_CFG</code> 或者 <code>--config-file</code> 执行配置文件的路径，为了省事儿还是将它放到 <code>~/.python-gitlab.cfg</code> 下。</p><p>配置完成之后，可以使用 <code>gitlab current-user get</code> 命令测试连接是否正常，如果有返回值且正确的用户名说明配置成功了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab current-user get</span><br><span class="line">username: muzi502</span><br></pre></td></tr></table></figure><h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><p>gitlab 命令行工具主要是对 Gitlab 服务器上的各种对象如：user, project, file, repo, mr, tag, commit 等进行增删改查(get、list、create、delete、update)。使用的命令行格式方式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab &lt;option&gt; [object] [action] &lt;option&gt;</span><br></pre></td></tr></table></figure><p>一般来讲只需要 4 种参数：</p><ul><li><p>第一个参数是紧接着 gitlab 命令后面的参数，它是 gitlab 命令行的输出参数和配置参数，如 <code>-o</code>参数指定输出结果的格式；<code>-f</code> 参数将输出结果存放到文件中; <code>-g</code> 参数执行连接哪个 Gitlab 服务器。</p></li><li><p>第二个参数则是用来指定所要操作的对象，比如 project-merge-request，project-tag 等，所支持的对象有很多，基本上涵盖了所有 Gitlab API 所支持的操作对象，如下：</p></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab -h</span><br><span class="line">usage: gitlab [-h] [--version] [-v] [-d] [-c CONFIG_FILE] [-g GITLAB] [-o &#123;json,legacy,yaml&#125;] [-f FIELDS]</span><br><span class="line">&#123;application,application-appearance,application-settings,audit-event,broadcast-message,current-user,current-user-email,current-user-gp-gkey,current-user-key,current-user-status,deploy-key,deploy-token,dockerfile,event,feature,geo-node,gitignore,gitlabciyml,group,group-access-request,group-badge,group-board,group-board-list,group-cluster,group-custom-attribute,group-deploy-token,group-epic,group-epic-issue,group-epic-resource-label-event,group-export,group-import,group-issue,group-label,group-member,group-merge-request,group-milestone,group-notification-settings,group-package,group-project,group-runner,group-subgroup,group-variable,hook,issue,l-da-pgroup,license,merge-request,namespace,notification-settings,pages-domain,project,project-access-request,project-additional-statistics,project-approval,project-approval-rule,project-badge,project-board,project-board-list,project-branch,project-cluster,project-commit,project-commit-comment,project-commit-discussion,project-commit-discussion-note,project-commit-status,project-custom-attribute,project-deploy-token,project-deployment,project-environment,project-event,project-export,project-file,project-fork,project-hook,project-import,project-issue,project-issue-award-emoji,project-issue-discussion,project-issue-discussion-note,project-issue-link,project-issue-note,project-issue-note-award-emoji,project-issue-resource-label-event,project-issue-resource-milestone-event,project-issues-statistics,project-job,project-key,project-label,project-member,project-merge-request,project-merge-request-approval,project-merge-request-approval-rule,project-merge-request-award-emoji,project-merge-request-diff,project-merge-request-discussion,project-merge-request-discussion-note,project-merge-request-note,project-merge-request-note-award-emoji,project-merge-request-resource-label-event,project-merge-request-resource-milestone-event,project-milestone,project-note,project-notification-settings,project-package,project-pages-domain,project-pipeline,project-pipeline-bridge,project-pipeline-job,project-pipeline-schedule,project-pipeline-schedule-variable,project-pipeline-variable,project-protected-branch,project-protected-tag,project-push-rules,project-registry-repository,project-registry-tag,project-release,project-remote-mirror,project-runner,project-service,project-snippet,project-snippet-award-emoji,project-snippet-discussion,project-snippet-discussion-note,project-snippet-note,project-snippet-note-award-emoji,project-tag,project-trigger,project-user,project-variable,project-wiki,runner,runner-job,snippet,todo,user,user-activities,user-custom-attribute,user-email,user-event,user-gp-gkey,user-impersonation-token,user-key,user-membership,user-project,user-status,variable&#125;</span><br></pre></td></tr></table></figure><ul><li>第三个参数则是 action 参数，即用于指定对所操作的对象进行何种操作，一般来讲都会支持增删改查操作（get, list, create, update, delete）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab project-tag</span><br><span class="line">usage: gitlab project-tag [-h] &#123;list,get,create,delete,<span class="built_in">set</span>-release-description&#125; ...</span><br></pre></td></tr></table></figure><ul><li>第三个参数则是 object + action 所依赖的参数，比如指定 project id</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab project-tag list</span><br><span class="line">usage: gitlab project-tag list --project-id PROJECT_ID [--page PAGE] [--per-page PER_PAGE] [--all]</span><br><span class="line">gitlab project-tag list: error: the following arguments are required: --project-id</span><br></pre></td></tr></table></figure><ul><li><p>Project-ID：是 gitlab 上唯一表示该 repo 的 ID，可分为两种，一种是 <code>group/project</code> 的形式，其中 <code>/</code> 要转译成 <code>%2F</code> 如：<code>muzi502%2Fkubespray</code>；另一种则是数字的形式，在该 repo 的 web 页面上可以看到，推荐使用第二种。</p><p><img src="https://p.k8s.li/image-20210319085926423.png" alt="image-20210319085926423"></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 也可以使用gitlab 命令获取 repo 的 id</span></span><br><span class="line">$ gitlab project get --id muzi502%2Fkubespray</span><br><span class="line">id: 25099880</span><br><span class="line">path: kubespray</span><br></pre></td></tr></table></figure><ul><li>在流水线中可以根据 token 获取用户的用户名和邮箱，用于配置流水线中的 repo git 信息，避免因为 CLA 无法通过。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gitlab -o json current-user get | jq '.id'</span><br><span class="line">git config --global user.email $(gitlab -o json current-user get | jq -r '.email')</span><br><span class="line">git config --global user.name $(gitlab -o json current-user get | jq -r '.username')</span><br></pre></td></tr></table></figure><h3 id="project"><a href="#project" class="headerlink" title="project"></a>project</h3><ul><li>获取 repo ssh url  地址</li></ul><p>由于 Jenkins 流水线中 clone 的 repo url 是使用 token+ https 的方式，在流水线中如果要 push 代码到 repo 需要修改为 ssh 的方式，可使用如下方式根据 project id 来获取该 repo 的 ssh url。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab -o json  project get --id <span class="variable">$&#123;PROJECT_ID&#125;</span> | jq -r <span class="string">'.ssh_url_to_repo'</span></span><br><span class="line">$ git remote remove origin</span><br><span class="line">$ git remote add origin $(gitlab -o json  project get --id <span class="variable">$&#123;PROJECT_ID&#125;</span> | jq -r <span class="string">'.ssh_url_to_repo'</span>)</span><br></pre></td></tr></table></figure><h3 id="file"><a href="#file" class="headerlink" title="file"></a>file</h3><p>对于 repo 中文件的操作使用 project-file</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab project-file</span><br><span class="line">usage: gitlab project-file [-h] &#123;get,create,update,delete,raw,blame&#125; ...</span><br></pre></td></tr></table></figure><ul><li>获取文件，通过 <code>project-file</code> 对象的 get 操作</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab -o json project-file get --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span> --file-path .gitignore --ref master  | jq <span class="string">'.'</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"file_name"</span>: <span class="string">".gitignore"</span>,</span><br><span class="line">  <span class="string">"file_path"</span>: <span class="string">".gitignore"</span>,</span><br><span class="line">  <span class="string">"size"</span>: 1208,</span><br><span class="line">  <span class="string">"encoding"</span>: <span class="string">"base64"</span>,</span><br><span class="line">  <span class="string">"content_sha256"</span>: <span class="string">"91f1d50ba3a4f79f96d9371afc70b389f75dfb2ac5190b8fb01051aa8679fd04"</span>,</span><br><span class="line">  <span class="string">"ref"</span>: <span class="string">"master"</span>,</span><br><span class="line">  <span class="string">"blob_id"</span>: <span class="string">"b09ca9d3b101034c7e34430177c1d64738df5fbb"</span>,</span><br><span class="line">  <span class="string">"commit_id"</span>: <span class="string">"a9c97e5253c455546c2c7fdd794147eeb9b8ab7a"</span>,</span><br><span class="line">  <span class="string">"last_commit_id"</span>: <span class="string">"4ffc106c58fc5865b6d72a52365e25b8c268d4d8"</span>,</span><br><span class="line">  <span class="string">"content"</span>: <span class="string">"LnZhZ3JhbnQKKi5yZXRyeQoqKi92YWdyYW50X2Fuc2libGVfaW52ZW50b3J5CiouaW1sCnRlbXAKLmlkZWEKLnRveAouY2FjaGUKKi5iYWsKKi50ZnN0YXRlCioudGZzdGF0ZS5iYWNrdXAKLnRlcnJhZm9ybS8KY29udHJpYi90ZXJyYWZvcm0vYXdzL2NyZWRlbnRpYWxzLnRmdmFycwovc3NoLWJhc3Rpb24uY29uZgoqKi8qLnN3W3Bvbl0KKn4KdmFncmFudC8KcGx1Z2lucy9taXRvZ2VuCgojIEFuc2libGUgaW52ZW50b3J5CmludmVudG9yeS8qCiFpbnZlbnRvcnkvbG9jYWwKIWludmVudG9yeS9zYW1wbGUKaW52ZW50b3J5LyovYXJ0aWZhY3RzLwoKIyBCeXRlLWNvbXBpbGVkIC8gb3B0aW1pemVkIC8gRExMIGZpbGVzCl9fcHljYWNoZV9fLwoqLnB5W2NvZF0KKiRweS5jbGFzcwoKIyBEaXN0cmlidXRpb24gLyBwYWNrYWdpbmcKLlB5dGhvbgplbnYvCmJ1aWxkLwpjcmVkZW50aWFscy8KZGV2ZWxvcC1lZ2dzLwpkaXN0Lwpkb3dubG9hZHMvCmVnZ3MvCi5lZ2dzLwpwYXJ0cy8Kc2Rpc3QvCnZhci8KKi5lZ2ctaW5mby8KLmluc3RhbGxlZC5jZmcKKi5lZ2cKCiMgUHlJbnN0YWxsZXIKIyAgVXN1YWxseSB0aGVzZSBmaWxlcyBhcmUgd3JpdHRlbiBieSBhIHB5dGhvbiBzY3JpcHQgZnJvbSBhIHRlbXBsYXRlCiMgIGJlZm9yZSBQeUluc3RhbGxlciBidWlsZHMgdGhlIGV4ZSwgc28gYXMgdG8gaW5qZWN0IGRhdGUvb3RoZXIgaW5mb3MgaW50byBpdC4KKi5tYW5pZmVzdAoqLnNwZWMKCiMgSW5zdGFsbGVyIGxvZ3MKcGlwLWxvZy50eHQKcGlwLWRlbGV0ZS10aGlzLWRpcmVjdG9yeS50eHQKCiMgVW5pdCB0ZXN0IC8gY292ZXJhZ2UgcmVwb3J0cwpodG1sY292LwoudG94LwouY292ZXJhZ2UKLmNvdmVyYWdlLioKLmNhY2hlCm5vc2V0ZXN0cy54bWwKY292ZXJhZ2UueG1sCiosY292ZXIKLmh5cG90aGVzaXMvCgojIFRyYW5zbGF0aW9ucwoqLm1vCioucG90CgojIERqYW5nbyBzdHVmZjoKKi5sb2cKbG9jYWxfc2V0dGluZ3MucHkKCiMgRmxhc2sgc3R1ZmY6Cmluc3RhbmNlLwoud2ViYXNzZXRzLWNhY2hlCgojIFNjcmFweSBzdHVmZjoKLnNjcmFweQoKIyBTcGhpbnggZG9jdW1lbnRhdGlvbgpkb2NzL19idWlsZC8KCiMgUHlCdWlsZGVyCnRhcmdldC8KCiMgSVB5dGhvbiBOb3RlYm9vawouaXB5bmJfY2hlY2twb2ludHMKCiMgcHllbnYKLnB5dGhvbi12ZXJzaW9uCgojIGRvdGVudgouZW52CgojIHZpcnR1YWxlbnYKdmVudi8KRU5WLwo="</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件内容是 base64 编码的，需要使用 base64 解码才能获取原始的内容。</span></span><br><span class="line">$ gitlab -g gitlab -o json project-file get --project-id 25099880 --file-path .gitignore --ref master  | jq -r <span class="string">'.content'</span> | base64 -d</span><br><span class="line">.vagrant</span><br><span class="line">*.retry</span><br><span class="line">**/vagrant_ansible_inventory</span><br><span class="line">*.iml</span><br><span class="line">temp</span><br><span class="line">.idea</span><br><span class="line">.tox</span><br><span class="line">…………</span><br></pre></td></tr></table></figure><ul><li>通过 project-file 的 raw 方法可以获取文件的原始内容，无须 base64 解码</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab project-file get --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span> --file-path .gitignore --ref master</span><br></pre></td></tr></table></figure><ul><li><p>创建文件，对文件的增删改都是通过提交 commit 来完成的，因此需要指定所要操作的分支以及 commit-message 的信息。另外如果操作的文件是 master 分支获取其他保护分支，要确保当前用户有写入的权限，不然会提示如下错误：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gitlab project-file update</span><br><span class="line">Impossible to update object (400: You are not allowed to push into this branch)</span><br></pre></td></tr></table></figure></li></ul><p>之前在 GitHub 上有一套 CI 并不能适用于 Gitlab，因此需要为所有的分支创建 CI 流水线，用于检查代码是否符合规范，可以通过如下方法批量量地向所有分支创建文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ID=123456</span><br><span class="line">BRANCHS=$(gitlab -o json project-branch list --project-id <span class="variable">$&#123;ID&#125;</span> --all | jq -r <span class="string">".[].name"</span>)</span><br><span class="line"><span class="keyword">for</span> branch <span class="keyword">in</span> <span class="variable">$&#123;BRANCHS&#125;</span>; <span class="keyword">do</span></span><br><span class="line">gitlab project-file create --project-id <span class="variable">$&#123;ID&#125;</span> --file-path .gitlab-ci.yml --branch <span class="variable">$&#123;branch&#125;</span> --content @.gitlab-ci.yml --commit-message <span class="string">"feat(gitlab-ci): add gitlab-ci.yml for ci"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><ul><li>更新文件</li></ul><p>比如批量更新所有分支的 <code>Makefile</code> 中 <code>github.com</code> 为 <code>gitlab.com</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ID=123456</span><br><span class="line">BRANCHS=$(gitlab -o json project-branch list --project-id <span class="variable">$&#123;ID&#125;</span> --all | jq -r <span class="string">".[].name"</span>)</span><br><span class="line"><span class="keyword">for</span> branch <span class="keyword">in</span> <span class="variable">$&#123;BRANCHS&#125;</span>; <span class="keyword">do</span></span><br><span class="line">    rm -f Makefile Makefile-</span><br><span class="line">    gitlab project-file raw --project-id <span class="variable">$&#123;ID&#125;</span> --file-path Makefile --ref <span class="variable">$&#123;branch&#125;</span> &gt; Makefile</span><br><span class="line">    sed -i- <span class="string">"s|github.com/muzi502|gitlab.com/muzi502"</span> Makefile</span><br><span class="line">    gitlab project-file update --project-id <span class="variable">$&#123;ID&#125;</span> --file-path Makefile --branch <span class="variable">$&#123;branch&#125;</span> --content @Makefile \</span><br><span class="line">    --commit-message <span class="string">"chore(Makefile): update repo url in Makefile for migrate gitlab"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><ul><li>删除文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab project-file delete --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span> --file-path .gitignore --ref master \</span><br><span class="line">--commit-message <span class="string">"test delete file"</span></span><br></pre></td></tr></table></figure><h3 id="MR-1"><a href="#MR-1" class="headerlink" title="MR"></a>MR</h3><ul><li>创建 MR，指定 source branch 和 target branch 以及 mr 的 title 这三个参数。前面最好加上 -o json 参数用户获取 mr 的 iid，可通过此 iid 来对这个 mr 进行增删改查。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab -o json project-merge-request create --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span> --<span class="built_in">source</span>-branch --target-branch <span class="variable">$&#123;BASE_BRANCH&#125;</span> --title <span class="string">"<span class="variable">$&#123;MR_TITLE&#125;</span>"</span></span><br></pre></td></tr></table></figure><p>通过 -o json 参数会返回此 mr 的信息，其中 <code>iid</code> 就是该 mr 在此 repo 中的唯一标示</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab -g gitlab -o json project-merge-request create --project-id 25099880 --source-branch release-2.14 --target-branch  master --title "mr create test"</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"id"</span>: <span class="number">92872102</span>,</span><br><span class="line">  <span class="attr">"iid"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"project_id"</span>: <span class="number">25099880</span>,</span><br><span class="line">  <span class="attr">"title"</span>: <span class="string">"mr create test"</span>,</span><br><span class="line">  <span class="attr">"description"</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">"state"</span>: <span class="string">"opened"</span>,</span><br><span class="line">  <span class="attr">"created_at"</span>: <span class="string">"2021-03-21T12:42:52.893Z"</span>,</span><br><span class="line">  <span class="attr">"updated_at"</span>: <span class="string">"2021-03-21T12:42:52.893Z"</span>,</span><br><span class="line">  <span class="attr">"merged_by"</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">"merged_at"</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">"closed_by"</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">"closed_at"</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">"target_branch"</span>: <span class="string">"master"</span>,</span><br><span class="line">  <span class="attr">"source_branch"</span>: <span class="string">"release-2.14"</span>,</span><br><span class="line">  <span class="attr">"user_notes_count"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"upvotes"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"downvotes"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"author"</span>: &#123;</span><br><span class="line">    <span class="attr">"id"</span>: <span class="number">5599205</span>,</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"muzi502"</span>,</span><br><span class="line">    <span class="attr">"username"</span>: <span class="string">"muzi502"</span>,</span><br><span class="line">    <span class="attr">"state"</span>: <span class="string">"active"</span>,</span><br><span class="line">    <span class="attr">"avatar_url"</span>: <span class="string">"https://secure.gravatar.com/avatar/f91578ffea9a538eedd8fbaf3007289b?s=80&amp;d=identicon"</span>,</span><br><span class="line">    <span class="attr">"web_url"</span>: <span class="string">"https://gitlab.com/muzi502"</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ul><li>合并 MR</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab project-merge-request merge --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span> --iid @mr_iid</span><br></pre></td></tr></table></figure><ul><li>查看 MR 状态</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab -o json project-merge-request get --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span> --iid @mr_iid | jq -r <span class="string">".state"</span></span><br></pre></td></tr></table></figure><ul><li>集成在 Jenkinsfile  中完成创建 MR、合并 MR、检查 MR </li></ul><p>调用用它的时候只需要传入 SOURCE_BRANCH, TARGET_BRANCH, MR_TITLE 这三个参数即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">def makeMR(SOURCE_BRANCH, TARGET_BRANCH, MR_TITLE) &#123;</span><br><span class="line">    container(<span class="string">"debian"</span>) &#123;</span><br><span class="line">        sh <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        gitlab -o json project-merge-request create --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span>  --title \"<span class="variable">$&#123;MR_TITLE&#125;</span>\" \</span></span><br><span class="line"><span class="string">        --source-branch <span class="variable">$&#123;SOURCE_BRANCH&#125;</span> --target-branch <span class="variable">$&#123;TARGET_BRANCH&#125;</span> &gt; mr_info.json</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        jq -r '.iid' mr_info.json &gt; mr_iid</span></span><br><span class="line"><span class="string">        jq -r '.web_url' mr_info.json &gt; mr_url</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">def <span class="function"><span class="title">checkMR</span></span>() &#123;</span><br><span class="line">    container(<span class="string">"debian"</span>) &#123;</span><br><span class="line">        retry(120) &#123;</span><br><span class="line">        sh <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        if [ ! -s mr_iid ]; then exit 0; else sleep 60s; fi</span></span><br><span class="line"><span class="string">        gitlab -o json project-merge-request get --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span> --iid @mr_iid | jq -r "</span>.labels[]<span class="string">" | grep 'approve'</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">def <span class="function"><span class="title">mergeMR</span></span>()&#123;</span><br><span class="line">    container(<span class="string">"debian"</span>) &#123;</span><br><span class="line">        retry(10)&#123;</span><br><span class="line">        sh <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        if [ ! -s mr_iid ]; then exit 0; else sleep 60s; fi</span></span><br><span class="line"><span class="string">        if gitlab project-merge-request merge --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span> --iid @mr_iid; then sleep 10s; fi</span></span><br><span class="line"><span class="string">        gitlab -o json project-merge-request get --project-id <span class="variable">$&#123;PROJECT_ID&#125;</span> --iid @mr_iid | jq -r "</span>.state<span class="string">" | grep 'merged'</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Tag"><a href="#Tag" class="headerlink" title="Tag"></a>Tag</h3><ul><li>列出 repo tag</li></ul><p>在这里还是推荐使用 git tag 的方式获取 repo tag ，因为 Gitlab API 的限制，每次请求最多只能返回 100 个值，可以加上 <code>--all</code> 参数来返回所有的值。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab -o json project-tag list --project-id <span class="variable">$&#123;ID&#125;</span> | jq -r <span class="string">'.[].name'</span></span><br><span class="line">$ gitlab -o json project-tag list --project-id <span class="variable">$&#123;ID&#125;</span> --all | jq -r <span class="string">'.[].name'</span></span><br></pre></td></tr></table></figure><ul><li>创建 tag</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab project-tag create --project-id <span class="variable">$&#123;ID&#125;</span> --tag-name v1.0.0-rc.2 --ref master</span><br></pre></td></tr></table></figure><ul><li>删除 tag</li></ul><p>upstream 上的 repo tag 只能通过在 Gitlab 上删除，在本地 repo 下是无法删除的，因此可以使用如下命令删除  Gitlab repo tag，注意：受保护的 repo tag 如果没有权限的话是无法删除的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab project-tag delete --project-id <span class="variable">$&#123;ID&#125;</span> --tag-name v1.0.0-rc.2</span><br></pre></td></tr></table></figure><ul><li>创建受保护的 repo tag</li></ul><p>由于我们流水线任务依赖于 repo tag 来做版本的对于，因此需要保护每一个 repo tag，但有特殊情况下又要覆盖 repo tag，所以受保护的 repo tag 目前还没有找到合适的方法，只能先手动创建了，等到需要删除的时候再删除它。可以使用如下命令批量创建受保护的 repo tag。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git tag | xargs -L1 -I &#123;&#125; gitlab project-protected-tag create --project-id <span class="variable">$&#123;ID&#125;</span> --name &#123;&#125;</span><br></pre></td></tr></table></figure><h2 id="Lint-流水线"><a href="#Lint-流水线" class="headerlink" title="Lint 流水线"></a>Lint 流水线</h2><p>迁移到了 Gitlab 之后原有的流水线在内网的 Gitlab 上也就无法使用了，为了减少维护成本就使用了 Gitlab 自带的 CI 。我所维护的 repo 使用 Gitlab CI 只是做一些 lint 的检查内容，因此 CI 配置起来也特别简单。如 kubespray 的 CI 配置：</p><ul><li><code>.gitlab-ci.yml</code></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">lint:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">'quay.io/kubespray/kubespray:v2.15.0'</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">chmod</span> <span class="string">-R</span> <span class="string">o-w</span> <span class="string">.</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">make</span> <span class="string">lint</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">shared</span></span><br></pre></td></tr></table></figure><ul><li>使用 gitlab CLI 工具给所有分支添加 <code>.gitlab-ci.yml</code> 文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ID=123456</span><br><span class="line">BRANCHS=$(gitlab -o json project-branch list --project-id <span class="variable">$&#123;ID&#125;</span> --all | jq -r <span class="string">".[].name"</span>)</span><br><span class="line"><span class="keyword">for</span> branch <span class="keyword">in</span> <span class="variable">$&#123;BRANCHS&#125;</span>; <span class="keyword">do</span></span><br><span class="line">gitlab project-file create --project-id <span class="variable">$&#123;ID&#125;</span> --file-path .gitlab-ci.yml --branch <span class="variable">$&#123;branch&#125;</span> --content @.gitlab-ci.yml --commit-message <span class="string">"feat(gitlab-ci): add gitlab-ci.yml for ci"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>repo 迁移</li></ul><p>由于内部的 Gitlab 不支持导入 git url 的方式，所以只能手动地将 GitHub 上的 repo clone 到本地再 push 到 Gitlab 上。使用 git clone 的方式本地只会有一个 master 分支，要把 GitHub 上 repo 的所有分支都 track 一遍，然后再 push 到 Gitlab 上。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 git clone 下来的 repo 默认为 master 分支</span></span><br><span class="line">$ git <span class="built_in">clone</span> git@gitlab.com/muzi502/kubespray.git</span><br><span class="line"><span class="comment"># track 出 origin 上的所有分支</span></span><br><span class="line">$ git branch -r | grep -v <span class="string">'\-&gt;'</span> | <span class="keyword">while</span> <span class="built_in">read</span> remote; <span class="keyword">do</span> git branch --track <span class="string">"<span class="variable">$&#123;remote#origin/&#125;</span>"</span> <span class="string">"<span class="variable">$remote</span>"</span>; <span class="keyword">done</span></span><br><span class="line">$ git fetch --all</span><br><span class="line">$ git pull --all</span><br><span class="line">$ git remote remove origin</span><br><span class="line">$ git remote add origin git@gitlab/gitlab502/kubespray.git</span><br><span class="line">$ git push origin --all</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://stackoverflow.com/questions/10312521/how-to-fetch-all-git-branches" target="_blank" rel="noopener">How to fetch all Git branches</a></li><li><a href="https://yixinglu.gitlab.io/gitlab-workflow.html" target="_blank" rel="noopener">GitLab 工作流</a></li><li><a href="https://python-gitlab.readthedocs.io/" target="_blank" rel="noopener">python-gitlab</a></li><li><a href="https://docs.gitlab.com/ee/api/README.html" target="_blank" rel="noopener">Gitlab API Docs</a></li><li><a href="https://github.com/xanzy/go-gitlab" target="_blank" rel="noopener">go-gitlab</a></li><li><a href="https://mp.weixin.qq.com/s/x5PHNn87OYCSpYE_hb8I2A" target="_blank" rel="noopener">谈谈 Git 存储原理及相关实现</a></li><li><a href="https://morningspace.github.io/tech/inside-git-3/" target="_blank" rel="noopener">Git解密——认识Git引用</a></li><li><a href="https://blinkfox.github.io/2018/11/22/ruan-jian-gong-ju/devops/gitlab-ci-jie-shao-he-shi-yong/" target="_blank" rel="noopener">GitLab CI/CD 介绍和使用</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;开倒车-🚗-？&quot;&gt;&lt;a
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://blog.k8s.li/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ci" scheme="https://blog.k8s.li/tags/ci/"/>
    
      <category term="gitlab" scheme="https://blog.k8s.li/tags/gitlab/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins 大叔与 kubernetes 船长手牵手 🧑‍🤝‍🧑</title>
    <link href="https://blog.k8s.li/jenkins-with-kubernetes.html"/>
    <id>https://blog.k8s.li/jenkins-with-kubernetes.html</id>
    <published>2021-03-05T16:00:00.000Z</published>
    <updated>2021-03-06T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>虽然云原生时代有了 <a href="https://jenkins-x.io/" target="_blank" rel="noopener">JenkinsX</a>、<a href="https://www.drone.io/" target="_blank" rel="noopener">Drone</a>、<a href="https://tekton.dev" target="_blank" rel="noopener">Tekton</a> 这样的后起之秀，但 Jenkins 这样一个老牌的 CI/CD 工具仍是各大公司主流的使用方案。比如我司的私有云产品打包发布就是用这老家伙完成的。然而传统的 Jenkins Slave 一主多从方式会存在一些痛点，比如：</p><ul><li>每个 Slave 的配置环境不一样，来完成不同语言的编译打包等操作，但是这些差异化的配置导致管理起来非常不方便，维护起来也是比较费劲</li><li>资源分配不均衡，有的 Slave 要运行的 job 出现排队等待，而有的 Slave 处于空闲状态</li><li>资源有浪费，每台 Slave 可能是物理机或者虚拟机，当 Slave 处于空闲状态时，也不会完全释放掉资源。</li></ul><p>正因为上面的 Jenkins slave 存在这些种种痛点，我们渴望一种更高效更可靠的方式来完成这个 CI/CD 流程，而 Docker 虚拟化容器技术能很好的解决这个痛点，又特别是在 Kubernetes 集群环境下面能够更好来解决上面的问题，下图是基于 Kubernetes 搭建 Jenkins slave 集群的简单示意图：</p><p><img src="https://p.k8s.li/k8s-jenkins-slave.png" alt="k8s-jenkins"></p><p>从图上可以看到 Jenkins Master 时以 docker-compose 的方式运行在一个节点上。Jenkins Slave 以 Pod 形式运行在 Kubernetes 集群的 Node 上，并且它不是一直处于运行状态，它会按照需求动态的创建并自动删除。这种方式的工作流程大致为：当 Jenkins Master 接受到 Build 请求时，会根据配置的 Label 动态创建一个运行在 Pod 中的 Jenkins Slave 并注册到 Master 上，当运行完 Job 后，这个 Slave 会被注销并且这个 Pod 也会自动删除，恢复到最初状态。</p><p>那么我们使用这种方式带来了以下好处：</p><ul><li><strong>动态伸缩</strong>，合理使用资源，每次运行 Job 时，会自动创建一个 Jenkins Slave，Job 完成后，Slave 自动注销并删除容器，资源自动释放，而且 Kubernetes 会根据每个资源的使用情况，动态分配 Slave 到空闲的节点上创建，降低出现因某节点资源利用率高，还排队等待在该节点的情况。</li><li><strong>扩展性好</strong>，当 Kubernetes 集群的资源严重不足而导致 Job 排队等待时，可以很容易的添加一个 Kubernetes Node 到集群中，从而实现扩展。</li></ul><p>上面的大半段复制粘贴自 <a href="https://www.qikqiak.com/k8s-book/docs/36.Jenkins%20Slave.html" target="_blank" rel="noopener">基于 Jenkins 的 CI/CD (一)</a> 🤐</p><h2 id="kubernetes-集群"><a href="#kubernetes-集群" class="headerlink" title="kubernetes 集群"></a>kubernetes 集群</h2><p>关于 kubernetes 集群部署，使用 kubeadm 部署是最为方便的了，可参考我很早之前写过的文章《<a href="https://blog.k8s.li/kubeadm-deploy-k8s-v1.17.4.html">使用 kubeadm 快速部署体验 K8s</a>》，在这里只是简单介绍一下：</p><ul><li>使用 kubeadm 来创建一个单 master 节点的 kubernets 集群</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@jenkins:~ <span class="comment"># kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.20.11</span></span><br></pre></td></tr></table></figure><ul><li>集群成功部署完成之后会有如下提示：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><ul><li>查看节点状态和 pod 都已经正常</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">root@jenkins:~ <span class="comment"># kubectl get pod -A</span></span><br><span class="line">NAMESPACE     NAME                              READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-f9fd979d6-9t6qp           1/1     Running   0          89s</span><br><span class="line">kube-system   coredns-f9fd979d6-hntm8           1/1     Running   0          89s</span><br><span class="line">kube-system   etcd-jenkins                      1/1     Running   0          106s</span><br><span class="line">kube-system   kube-apiserver-jenkins            1/1     Running   0          106s</span><br><span class="line">kube-system   kube-controller-manager-jenkins   1/1     Running   0          106s</span><br><span class="line">kube-system   kube-proxy-8pzkz                  1/1     Running   0          89s</span><br><span class="line">kube-system   kube-scheduler-jenkins            1/1     Running   0          106s</span><br><span class="line">root@jenkins:~ <span class="comment"># kubectl get node</span></span><br><span class="line">NAME      STATUS   ROLES    AGE    VERSION</span><br><span class="line">jenkins   Ready    master   119s   v1.19.8</span><br></pre></td></tr></table></figure><ul><li>去除 master 节点上的污点，允许其他的 pod 调度在 master 节点上，不然后面 Jenkins 所创建的 pod 将无法调度在该节点上。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes $(hostname) node-role.kubernetes.io/master:NoSchedule-</span><br></pre></td></tr></table></figure><h2 id="Jenkins-master"><a href="#Jenkins-master" class="headerlink" title="Jenkins master"></a>Jenkins master</h2><p>至于  Jenkins master 的部署方式，个人建议使用 docker-compose 来部署。运行在 kubernetes 集群集群中也没什么毛病，可以参考 <a href="https://www.qikqiak.com/k8s-book/docs/36.Jenkins%20Slave.html" target="_blank" rel="noopener">基于 Jenkins 的 CI/CD (一)</a> 这篇博客。但从个人运维踩的坑来讲，还是将  Jenkins master 独立于 kubernetes 集群部署比较方便😂。</p><ul><li><code>docker-compose.yaml</code></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'3.6'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">jenkins:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">jenkins/jenkins:2.263.4-lts-slim</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">jenkins</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./jenkins_home:/var/jenkins_home</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">user:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JAVA_OPTS=-Duser.timezone=Asia/Shanghai</span></span><br></pre></td></tr></table></figure><ul><li>使用 docker-compose up 来启动，成功启动后会有如下提示，日志输出的密钥就是 <code>admin</code> 用户的默认密码，使用它来第一次登录 Jenkins。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">jenkins    | 2021-03-06 02:22:31.741+0000 [id=41]INFOjenkins.install.SetupWizard<span class="comment">#init:</span></span><br><span class="line">jenkins    |</span><br><span class="line">jenkins    | *************************************************************</span><br><span class="line">jenkins    | *************************************************************</span><br><span class="line">jenkins    | *************************************************************</span><br><span class="line">jenkins    |</span><br><span class="line">jenkins    | Jenkins initial setup is required. An admin user has been created and a password generated.</span><br><span class="line">jenkins    | Please use the following password to proceed to installation:</span><br><span class="line">jenkins    |</span><br><span class="line">jenkins    | 4c2361968cd94323acdde17f7603d8e1</span><br><span class="line">jenkins    |</span><br><span class="line">jenkins    | This may also be found at: /var/jenkins_home/secrets/initialAdminPassword</span><br><span class="line">jenkins    |</span><br><span class="line">jenkins    | *************************************************************</span><br><span class="line">jenkins    | *************************************************************</span><br><span class="line">jenkins    | *************************************************************</span><br></pre></td></tr></table></figure><ul><li>登录上去之后，建议选择 <code>选择插件来安装</code>，尽可能少地安装插件，按需安装即可。</li></ul><p><img src="https://p.k8s.li/image-20210306102735594.png" alt="image-20210306102735594"></p><ul><li>在 Jenkins 的插件管理那里安装上 kubernetes 插件</li><li><img src="https://p.k8s.li/image-20210306103352837.png" alt="image-20210306103352837"></li><li>接下来开始配置 Jenkins 大叔如何与 kubernetes 船长手牵手🧑‍🤝‍🧑 :-)。配置 kubernets 的地方是在 <code>系统管理 &gt; 节点管理 &gt; Configure Clouds</code>。点击 <code>Add a new cloud</code>，来添加一个 kubernetes 集群。</li></ul><p><img src="https://p.k8s.li/image-20210306111626079.png" alt="image-20210306111626079"></p><ul><li>配置连接参数</li></ul><table><thead><tr><th>参数</th><th>值</th><th>说明</th></tr></thead><tbody><tr><td>名称</td><td>kubernetes</td><td>也是后面 pod 模板中的 <code>cloud</code> 的值</td></tr><tr><td>凭据</td><td>kubeconfig 凭据 id</td><td>使用 kubeconfig 文件来连接集群</td></tr><tr><td>Kubernetes 地址</td><td>默认即可</td><td></td></tr><tr><td>Use Jenkins Proxy</td><td>默认即可</td><td></td></tr><tr><td>Kubernetes 服务证书 key</td><td>默认即可</td><td></td></tr><tr><td>禁用 HTTPS 证书检查</td><td>默认即可</td><td></td></tr><tr><td>Kubernetes 命名空间</td><td>默认即可</td><td></td></tr><tr><td>WebSocket</td><td>默认即可</td><td></td></tr><tr><td>Direct Connection</td><td>默认即可</td><td></td></tr><tr><td>Jenkins 地址</td><td><a href="http://jenkins.k8s.li:8080" target="_blank" rel="noopener">http://jenkins.k8s.li:8080</a></td><td>Jenkins pod 连接  Jenkins master 的  URL</td></tr><tr><td>Jenkins 通道</td><td>50000</td><td>Jenkins <code>JNLP</code> 的端口，默认为 50000</td></tr><tr><td>Connection Timeout</td><td>默认即可</td><td>Jenkins 连接 kubernetes 超时时间</td></tr><tr><td>Read Timeout</td><td>默认即可</td><td></td></tr><tr><td>容器数量</td><td>默认即可</td><td>Jenkins pod 创建的最大数量</td></tr><tr><td>Pod Labels</td><td>默认即可</td><td>Jenkins pod 的 lables</td></tr><tr><td>连接 Kubernetes API 的最大连接数</td><td>默认即可</td><td></td></tr><tr><td>Seconds to wait for pod to be running</td><td>默认即可</td><td>等待 pod 正常 running 的时间</td></tr></tbody></table><ul><li>在 Jenkins 的凭据那里添加上 kubeconfig 文件，凭据的类型选择为 <code>Secret file</code>，然后将上面使用 kubeadm 部署生成的 kubeconfig 上传到这里。</li></ul><p><img src="https://p.k8s.li/image-20210306111037947.png" alt="image-20210306111037947"></p><ul><li>点击连接测试，如果提示 <code>Connected to Kubernetes v1.19.8</code> 就说明已经成功连接上了 kubernetes 集群。</li></ul><p><img src="https://p.k8s.li/image-20210306111148462.png" alt="image-20210306111148462"></p><ul><li>关于 pod 模板</li></ul><p>其实就是配置 Jenkins Slave 运行的 Pod 模板，个人不太建议使用插件中的模板去配置，推荐将 pod 的模板放在 Jenkinsfile 中，因为这些配置与我们的流水线紧密相关，把 pod 的配置存储在 Jenkins 的插件里实在是不太方便；不方便后续的迁移备份之类的工作；后续插件升级后这些配置也可能会丢失。因此建议将 pod 模板的配置直接定义在 Jenkinsfile 中，灵活性更高一些，不会受 Jenkins 插件升级的影响。总之用代码去管理这些 pod 配置维护成本将会少很多。</p><h2 id="Jenkinsfile"><a href="#Jenkinsfile" class="headerlink" title="Jenkinsfile"></a>Jenkinsfile</h2><ul><li>流水线 <code>Jenkinsfile</code>，下面是一个简单的任务，用于构建 <a href="https://github.com/webp-sh/webp_server_go" target="_blank" rel="noopener">webp-server-go</a> 项目的 docker 镜像。</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">//</span> <span class="string">Kubernetes</span> <span class="string">pod</span> <span class="string">template</span> <span class="string">to</span> <span class="string">run.</span></span><br><span class="line"><span class="string">def</span> <span class="string">JOB_NAME</span> <span class="string">=</span> <span class="string">"$&#123;env.JOB_NAME&#125;"</span></span><br><span class="line"><span class="string">def</span> <span class="string">BUILD_NUMBER</span> <span class="string">=</span> <span class="string">"$&#123;env.BUILD_NUMBER&#125;"</span></span><br><span class="line"><span class="string">def</span> <span class="string">POD_NAME</span> <span class="string">=</span> <span class="string">"jenkins-$&#123;JOB_NAME&#125;-$&#123;BUILD_NUMBER&#125;"</span></span><br><span class="line"><span class="string">podTemplate(</span></span><br><span class="line"><span class="comment"># 这里定义 pod 模版</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">&#123;</span> <span class="string">node(POD_NAME)</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="string">container(JOB_NAME)</span> <span class="string">&#123;</span></span><br><span class="line">      <span class="string">stage("Build</span> <span class="string">image")</span> <span class="string">&#123;</span></span><br><span class="line">        <span class="string">sh</span> <span class="string">""</span><span class="string">"#!/bin/bash</span></span><br><span class="line"><span class="string">          git clone https://github.com/webp-sh/webp_server_go /build</span></span><br><span class="line"><span class="string">          cd /build</span></span><br><span class="line"><span class="string">          docker build -t webps:0.3.2-rc.1 .</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">      <span class="string">&#125;</span></span><br><span class="line">    <span class="string">&#125;</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><ul><li>pod 模版如下，将模板的内容复制粘贴到上面的 Jenkinsfile 中。在容器中构建镜像，我们使用 dind 的方案：将 pod 所在宿主机的 docker sock 文件挂载到 pod 的容器内，pod 容器内只要安装好 docker-cli 工具就可以像宿主机那样直接使用 docker 了。</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">podTemplate(</span></span><br><span class="line">  <span class="attr">cloud:</span> <span class="string">"kubernetes"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">"default"</span><span class="string">,</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">POD_NAME,</span></span><br><span class="line">  <span class="attr">label:</span> <span class="string">POD_NAME,</span></span><br><span class="line">  <span class="attr">yaml:</span> <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Pod</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  containers:</span></span><br><span class="line"><span class="string">  - name: $&#123;JOB_NAME&#125;</span></span><br><span class="line"><span class="string">    image: "</span><span class="string">debian:buster-docker"</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">tty:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dockersock</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/var/run/docker.sock</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jnlp</span></span><br><span class="line">    <span class="attr">args:</span> <span class="string">["\$(JENKINS_SECRET)",</span> <span class="string">"\$(JENKINS_NAME)"</span><span class="string">]</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">"jenkins/inbound-agent:4.3-4-alpine"</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dockersock</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/var/run/docker.sock</span></span><br><span class="line"><span class="string">""</span><span class="string">",</span></span><br><span class="line"><span class="string">)</span></span><br></pre></td></tr></table></figure><ul><li>构建 <code>debian:buster-docker</code> 镜像，使用它来在 pod 的容器内构建 docker 镜像，使用的 <code>Dockerfile</code> 如下：</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> debian:buster</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt update \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apt install -y --no-install-recommends \</span></span><br><span class="line"><span class="bash">        vim \</span></span><br><span class="line"><span class="bash">        curl \</span></span><br><span class="line"><span class="bash">        git \</span></span><br><span class="line"><span class="bash">        make \</span></span><br><span class="line"><span class="bash">        ca-certificates \</span></span><br><span class="line"><span class="bash">        gnupg \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm -rf /var/lib/apt/lists/*</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> curl -fsSL <span class="string">"https://download.docker.com/linux/debian/gpg"</span> | apt-key add -qq - &gt;/dev/null \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">echo</span> <span class="string">"deb [arch=amd64] https://download.docker.com/linux/debian buster stable"</span> &gt; /etc/apt/sources.list.d/docker.list \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apt update -qq \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apt-get install -y -qq --no-install-recommends docker-ce-cli \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm -rf /var/lib/apt/lists/*</span></span><br></pre></td></tr></table></figure><p>定义好 jenkinsfile 文件并且构建好 pod 模板中的镜像后，接下来我们开始使用它来创建流水线任务。</p><h2 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h2><ul><li>在 Jenkins 上新建一个任务，选择任务的类型为 <code>流水线</code></li></ul><p><img src="https://p.k8s.li/image-20210306185651025.png" alt="image-20210306185651025"></p><ul><li>将定义好的 Jenkinsfile 内容复制粘贴到流水线定义 <code>Pipeline script</code> 中并点击保存。在新建好的 Job 页面点击 <code>立即构建</code> 来运行流水线任务。</li></ul><p><img src="https://p.k8s.li/image-20210306185838845.png" alt="image-20210306185838845"></p><ul><li>在 kubernetes 集群的机器上使用 kubectl 命令查看 pod 是否正常 Running</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@jenkins:~ <span class="comment"># kubectl get pod</span></span><br><span class="line">NAME                              READY   STATUS    RESTARTS   AGE</span><br><span class="line">jenkins-webps-9-bs78x-5x204   2/2     Running   0          66s</span><br></pre></td></tr></table></figure><ul><li>Job 正常运行并且状态为绿色表明该 job 已经成功执行了。</li></ul><p><img src="https://p.k8s.li/image-20210306190124096.png" alt="image-20210306190124096"></p><ul><li>在 kubernetes 集群机器上查看 docker 镜像是否构建成功</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@jenkins:~ <span class="comment"># docker images | grep webps</span></span><br><span class="line">webps                                0.3.2-rc.1          f68f496c0444        20 minutes ago      13.7MB</span><br></pre></td></tr></table></figure><h2 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h2><ul><li>pod 无法正常 Running</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Running <span class="keyword">in</span> Durability level: MAX_SURVIVABILITY</span><br><span class="line">[Pipeline] Start of Pipeline</span><br><span class="line">[Pipeline] podTemplate</span><br><span class="line">[Pipeline] &#123;</span><br><span class="line">[Pipeline] node</span><br><span class="line">Created Pod: kubernetes default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r][Scheduled] Successfully assigned default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r to jenkins</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r][Pulling] Pulling image <span class="string">"debian:buster"</span></span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r][Pulled] Successfully pulled image <span class="string">"debian:buster"</span> <span class="keyword">in</span> 2.210576896s</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r][Created] Created container debian</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r][Started] Started container debian</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r][Pulling] Pulling image <span class="string">"jenkins/inbound-agent:4.3-4-alpine"</span></span><br><span class="line">Still waiting to schedule task</span><br><span class="line">‘debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r’ is offline</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r][Pulled] Successfully pulled image <span class="string">"jenkins/inbound-agent:4.3-4-alpine"</span> <span class="keyword">in</span> 3.168311973s</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r][Created] Created container jnlp</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-9wm0r][Started] Started container jnlp</span><br><span class="line">Created Pod: kubernetes default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-qdw4m</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-qdw4m][Scheduled] Successfully assigned default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-qdw4m to jenkins</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-qdw4m][Pulled] Container image <span class="string">"debian:buster"</span> already present on machine</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-qdw4m][Created] Created container debian</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-qdw4m][Started] Started container debian</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-qdw4m][Pulled] Container image <span class="string">"jenkins/inbound-agent:4.3-4-alpine"</span> already present on machine</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-qdw4m][Created] Created container jnlp</span><br><span class="line">[Normal][default/debian-35a11b49-087b-4a8c-abac-bd97d7eb5a1f-fkmzq-qdw4m][Started] Started container jnlp</span><br></pre></td></tr></table></figure><p>这是因为 Jenkins pod 中的 jnlp 容器无法连接  Jenkins master。可以检查一下 Jenkins master 上 <code>系统管理 &gt; 节点管理 &gt; Configure Clouds</code> 中 <code>Jenkins 地址</code> 和 <code>Jenkins 通道</code> 这两个参数是否配置正确。</p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2><p>到此为止，我们就完成了让 Jenkins 大叔与 kubernetes 船长手牵手🧑‍🤝‍🧑啦！上面使用了一个简单的例子来展示了如何将 Jenkins 的 Job 任务运行在 kubernetes 集群上，但在实际工作中遇到的情形可能比这要复杂一些，流水线需要配置的参数也要多一些。那么我将会在下一篇博客中再讲一下高级的用法：使用 Jenkins 完成 kubespray 离线安装包打包。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><p><a href="https://jenkins-zh.cn/wechat/articles/2020/03/2020-03-10-create-a-ci-cd-pipeline-with-kubernetes-and-jenkins/" target="_blank" rel="noopener">使用 Kubernetes 和 Jenkins 创建一个 CI/CD 流水线</a></p></li><li><p><a href="https://www.qikqiak.com/k8s-book/docs/36.Jenkins%20Slave.html" target="_blank" rel="noopener">基于 Jenkins 的 CI/CD (一)</a></p></li><li><p><a href="https://a-wing.top/kubernetes/2021/01/27/jenkins_and_kubernetes.html" target="_blank" rel="noopener">PingCAP 面试：Jenkins 和 Kubernetes</a></p></li><li><p><a href="https://www.chenshaowen.com/blog/using-podman-to-build-images-under-kubernetes-and-jenkins.html" target="_blank" rel="noopener">基于 Kubernetes 的 Jenkins 服务也可以去 Docker 了</a></p></li><li><p><a href="https://www.chenshaowen.com/blog/jenkins-pipeline-usging-and-debug.html" target="_blank" rel="noopener">Jenkins Pipeline 使用及调试</a></p></li><li><p><a href="https://www.chenshaowen.com/blog/creating-jenkins-slave-dynamically-on-kubernetes.html" target="_blank" rel="noopener">在 Kubernetes 上动态创建 Jenkins Slave</a></p></li><li><p><a href="https://www.chenshaowen.com/blog/jenkins-x-is-not-jenkins-but-stack.html" target="_blank" rel="noopener">Jenkins X 不是 Jenkins ，而是一个技术栈</a></p></li><li><p><a href="https://atbug.com/using-role-based-authorization-strategy-in-jenkins/" target="_blank" rel="noopener">Jenkins CI/CD (一) 基于角色的授权策略</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot;
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://blog.k8s.li/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="kubernetes" scheme="https://blog.k8s.li/tags/kubernetes/"/>
    
      <category term="Jenkins" scheme="https://blog.k8s.li/tags/Jenkins/"/>
    
  </entry>
  
  <entry>
    <title>overlay2 在打包发布流水线中的应用</title>
    <link href="https://blog.k8s.li/overlay2-on-package-pipline.html"/>
    <id>https://blog.k8s.li/overlay2-on-package-pipline.html</id>
    <published>2021-03-01T16:00:00.000Z</published>
    <updated>2021-03-01T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>自从去年五月份入职后一直在负责公司 PaaS toB 产品的打包发布及部署运维工作，工作性质上有点类似于 Kubernetes 社区的 <a href="https://github.com/kubernetes/sig-release" target="_blank" rel="noopener">SIG Release  团队</a>。试用期的主要工作就是优化我们先有的打包发布流程。在这期间产品打包发布流水线做了很多优化，其中最突出的是镜像同步的优化，将镜像同步的速度提升了 5 到 15 倍。大大缩短了整个产品的发布耗时，也得到了同事们的一致好评。于是今天就想着把这项优化和背后的原理分享出来。</p><p>我们的产品打包时会有一个镜像列表，并根据这个镜像列表在 CI/CD 的流水线镜像仓库里将镜像同步到一个发布归档的镜像仓库和一个打包的镜像仓库。最终会将打包的镜像仓库的 registry 存储目录打包一个未经 gzip 压缩的 tar 包。最终在客户环境部署的时候将这个 tar 包解压到部署的镜像仓库存储目录中，供集群部署和组件部署使用。至于部署的时候为什么可以这样做，其中的原理可以参考我之前写过的文章 <a href="https://blog.k8s.li/docker-registry-to-harbor.html">docker registry 迁移至 harbor</a>。</p><p>在打包的过程中镜像同步会进行两次，每次都会根据一个 images.list 列表将镜像同步到不同的镜像仓库中，同步的方式使用的是  <code>docker pull –&gt; docker tag –&gt; docker push</code>。其镜像同步的流程如下图所示：</p><p><img src="https://p.k8s.li/2021-03-01-001.jpeg" alt="img"></p><p>第一次是从CI/CD 流水线镜像仓库（cicd.registry.local）中拉取镜像并 push 到发布归档的镜像仓库(archive.registry.local)中，其目的是归档并备份我们已经发布的镜像，这一步称其为保存备份同步（save sync）。</p><p>第二次将镜像从发布归档的镜像仓库 (archive.registry.local) 同步镜像到打包镜像仓库（package.registry.local）中。不同于第一次的镜像同步，这次同步镜像的时候会对镜像仓库做清理的操作，首先清理打包镜像仓库的存储目录，然后容器 registry 容器让 registry 重新提取镜像的元数据信息到内存中。其目的是清理旧数据，防止历史的镜像带入本次发布版本的安装包中。</p><p>镜像同步完成之后会将整个打包镜像仓库的存储目录（/var/lib/registry）打包成一个 tar 包，并放到产品安装包中。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>我刚入职的时候，我们的产品发布耗时最久的就是镜像同步阶段，记得最长的时候耗时 <code>2h30min</code>。耗时这么久的主要原因分析如下：</p><h3 id="docker-性能问题"><a href="#docker-性能问题" class="headerlink" title="docker 性能问题"></a>docker 性能问题</h3><p>在做镜像同步的时候使用的是  <code>docker pull –&gt; docker tag –&gt; docker push</code> 的方式。木子在<a href="https://blog.k8s.li/Exploring-container-image.html">《深入浅出容器镜像的一生》</a> 中分析过：在 docker pull 和 docker push 的过程中 docker 守护进程都会对镜像的 layer 做解压缩的操作，这是及其耗时和浪费 CPU 资源的。</p><p>又因为我们的内网机器的磁盘性能实在是太烂了，有时甚至连 USB 2.0 的速度（57MB/s）都不如！那慢的程度可想而知。这就导致了每次同步一两百个镜像时用时很久，最长的时候需要两个半小时。</p><h3 id="无法复用旧数据"><a href="#无法复用旧数据" class="headerlink" title="无法复用旧数据"></a>无法复用旧数据</h3><p>在第二次镜像同步时会对打包镜像仓库做清理的操作，导致无法复用历史的镜像。其实每次发布的时候，变更和新增的镜像很少，平均为原来的 1/10 左右，增量同步的镜像也就那么一丢丢。因为要保证这次打包发布的镜像仓库中只能包好这个需要的镜像，不能包含与本次无关的镜像，因此每次都需要清理打包镜像仓库，这无法避免。一直没有找到能够复用这些历史镜像的方法。</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>根据上面提到的两个问题，经过反复的研究和测试终于都完美地解决了，并将镜像同步从原来最长需要两个半小时优化到了平均五分钟。</p><h3 id="skopeo-替代-docker"><a href="#skopeo-替代-docker" class="headerlink" title="skopeo 替代 docker"></a>skopeo 替代 docker</h3><p>针对  <code>docker pull –&gt; docker tag –&gt; docker push</code>  的性能问题，当时第一个方案想到的就是使用 skopeo 来替代它。使用 <code>skopeo copy</code> 直接将镜像从一个 registry 复制到另一个 registry 中。这样可以避免 docker 守护进程对镜像的 layer 进行解压缩而带来的性能损耗。关于 skopeo 的使用和其背后的原理可以参考我之前的博客 <a href="https://blog.k8s.li/skopeo.html">镜像搬运工 skopeo 初体验</a> 。使用 skopeo 之后镜像同步比之前快了很多，平均快了 5 倍左右。</p><h3 id="overlay2-复用旧数据"><a href="#overlay2-复用旧数据" class="headerlink" title="overlay2 复用旧数据"></a>overlay2 复用旧数据</h3><p>解决了 docker 的性能问题，剩下的就是无法复用旧数据的问题了。在如何保留历史镜像的问题上可煞费苦心。<strong>当时也不知道为什么就想到了 overlay2 的特性</strong>：<code>写时复制</code>。就好比如 docker run 启动一个容器，在容器内进行修改和删除文件的操作，这些操作并不会影响到镜像本身。因为 docker 使用 overlay2 联合挂载的方式将镜像的每一层挂载为一个 merged 的层。在容器内看到的就是这个 merged 的层，在容器内对 merged 层文件的修改和删除操作是通过 overlay2 的 upper 层完成的，并不会影响到处在 lower 层的镜像本身。从 docker 官方文档 <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/" target="_blank" rel="noopener">Use the OverlayFS storage driver</a> 里偷来的一张图片：</p><p><img src="https://p.k8s.li/overlay_constructs.jpg" alt="img"></p><p>关于上图中这些 Dir 的作用，下面是一段从 <a href="https://stackoverflow.com/questions/56550890/docker-image-merged-diff-work-lowerdir-components-of-graphdriver" target="_blank" rel="noopener">StackOverflow</a> 上搬运过来的解释。如果想对 overlayfs 文件系统有详细的了解，可以参考 Linux 内核官网上的这篇文档 <a href="https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt" target="_blank" rel="noopener">overlayfs.txt</a> 。</p><blockquote><p><strong>LowerDir</strong>: these are the read-only layers of an overlay filesystem. For docker, these are the image layers assembled in order.</p><p><strong>UpperDir</strong>: this is the read-write layer of an overlay filesystem. For docker, that is the equivalent of the container specific layer that contains changes made by that container.</p><p><strong>WorkDir</strong>: this is a required directory for overlay, it needs an empty directory for internal use.</p><p><strong>MergedDir</strong>: this is the result of the overlay filesystem. Docker effectively chroot’s into this directory when running the container.</p></blockquote><p>总之 overlay2 大法好！根据 overlay2 的特性，我们可以将历史的数据当作 overlay2 里的 lowerdir 来使用。而 upperdir 则是本次镜像同步的增量数据，merged 则是最终实际需要的数据。</p><h2 id="overlay2"><a href="#overlay2" class="headerlink" title="overlay2"></a>overlay2</h2><p>虽然在上文中提到了使用 overlay2 的方案，但到目前为止还是没有一个成熟的解决方案。需要解决的问题如下：</p><ul><li><p>如何清理旧数据</p></li><li><p>如何复用历史的镜像？</p></li><li><p>如何区分出历史的镜像和本次的镜像？</p></li><li><p>如何保障本次镜像同步的结果只包含本次需要的镜像？</p></li></ul><h3 id="registry-存储结构"><a href="#registry-存储结构" class="headerlink" title="registry 存储结构"></a>registry 存储结构</h3><p>既然要使用历史的镜像仓库数据来作为 overlay2 的 lowerdir。那么如何解决之前提到的清理旧数据问题，以及如何使用历史的镜像的问题？那么还是需要再次回顾一下 registry 存储目录结构。</p><p><img src="https://p.k8s.li/registry-storage.jpeg" alt="img"></p><p>根据 registry 的存储结构可以得知：在 blobs 目录下保存的是镜像的 blob 的文件。blob 文件大体上有三种：镜像的 manifests；镜像的 image config 文件；以及镜像的 layer 层文件。其中 manifests 和 images config 文件都是 json 格式的文本文件，镜像的 layer 层文件则是经过压缩的 tar 包文件(一般为 gzip)。如果要复用历史的镜像，很大程度上复用的是镜像的 layer 层文件，因为这些文件是镜像当中最大的，在 docker pull 和 docker push 的时候就是对镜像的 layer 层文件进行解压缩的。</p><p>而且对于同一个镜像仓库来讲，blobs 下的文件都是由 repositories 下的 link 文件指向对应的 data 文件的。这就意味着，多个镜像可以使用相同的 layer。比如假如多个镜像的 base 镜像使用的都是  <code>debian:buster</code>，那么对于整个 registry 镜像仓库而言，只需要存一份 <code>debian:buster</code> 镜像即可。</p><p>同理，在使用历史的镜像时，我们是否可以只使用它的 layer 呢？这一点可能比较难理解 😂。我们使用下面这个例子来简单说明下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">k8s.gcr.io/kube-apiserver:v1.18.3</span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1.18.3</span><br><span class="line">k8s.gcr.io/kube-scheduler:v1.18.3</span><br><span class="line">k8s.gcr.io/kube-proxy:v1.v1.18.3</span><br></pre></td></tr></table></figure><p>当我们使用  skopeo copy 将这些镜像从 <code>k8s.gcr.io</code> 复制到本地的一个镜像仓库时，复制完第一个镜像后，在 copy 后面的镜像时都会提示 <code>Copying blob 83b4483280e5 skipped: already exists</code> 的日志信息。这是因为这些镜像使用的是同一个 base 镜像，这个 base 镜像只包含了一个 layer，也就是 <code>83b4483280e5</code> 这一个 blob 文件。虽然本地的镜像仓库中没有这些镜像的 base 镜像，但是有 base 镜像的 layer，skopeo 也就不会再 copy 这个相同的 blob。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">╭─root@sg-02 /home/ubuntu</span><br><span class="line">╰─<span class="comment"># skopeo copy docker://k8s.gcr.io/kube-apiserver:v1.18.3 docker://localhost/kube-apiserver:v1.18.3 --dest-tls-verify=false                                                     </span></span><br><span class="line">Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob 83b4483280e5 <span class="keyword">done</span></span><br><span class="line">Copying blob 2bfb66b13a96 <span class="keyword">done</span></span><br><span class="line">Copying config 7e28efa976 <span class="keyword">done</span></span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br><span class="line">╭─root@sg-02 /home/ubuntu</span><br><span class="line">╰─<span class="comment"># skopeo copy docker://k8s.gcr.io/kube-controller-manager:v1.18.3 docker://localhost/kube-controller-manager:v1.18.3 --dest-tls-verify=false</span></span><br><span class="line">Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob 83b4483280e5 skipped: already exists</span><br><span class="line">Copying blob 7a73c2c3b85e <span class="keyword">done</span></span><br><span class="line">Copying config da26705ccb <span class="keyword">done</span></span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br><span class="line">╭─root@sg-02 /home/ubuntu</span><br><span class="line">╰─<span class="comment"># skopeo copy docker://k8s.gcr.io/kube-scheduler:v1.18.3 docker://localhost/kube-scheduler:v1.18.3 --dest-tls-verify=false</span></span><br><span class="line">Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob 83b4483280e5 skipped: already exists</span><br><span class="line">Copying blob 133c4d2f432a <span class="keyword">done</span></span><br><span class="line">Copying config 76216c34ed <span class="keyword">done</span></span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br><span class="line">╭─root@sg-02 /home/ubuntu</span><br><span class="line">╰─<span class="comment"># skopeo copy docker://k8s.gcr.io/kube-proxy:v1.18.3 docker://localhost/kube-proxy:v1.18.3 --dest-tls-verify=false</span></span><br><span class="line">Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob 83b4483280e5 skipped: already exists</span><br><span class="line">Copying blob ffa39a529ef3 <span class="keyword">done</span></span><br><span class="line">Copying config 3439b7546f <span class="keyword">done</span></span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br></pre></td></tr></table></figure><p>从上面的实验我们可以得知，只要 registry 中存在相同的 blob，skopeo 就不会 copy 这个相同的 blob。那么如何让 skopeo 和 registry 知道存在这些 layer 了呢？</p><p>这时需要再次回顾以下 registry 存储结构。在 repositories 下，每个镜像的文件夹中都会有 <code>_layers</code> 这个目录，而这个目录下的内容正是指向镜像 layer 和 image config 的 link 文件。也就是说：只要某个镜像的 <code>_layers</code> 下有指向 blob 的 link 文件，并且该 link 文件指向的 blobs 下的 data 文件确实存在，那么在 push 镜像的时候 registry 就会向客户端返回该 blob 已经存在，而 skopeo 就会略过处理已经存在的 blob 。以此，我们就可以达到复用历史数据的目的。</p><p><img src="https://p.k8s.li/registry-storage.jpeg" alt="img"></p><p>在历史镜像仓库文件中：blobs 目录是全部都要的； repositories 目录下只需要每个镜像的 <code>_layers</code> 目录即可；<code>_manifests</code> 目录下是镜像的 tag 我们并不需要他们； <code>_uploads</code> 目录则是 push 镜像时的临时目录也不需要。那么我们最终需要的历史镜像仓库中的文件就如下图所示：</p><p><img src="https://p.k8s.li/2021-03-01_09-18-19.jpg" alt="img"></p><p>到此为止已经解决掉了如何清理旧数据和如何如何复用历史的镜像的问题了。接下来要做的如何使用 overlay2  去构建这个镜像仓库所需的文件系统了。</p><h3 id="套娃：镜像里塞镜像？"><a href="#套娃：镜像里塞镜像？" class="headerlink" title="套娃：镜像里塞镜像？"></a>套娃：镜像里塞镜像？</h3><p>提到 overlay2 第一个想到的方案就是容器镜像：使用套娃的方式，将历史的镜像仓库存储目录复制到一个 registry 的镜像里，然后用这个镜像来启动打包镜像仓库的 registry 容器。这个镜像仓库的 <code>Dockerfile</code> 如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> registry:latest</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将历史镜像仓库的目录打包成 tar 包，放到 registry 的镜像中， ADD 指令会自动解开这个 tar 包</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> docker.tar /var/lib/registry/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除掉所有镜像的 _manifests 目录，让 registry 认为里面没有镜像只有 blobs 数据</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> find /var/lib/registry/docker/registry/v2/repositories -<span class="built_in">type</span> d -name <span class="string">"_manifests"</span> -<span class="built_in">exec</span> rm -rf &#123;&#125; \;</span></span><br></pre></td></tr></table></figure><ul><li>然后使用这个 <code>Dockerfile</code> 构建一个镜像，并命名为 <code>registry:v0.1.0-base</code> ，使用这个镜像来 docker run 一个容器。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name registry -p 127.0.0.1:443:5000 registry:v0.1.0-base</span><br></pre></td></tr></table></figure><ul><li>接着同步镜像</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat images.list | xargs -L1 -I &#123;&#125; skopeo copy  docker://cidi.registry.local/&#123;&#125; docker://package.registry.local/&#123;&#125;</span><br></pre></td></tr></table></figure><ul><li>同步完成镜像之后，需要删除掉 repositories 下没有生成 _manifests 目录的镜像。因为如果本次同步镜像有该镜像的话，会在 repositories 目录下重新生成 _manifests 目录，如果没有生成的话就说明本次同步的列表中不包含该镜像。以此可以解决如何区分出历史的镜像和本次的镜像的问腿，这样又能何保障本次镜像同步的结果只包含本次需要的镜像。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> project <span class="keyword">in</span> $(ls repositories/); <span class="keyword">do</span></span><br><span class="line">  <span class="keyword">for</span> image <span class="keyword">in</span> $(ls repositories/<span class="variable">$&#123;project&#125;</span>); <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> [[ ! -d <span class="string">"repositories/<span class="variable">$&#123;project&#125;</span>/<span class="variable">$&#123;image&#125;</span>/_manifests"</span> ]]; <span class="keyword">then</span></span><br><span class="line">    rm -rf repositories/<span class="variable">$&#123;project&#125;</span>/<span class="variable">$&#123;image&#125;</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><ul><li>最后还需要使用 registry GC 来删除掉 blobs 目录下没有被引用的文件。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it registry registry garbage-collect /etc/docker/registry/config.yml</span><br></pre></td></tr></table></figure><ul><li>再使用 docker cp 的方式将镜像从容器里复制出来并打包成一个 tar 包</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker cp registry:/var/lib/registry/docker docker</span><br><span class="line">tar -cf docker.tar docker</span><br></pre></td></tr></table></figure><p>使用这种办法做了一下简单的测试，因为使用 skopeo copy 镜像的时候会提示很多 blobs 已经存在了，所以实际上复制的镜像只是一小部分，性能上的确比之前快了很多。但是这种方案也存在很多的弊端：一是这个 registry 的镜像需要手动维护和构建；二是使用 docker cp 的方式将容器内的 registry 存储目录复制到容器宿主机，性能上有点差；三是不同的产品需要不同的 base 镜像，维护起来比较麻烦。所以我们还需要更为简单一点使用 overlay2 技术。</p><h3 id="容器挂载-overlay2-merged-目录"><a href="#容器挂载-overlay2-merged-目录" class="headerlink" title="容器挂载 overlay2 merged 目录"></a>容器挂载 overlay2 merged 目录</h3><p>仔细想一下，将历史的镜像数据放到 registry 镜像中，用它来启动一个 registry 容器。同步镜像和进行 registry gc 这两部实际上是对 overlay2 的 merged 层进行读写删除操作。那我们为何不直接在宿主机上创建好 overlay2 需要的目录，然后再使用 overlay2 联合挂载的方式将这些目录挂载为一个 merged 目录。在启动 registry 容器的时候通过 <code>docker run -v</code> 参数将这个 merged 目录以 bind 的方式挂载到 registry 容器内呢？下面我们就做一个简单的验证和测试：</p><ul><li>首先创建 overlay2 需要的目录</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /var/lib/registry</span><br><span class="line">mkdir -p lower upper work merged</span><br></pre></td></tr></table></figure><ul><li>将历史镜像仓库数据放到 lower 目录内</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -cf docker.tar -C /var/lib/registry/lower</span><br></pre></td></tr></table></figure><ul><li>删除 所有镜像的 _manifests 目录，让 registry 认为里面没有镜像只有 blobs 数据</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find /var/lib/registry/lower/docker/registry/v2/repositories -<span class="built_in">type</span> d -name <span class="string">"_manifests"</span> -<span class="built_in">exec</span> rm -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure><ul><li>模拟容器的启动，使用 overlay2 联合挂载为一层 merged 层</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount -t overlay overlay -o lowerdir=lower,upperdir=upper,workdir=work merged</span><br></pre></td></tr></table></figure><ul><li>docker run 启动一个 registry ，并将 merged 目录挂载到容器内的 <code>/var/lib/registry/docker</code> 目录</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -name registry -p 127.0.0.1:443:5000 \</span><br><span class="line">-v /var/lib/registry/merged/docker:/var/lib/registry/docker</span><br></pre></td></tr></table></figure><ul><li>同步镜像，将本次发布需要的镜像同步到 registry 中</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat images.list | xargs -L1 -I &#123;&#125; skopeo copy --insecure-policy --src-tls-verify=<span class="literal">false</span> --dest-tls-verify=<span class="literal">false</span> docker://cicd.registry.local/&#123;&#125; docker://package.registry.local/&#123;&#125;</span><br></pre></td></tr></table></figure><ul><li>同步完成镜像后，进行 registry gc ，删除无用的 blob 数据</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it registry registry garbage-collect /etc/docker/registry/config.yml</span><br></pre></td></tr></table></figure><ul><li>最后打包 merged 目录，就是本次最终的结果</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /var/lib/registry/merged</span><br><span class="line">tar -cf docker.tar docker</span><br></pre></td></tr></table></figure><p>在本地按照上述步骤进行了简单的验证，确实可以！在第二次同步镜像的时候会提示很多 blob 已经存在，镜像同步的速度比之前又快了 5 倍左右。那么将上述步骤写成一个脚本就能反复使用了。</p><h3 id="registry-gc-问题-？"><a href="#registry-gc-问题-？" class="headerlink" title="registry gc 问题 ？"></a>registry gc 问题 ？</h3><p>在使用的过程中遇到过 registry GC 清理不干净的问题：在进行 GC 之后，一些镜像 layer 和 config 文件已经在 blobs 存储目录下删除了，但指向它的 link 文件依旧保存在 repositories 目录下🙄。GitHub 上有个 PR <a href="https://github.com/docker/distribution/issues/2288" target="_blank" rel="noopener">Remove the layer’s link by garbage-collect #2288</a> 就是专门来清理这些无用的 layer link 文件的，最早的一个是三年前的，但是还没有合并😂。</p><p>解决办法就是使用我在 <a href="https://blog.k8s.li/registry-gc.html">docker registry GC 原理分析</a> 文章中提到的方案：自制 registry GC 脚本🙃。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">v2=<span class="variable">$1</span></span><br><span class="line">v2=<span class="variable">$&#123;v2:="/var/lib/registry/docker/registry/v2"&#125;</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;v2&#125;</span></span><br><span class="line">all_blobs=/tmp/all_blobs.list</span><br><span class="line">: &gt; <span class="variable">$&#123;all_blobs&#125;</span></span><br><span class="line"><span class="comment"># delete unlink blob's link file in _layers</span></span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> $(find repositories -<span class="built_in">type</span> f -name <span class="string">"link"</span> | grep -E <span class="string">"_layers\/sha256\/.*"</span>); <span class="keyword">do</span></span><br><span class="line">    link_sha256=$(<span class="built_in">echo</span> <span class="variable">$&#123;link&#125;</span> | grep -Eo <span class="string">"_layers\/sha256\/.*"</span> | sed <span class="string">'s/_layers\/sha256\///g;s/\/link//g'</span>)</span><br><span class="line">    link_short=<span class="variable">$&#123;link:0:2&#125;</span></span><br><span class="line">    link_dir=$(<span class="built_in">echo</span> <span class="variable">$&#123;link&#125;</span> | sed <span class="string">'s/\/link//'</span>)</span><br><span class="line">    data_file=blobs/sha256/<span class="variable">$&#123;link_short&#125;</span>/<span class="variable">$&#123;link&#125;</span></span><br><span class="line">    <span class="keyword">if</span> [[ ! -d <span class="variable">$&#123;data_file&#125;</span> ]]; <span class="keyword">then</span> rm -rf <span class="variable">$&#123;link_dir&#125;</span>; <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment">#marking all the blob by all images manifest</span></span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> $(find repositories -name <span class="string">"link"</span> | grep current); <span class="keyword">do</span></span><br><span class="line">    link=$(cat <span class="variable">$&#123;tag&#125;</span> | cut -c8-71)</span><br><span class="line">    mfs=blobs/sha256/<span class="variable">$&#123;link:0:2&#125;</span>/<span class="variable">$&#123;link&#125;</span>/data</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;link&#125;</span> &gt;&gt; <span class="variable">$&#123;all_blobs&#125;</span></span><br><span class="line">    grep -Eo <span class="string">"\b[a-f0-9]&#123;64&#125;\b"</span> <span class="variable">$&#123;mfs&#125;</span> | sort -n | uniq | cut -c1-12 &gt;&gt; <span class="variable">$&#123;all_blobs&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment">#delete blob if the blob doesn't exist in all_blobs.list</span></span><br><span class="line"><span class="keyword">for</span> blob <span class="keyword">in</span> $(find blobs -name <span class="string">"data"</span> | cut -d <span class="string">"/"</span> -f4); <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> ! grep <span class="variable">$&#123;blob&#125;</span> <span class="variable">$&#123;all_blobs&#125;</span>; <span class="keyword">then</span></span><br><span class="line">        rm -rf blobs/sha256/<span class="variable">$&#123;blob:0:2&#125;</span>/<span class="variable">$&#123;blob&#125;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>好了，至此最终的优化方案已经定下来了，其流程上如下：</p><p><img src="https://p.k8s.li/2021-03-01-002.jpeg" alt="img"></p><ul><li>第一次同步镜像的时候不再将镜像同步归档备份的镜像仓库（archive.registry.local） 而是同步到 overlay2 的镜像仓库，这个镜像仓库中的镜像将作为第二次镜像同步的 lower 层。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat images.list | xargs -L1 -I &#123;&#125; skopeo copy --insecure-policy --src-tls-verify=<span class="literal">false</span> --dest-tls-verify=<span class="literal">false</span> docker://cicd.registry.local/&#123;&#125; docker://overlay2.registry.local/&#123;&#125;</span><br></pre></td></tr></table></figure><ul><li>第一次镜像同步完成之后，先清理掉 overlay2 的 merged、upper、work 这三层，只保留 lower 层。因为 lower 层里保留着第一次镜像同步的结果。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">umount /var/lib/registry/merged</span><br><span class="line">rm -rf /var/lib/registry/&#123;merged,upper,work&#125;</span><br></pre></td></tr></table></figure><ul><li>接下来就是使用 mount 挂载 overlay2，挂载完成之后进入到 merged 层删除掉所有的 _manifests 目录</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mount -t overlay overlay -o lowerdir=lower,upperdir=upper,workdir=work merged</span><br><span class="line"><span class="built_in">cd</span> /var/lib/registry/merged</span><br><span class="line">find registry/v2/repositories -<span class="built_in">type</span> d -name <span class="string">"_manifests"</span> -<span class="built_in">exec</span> rm -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure><ul><li>接着进行第二次的镜像同步，这一次的同步目的是重新建立  _manifests 目录</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat images.list | xargs -L1 -I &#123;&#125; skopeo copy --insecure-policy --src-tls-verify=<span class="literal">false</span> --dest-tls-verify=<span class="literal">false</span> docker://overlay2.registry.local/&#123;&#125; docker://package.registry.local/&#123;&#125;</span><br></pre></td></tr></table></figure><ul><li>第二次同步完成之后再使用自制的 registry GC 脚本来删除不必要的 blob 文件和 link 文件。</li><li>最后将镜像仓库存储目录打包就得到了本次需要的镜像啦。</li></ul><h2 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h2><p>虽然比之前的流程复杂了很多，但优化的结果是十分明显，比以往快了 5 到 15 倍，并在我们的生产环境中已经稳稳地使用了大半年。</p><p>读完这篇文章可能你会觉得一头雾水，不知道究竟在讲什么。什么镜像同步、镜像 blob、layer、overlay2、联合挂载、写时复制等等，被这一堆复杂的背景和概念搞混了😂。本文确实不太好理解，因为背景可能较特殊和复杂，很少人会遇到这样的场景。为了很好地理解本文所讲到的内容和背后的原理，过段时间我会单独写一篇博客，通过最佳实践来理解本文提到的技术原理。敬请期待😝</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><h3 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h3><ul><li><a href="https://github.com/containers/image" target="_blank" rel="noopener">image</a></li><li><a href="https://github.com/opencontainers/image-spec" target="_blank" rel="noopener">OCI Image Manifest Specification</a></li><li><a href="https://github.com/opencontainers/distribution-spec" target="_blank" rel="noopener">distribution-spec</a></li><li><a href="https://doi-janky.infosiftr.net/job/tianon/job/debuerreotype/" target="_blank" rel="noopener">debuerreotype/</a></li><li><a href="https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt" target="_blank" rel="noopener">overlayfs.txt</a></li></ul><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><ul><li><a href="http://open.daocloud.io/allen-tan-docker-xi-lie-zhi-tu-kan-jin-docker-rong-qi-wen-jian-xi-tong/" target="_blank" rel="noopener">看尽 docker 容器文件系统</a></li><li><a href="https://supereagle.github.io/2018/04/24/docker-registry/" target="_blank" rel="noopener">镜像仓库中镜像存储的原理解析</a></li><li><a href="https://segmentfault.com/a/1190000014284289" target="_blank" rel="noopener">Docker镜像的存储机制</a></li></ul><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><ul><li><a href="https://blog.k8s.li/Exploring-container-image.html">深入浅出容器镜像的一生🤔</a></li><li><a href="https://blog.k8s.li/skopeo.html">镜像搬运工 skopeo 初体验</a></li><li><a href="https://blog.k8s.li/mount-bind.html">mount 命令之 –bind 挂载参数</a></li><li><a href="https://blog.k8s.li/registry-gc.html">docker registry GC 原理分析</a></li><li><a href="https://blog.k8s.li/docker-registry-to-harbor.html">docker registry 迁移至 harbor</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot;
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://blog.k8s.li/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="registry" scheme="https://blog.k8s.li/tags/registry/"/>
    
      <category term="images" scheme="https://blog.k8s.li/tags/images/"/>
    
  </entry>
  
  <entry>
    <title>同步 docker hub library 镜像到本地 registry</title>
    <link href="https://blog.k8s.li/sync-dockerhub-library-images.html"/>
    <id>https://blog.k8s.li/sync-dockerhub-library-images.html</id>
    <published>2021-02-09T16:00:00.000Z</published>
    <updated>2021-02-15T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="恰烂钱？"><a href="#恰烂钱？" class="headerlink" title="恰烂钱？"></a>恰烂钱？</h2><p>自从去年 11 月份开始，docker 公司为了恰点烂钱就对 docker hub 上 pull 镜像的策略进行限制：</p><ul><li><strong>未登录用户，每 6 小时只允许 pull 100 次</strong></li><li><strong>已登录用户，每 6 小时只允许 pull 200 次</strong></li></ul><p>而且，限制的手段也非常地粗暴，通过判断请求镜像的 manifest 文件的次数，请求一个镜像的 manifest 文件就算作一次 pull 镜像。即便你 pull 失败了，也会算作一次。</p><p>随后也有很多大佬分享绕过 docker hub 限制的办法，比如搭建私有的镜像仓库，然后再给客户端配置上 <code>registry-mirrors</code> 参数，就可以通过本地的镜像仓库来拉取镜像。</p><ul><li><a href="https://moelove.info/2020/09/20/%E7%AA%81%E7%A0%B4-DockerHub-%E9%99%90%E5%88%B6%E5%85%A8%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F%E6%9C%8D%E5%8A%A1/" target="_blank" rel="noopener">突破 DockerHub 限制，全镜像加速服务</a></li><li><a href="https://nova.moe/bypass-docker-hub-429/" target="_blank" rel="noopener">绕过从 Docker Hub pull 镜像时的 429 toomanyrequests</a></li><li><a href="https://www.chenshaowen.com/blog/how-to-cross-the-limit-of-dockerhub.html" target="_blank" rel="noopener">如何绕过 DockerHub 拉取镜像限制</a></li></ul><p>但是呢，以上方法都比较局限：首先镜像需要挨个手动 push 到本地镜像仓库；其次本地镜像仓库中的镜像无法和官方镜像保持同步更新，如果要使用新的 tag 好的镜像仍然需要手动将镜像从 docker hub 上 pull 下来，然后再 push 到本地镜像仓库；还有手动 push 镜像是比较混乱的，如果使用的镜像比较多，比如公有云容器服务，这时候再手动 push 的话管理起来是及其不方便的。</p><p>因此经过一番折腾终于摸索出了一个方案：将 docker hub 上 library repo 的镜像同步到本地镜像仓库，最终要做到上游如果更新了镜像 tag 也能自动地将镜像同步到本地镜像仓库。</p><h2 id="获取镜像-tag"><a href="#获取镜像-tag" class="headerlink" title="获取镜像 tag"></a>获取镜像 tag</h2><p>对于 docker hub 上的镜像，我们使用到最多的就是 library 这个 repo 即 <a href="https://docs.docker.com/docker-hub/official_images/" target="_blank" rel="noopener">Official Images on Docker Hub</a>，里面包含着大部分开源软件和 Linux 发行版的基础镜像。</p><blockquote><ul><li>Provide essential base OS repositories (for example, <a href="https://hub.docker.com/_/ubuntu/" target="_blank" rel="noopener">ubuntu</a>, <a href="https://hub.docker.com/_/centos/" target="_blank" rel="noopener">centos</a>) that serve as the starting point for the majority of users.</li><li>Provide drop-in solutions for popular programming language runtimes, data stores, and other services, similar to what a Platform as a Service (PAAS) would offer.</li><li>Exemplify <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/" target="_blank" rel="noopener"><code>Dockerfile</code> best practices</a> and provide clear documentation to serve as a reference for other <code>Dockerfile</code> authors.</li><li>Ensure that security updates are applied in a timely manner. This is particularly important as Official Images are some of the most popular on Docker Hub.</li></ul></blockquote><p>library 的镜像常见的特点就是当我们使用 docker 客户端去 pull 一个镜像时，无需指定该镜像的 repo ，比如 <code>ubuntu:latest</code>，其他非 library 的镜像需要指定镜像所属的 repo ，比如 <code>jenkins/slave:latest</code>。这部分代码是硬编码在 docker 的源码当中的。</p><blockquote><p>我们虽然日常访问的是 <code>https://hub.docker.com</code> ，但是我们在 <a href="https://github.com/docker/distribution/blob/master/reference/normalize.go#L13" target="_blank" rel="noopener">https://github.com/docker/distribution/blob/master/reference/normalize.go#L13</a> 中可以看到实际 <code>docker</code> 使用的地址是一个硬编码的 <code>docker.io</code></p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">legacyDefaultDomain = <span class="string">"index.docker.io"</span></span><br><span class="line">defaultDomain       = <span class="string">"docker.io"</span></span><br><span class="line">officialRepoName    = <span class="string">"library"</span></span><br><span class="line">defaultTag          = <span class="string">"latest"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></blockquote><p>我们可以通过如下几种办法来获取 docker hub 上 library repo 的镜像列表。</p><h3 id="通过-docker-registry-命令行"><a href="#通过-docker-registry-命令行" class="headerlink" title="通过 docker registry 命令行"></a>通过 docker registry 命令行</h3><p>在 docker 官方文档中 <a href="https://docs.docker.com/engine/reference/commandline/registry/" target="_blank" rel="noopener">docker registry</a> 有提到可以列出某个 registry 中的镜像，但这个功能仅限于 <a href="https://docs.docker.com/ee/supported-platforms/" target="_blank" rel="noopener">Docker Enterprise Edition.</a> 版本，而社区的版本中未有该命令。遂放弃……</p><blockquote><p>This command is only available on Docker Enterprise Edition.</p><p>Learn more about <a href="https://docs.docker.com/ee/supported-platforms/" target="_blank" rel="noopener">Docker Enterprise products</a>.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker registry ls <span class="comment"># List registry images</span></span><br></pre></td></tr></table></figure><h3 id="通过-registry-v2-API"><a href="#通过-registry-v2-API" class="headerlink" title="通过 registry v2 API"></a>通过 registry v2 API</h3><ul><li><code>get-images.list</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">set</span> -eo pipefail</span><br><span class="line"></span><br><span class="line">DOCKER_HUB_URL=<span class="string">"https://hub.docker.com/v2/repositories/library"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">get_images_list</span></span>() &#123;</span><br><span class="line">    ALL_IMAGES=<span class="string">""</span></span><br><span class="line">    URL=<span class="string">"<span class="variable">$&#123;DOCKER_HUB_URL&#125;</span>/?page_size=100"</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">true</span> ; <span class="keyword">do</span></span><br><span class="line">        ALL_IMAGES=<span class="string">"<span class="variable">$(curl -sSL $&#123;URL&#125; | jq -r '.results[].name' | tr '\n' ' ')</span> <span class="variable">$&#123;ALL_IMAGES&#125;</span>"</span></span><br><span class="line">        URL=<span class="string">"<span class="variable">$(curl -sSL $&#123;URL&#125; | jq -r '.next')</span>"</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;URL&#125;</span>"</span> = <span class="string">"null"</span> ]; <span class="keyword">then</span> <span class="built_in">break</span>; <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">    : &gt; all_library_images.list</span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> <span class="variable">$&#123;ALL_IMAGES&#125;</span>;<span class="keyword">do</span></span><br><span class="line">        <span class="keyword">if</span> skopeo list-tags docker://<span class="variable">$&#123;image&#125;</span> &amp;&gt; /dev/null; <span class="keyword">then</span></span><br><span class="line">            skopeo list-tags docker://<span class="variable">$&#123;image&#125;</span> | jq <span class="string">".Tags"</span> | tr -d <span class="string">'[],\" '</span> | tr -s <span class="string">'\n'</span> | sed <span class="string">"s|^|<span class="variable">$&#123;image&#125;</span>:|g"</span> &gt;&gt; all_library_images.list</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line">get_images_list</span><br></pre></td></tr></table></figure><p>通过 docker hub 的  API 获取到的镜像 tag 实在是太多了，截至今日 docker hub 上整个 <a href="https://hub.docker.com/u/library" target="_blank" rel="noopener">library repo</a> 的项目一共有 162 个，而这 162 个项目中的镜像 tag 数量多达<strong>五万两千</strong>多个。总的镜像仓库存储占用空间的大小预计至少 5TB 。其中的镜像我们真正需要用到的估计也不到 <strong>0.1%</strong>，因此需要想个办法减少这个镜像列表的数量，获得的镜像列表更精确一些，通用一些。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">╭─root@sg-02 /opt/official-images ‹sync*›</span><br><span class="line">╰─<span class="comment"># cat all_library_images.list|cut -d ':' -f1 | sort -u | wc</span></span><br><span class="line">    162     162    1353</span><br><span class="line">╭─root@sg-02 /opt/official-images ‹sync*›</span><br><span class="line">╰─<span class="comment"># cat all_library_images.list | wc</span></span><br><span class="line">  52094   52094 1193973</span><br></pre></td></tr></table></figure><h3 id="通过-official-images-repo"><a href="#通过-official-images-repo" class="headerlink" title="通过 official-images repo"></a>通过 official-images repo</h3><p>以 <a href="https://hub.docker.com/_/debian" target="_blank" rel="noopener">debian</a> 为例，在 docker hub 上镜像的 tag 基本上都是这样子的：</p><blockquote><p><strong>Supported tags and respective <code>Dockerfile</code> links</strong></p><ul><li><a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/bullseye/Dockerfile" target="_blank" rel="noopener"><code>bullseye</code>, <code>bullseye-20210208</code></a></li><li><a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/bullseye/backports/Dockerfile" target="_blank" rel="noopener"><code>bullseye-backports</code></a></li><li><a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/bullseye/slim/Dockerfile" target="_blank" rel="noopener"><code>bullseye-slim</code>, <code>bullseye-20210208-slim</code></a></li><li><a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/buster/Dockerfile" target="_blank" rel="noopener"><code>buster</code>, <code>buster-20210208</code>, <code>10.8</code>, <code>10</code>, <code>latest</code></a></li><li><a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/buster/backports/Dockerfile" target="_blank" rel="noopener"><code>buster-backports</code></a></li><li><a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/buster/slim/Dockerfile" target="_blank" rel="noopener"><code>buster-slim</code>, <code>buster-20210208-slim</code>, <code>10.8-slim</code>, <code>10-slim</code></a></li><li><a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/experimental/Dockerfile" target="_blank" rel="noopener"><code>experimental</code>, <code>experimental-20210208</code></a></li><li><a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/jessie/Dockerfile" target="_blank" rel="noopener"><code>jessie</code>, <code>jessie-20210208</code>, <code>8.11</code>, <code>8</code></a></li><li><a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/jessie/slim/Dockerfile" target="_blank" rel="noopener"><code>jessie-slim</code>, <code>jessie-20210208-slim</code>, <code>8.11-slim</code>, <code>8-slim</code></a></li></ul></blockquote><p>每一行都代表着同一个镜像，如： <a href="https://github.com/debuerreotype/docker-debian-artifacts/blob/b05117a87fbd32f977b4909e399fe368c75767ad/buster/Dockerfile" target="_blank" rel="noopener"><code>buster</code>, <code>buster-20210208</code>, <code>10.8</code>, <code>10</code>, <code>latest</code></a> 。一行中镜像虽然有多个 tag，但这些 tag 指向的 manifest 其实都是一致的。镜像 tag 的关系有点类似于 C 语言里的指针变量，是引用的关系。</p><p>但这么多的信息是如何高效地管理的呢？于是顺藤摸瓜发现了：由于 library repo 里的镜像构建信息都是由 <a href="https://github.com/docker-library/official-images" target="_blank" rel="noopener">official-images</a> 这个 repo 来管理的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># buster -- Debian 10.8 Released 06 February 2021</span></span><br><span class="line">Tags: buster, buster-20210208, 10.8, 10, latest</span><br><span class="line">Architectures: amd64, arm32v5, arm32v7, arm64v8, i386, mips64le, ppc64le, s390x</span><br><span class="line">Directory: buster</span><br><span class="line"></span><br><span class="line">Tags: buster-backports</span><br><span class="line">Architectures: amd64, arm32v5, arm32v7, arm64v8, i386, mips64le, ppc64le, s390x</span><br><span class="line">Directory: buster/backports</span><br><span class="line"></span><br><span class="line">Tags: buster-slim, buster-20210208-slim, 10.8-slim, 10-slim</span><br><span class="line">Architectures: amd64, arm32v5, arm32v7, arm64v8, i386, mips64le, ppc64le, s390x</span><br><span class="line">Directory: buster/slim</span><br></pre></td></tr></table></figure><p>在这个 <a href="https://github.com/docker-library/official-images" target="_blank" rel="noopener">official-images</a>  repo 里  library 目录下有以镜像 name 命名的文件，而文件的内容正是记录着与 docker hub 相对应的 tag 信息。由此我们可以根据这个 repo 获取 library repo 镜像的 tag。好处在于虽然这样得到的镜像列表并不是全面的，但这个 repo 里记录的镜像 tag 都是官方还在维护的，并不会包含一些旧的或者 CI 测试的镜像。这样获得的镜像列表更通用一些。</p><p>拿出 Linux 文本处理三剑客，一顿操作搓出了个脚本来生成镜像以及镜像的数量。惊奇的发现，通过这种方式获取到的镜像数量为 docker hub 的 registry API 获取到的镜像数量的十分之一左右。根据如下数据可以得出，docker hub 真实需要的镜像数量为 1517 个，而 5590 个镜像中包含了多个 tag 指向同一个镜像的情况，因此，我们只需要将这些相同镜像的 tag pull 一次即可，其余的镜像通过 retag 的方式打上 tag 即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取镜像列表</span></span><br><span class="line">$ grep -Er <span class="string">"^Tags:|^SharedTags:"</span> library | sed <span class="string">'s|library/||g;s|:Tags||g;s|:SharedTags||g;s| ||g'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取镜像数量，也就是 manifests 的数量</span></span><br><span class="line">$ grep -Er <span class="string">"^Tags:|^SharedTags:"</span> library | sed <span class="string">'s|library/||g;s|:Tags||g;s|:SharedTags||g;s| ||g'</span> | wc</span><br><span class="line">   1518    1518   95999</span><br><span class="line"><span class="comment"># 获取所有镜像 tag 数量，包含了所有的 tag</span></span><br><span class="line">$ grep -Er <span class="string">"^Tags:|^SharedTags:"</span> library | sed <span class="string">'s|library/||g;s|:Tags||g;s|:SharedTags||g;s| ||g'</span> | tr <span class="string">','</span> <span class="string">'\n'</span> | wc</span><br><span class="line">   5590    5590   95999</span><br></pre></td></tr></table></figure><h2 id="本地同步镜像"><a href="#本地同步镜像" class="headerlink" title="本地同步镜像"></a>本地同步镜像</h2><p>获取到镜像列表之后，我们就可用使用 <a href="https://github.com/containers/skopeo/blob/master/docs/skopeo-copy.1.md" target="_blank" rel="noopener">skopeo copy</a> 直接将镜像 copy 到本地的镜像仓库中啦。结合上述步骤，使用不到 20 行的脚本就能完成：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ALL_IMAGES=$(grep -Er <span class="string">"^Tags:|^SharedTags:"</span> library \</span><br><span class="line">| sed <span class="string">'s|library/||g;s|:Tags||g;s|:SharedTags||g;s| ||g'</span>)</span><br><span class="line">IFS=$<span class="string">'\n'</span></span><br><span class="line"><span class="keyword">for</span> image <span class="keyword">in</span> <span class="variable">$&#123;ALL_IMAGES&#125;</span>; <span class="keyword">do</span></span><br><span class="line">    name=<span class="string">"<span class="variable">$(echo $&#123;image&#125; | cut -d ':' -f1)</span>"</span></span><br><span class="line">    tags=<span class="string">"<span class="variable">$(echo $&#123;image&#125; | cut -d ':' -f2 | cut -d ',' -f1)</span>"</span></span><br><span class="line">    <span class="keyword">if</span> skopeo copy docker://<span class="variable">$&#123;name&#125;</span>:<span class="variable">$&#123;tags&#125;</span> docker://registry.local/library/<span class="variable">$&#123;name&#125;</span>:<span class="variable">$&#123;tags&#125;</span>; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">for</span> tag <span class="keyword">in</span> $(<span class="built_in">echo</span> <span class="variable">$&#123;image&#125;</span> | cut -d <span class="string">':'</span> -f2 | tr <span class="string">','</span> <span class="string">'\n'</span>); <span class="keyword">do</span></span><br><span class="line">        skopeo copy docker://<span class="variable">$&#123;name&#125;</span>:<span class="variable">$&#123;tag&#125;</span> docker://registry.local/library/<span class="variable">$&#123;name&#125;</span>:<span class="variable">$&#123;tags&#125;</span>;</span><br><span class="line">     <span class="keyword">done</span></span><br><span class="line">     <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>但，没我想象中的那么简单，在自己的机器上 pull 了不到 150 个镜像的时候就报错退出了，提示 <code>toomanyrequests: You have reached your pull rate limit.</code> 错误。心里 mmp，docker inc 啊，干啥啥不行（如今 Docker Machine，Docker Swarm，docker-compose 三驾马车哪儿去了？），<strong>恰烂钱可还行</strong>😡。</p><blockquote><p>ime=”2021-02-12T07:08:51Z” level=fatal msg=”Error parsing image name &quot;docker://ubuntu:latest&quot;:</p><p>Error reading manifest latest in docker.io/library/ubuntu: toomanyrequests: You have reached your pull rate limit. You may increase the limit by authenticating and upgrading: <a href="https://www.docker.com/increase-rate-limit&quot;" target="_blank" rel="noopener">https://www.docker.com/increase-rate-limit&quot;</a></p></blockquote><h2 id="Dockerfile-里同步镜像？"><a href="#Dockerfile-里同步镜像？" class="headerlink" title="Dockerfile 里同步镜像？"></a>Dockerfile 里同步镜像？</h2><p>既然在本地有 pull 次数的限制，那什么地方不会有这种限制呢？首先想到的是 docker hub 上 build 镜像肯定不会限制吧。应该是的……。不如在 Dockerfile 里塞一个脚本，用它来同步镜像如何？于是一顿操作猛如虎，不一会儿就搓出来个 Dockerfile。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> debian:unstable-slim</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -xue ;\</span></span><br><span class="line"><span class="bash">    apt update -y ;\</span></span><br><span class="line"><span class="bash">    apt install ca-certificates skopeo git curl jq -y --no-install-recommends ;\</span></span><br><span class="line"><span class="bash">    rm -rf /var/lib/apt/lists/* ;\</span></span><br><span class="line"><span class="bash">    git <span class="built_in">clone</span> -b sync https://github.com/muzi502/official-images /build</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -xue ;\</span></span><br><span class="line"><span class="bash">    skopeo login hub.k8s.li -u admin -p Harbor123456 ;\</span></span><br><span class="line"><span class="bash">    bash /build/sync-images.sh</span></span><br></pre></td></tr></table></figure><p>然……事实证明是我太天真了，在同步了不到 100 多个镜像后，同样也出现了 429 toomanyrequests 的限制。掀桌儿！在 docker hub 上构建镜像，也会被限制？自己限制自己？？这什么鸡儿玩意。</p><p><del>假如有一个多阶段构建的 Dockerfile，就有可能因为拉不到镜像而导致镜像构建失败。那么这种智障的设计没想到过？</del></p><p>想到一种可能是 docker hub 内部是通过 token 来进行验证的，而不是根据客户端访问源 IP 。build 镜像的宿主机上会有 docker login 的 token 文件，但 build 镜像的容器里是没有这个 token 文件的，所以在 dockerfile 里 pull 镜像同样会被限制。看来 dockerfile 里同步镜像的方案也就不行了🙃，只能另寻他路啦。</p><h2 id="GitHub-Action-来同步镜像"><a href="#GitHub-Action-来同步镜像" class="headerlink" title="GitHub Action 来同步镜像"></a>GitHub Action 来同步镜像</h2><h3 id="ssh-连接-runner"><a href="#ssh-连接-runner" class="headerlink" title="ssh 连接 runner"></a>ssh 连接 runner</h3><p>在刚开始写这篇博客的时候也没有想到使用 GitHub Action，在刷 GitHub 动态的时候无意间发现了它。于是又一顿操作看看 GitHub Action 是否能用来同步镜像。</p><p>首先参考 <a href="https://p3terx.com/archives/ssh-to-the-github-actions-virtual-server-environment.html" target="_blank" rel="noopener">SSH 连接到 GitHub Actions 虚拟服务器</a> 连接到 runner 的机器上:</p><ul><li><code>.github/workflows/ssh.yaml</code></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Ubuntu</span></span><br><span class="line"><span class="attr">on:</span> <span class="string">push</span></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">build:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-20.04</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Setup</span> <span class="string">tmate</span> <span class="string">session</span></span><br><span class="line">      <span class="attr">uses:</span> <span class="string">mxschmitt/action-tmate@v1</span></span><br></pre></td></tr></table></figure><p>使用 ssh 连接到 action runner 的机器里意外发现，在 <code>~/.docker/config.json</code> 文件里竟然已经有了个 login 的 docker hub 账户。<code>哦豁.jpg</code>。由于 docker login 的配置文件只是简单的 base64 加密，解码后拿到真实的 user 和 token。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">runner@fv-az60-303:~$ cat .docker/config.json</span><br><span class="line">&#123;</span><br><span class="line">        "auths": &#123;</span><br><span class="line">                "https://index.docker.io/v1/": &#123;</span><br><span class="line">                        "auth": "Z2l0aHViYWN0aW9uczozZDY0NzJiOS0zZDQ5LTRkMTctOWZjOS05MGQyNDI1ODA0M2I="</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;runner@fv-az60-303:~$ echo "Z2l0aHViYWN0aW9uczozZDY0NzJiOS0zZDQ5LTRkMTctOWZjOS05MGQyNDI1ODA0M2I=" | base64 -d</span><br><span class="line">githubactions:3d6472b9-3d49-4d17-9fc9-90d24258043b</span><br></pre></td></tr></table></figure><p><img src="https://p.k8s.li/image-20210216173039196.png" alt=""></p><p>于是想着可以验证一下这个账户是否有限制：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl --user <span class="string">'githubactions:3d6472b9-3d49-4d17-9fc9-90d24258043'</span> <span class="string">"https://auth.docker.io/token?service=registry.docker.io&amp;scope=repository:ratelimitpreview/test:pull"</span></span><br></pre></td></tr></table></figure><p>但失败了，提示 <code>{&quot;details&quot;:&quot;incorrect username or password&quot;}</code> ，估计这个账户是个 bot 账户，只能用于 pull 镜像，其他的 api 请求都没权限使用。至于这个账户有没有限制，还需要做下测试。</p><p>另外意外地发现 runner 的机器里集成了很多工具，其中  skopeo 也包含在内，实在是太方便了。GitHub 牛皮，微软爸爸我爱你😘！那就方便了，我们就使用 skopeo inspect 去请求镜像的 manifests 文件。看看最多能请求多少会被限制。于是花了点时间搓了个脚本用于去获取 docker hub 上 library repo 中的所有镜像的 manifests 文件。</p><ul><li><code>get-manifests.sh</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">set</span> -eo pipefail</span><br><span class="line"></span><br><span class="line">DOCKER_HUB_URL=<span class="string">"https://hub.docker.com/v2/repositories/library"</span></span><br><span class="line">IMAGES_LIST=<span class="string">"images.list"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">get_images_list</span></span>() &#123;</span><br><span class="line">    ALL_IMAGES=<span class="string">""</span></span><br><span class="line">    URL=<span class="string">"<span class="variable">$&#123;DOCKER_HUB_URL&#125;</span>/?page_size=100"</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">true</span> ; <span class="keyword">do</span></span><br><span class="line">        ALL_IMAGES=<span class="string">"<span class="variable">$(curl -sSL $&#123;URL&#125; | jq -r '.results[].name' | tr '\n' ' ')</span> <span class="variable">$&#123;ALL_IMAGES&#125;</span>"</span></span><br><span class="line">        URL=<span class="string">"<span class="variable">$(curl -sSL $&#123;URL&#125; | jq -r '.next')</span>"</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;URL&#125;</span>"</span> = <span class="string">"null"</span> ]; <span class="keyword">then</span> <span class="built_in">break</span>; <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">    : &gt; <span class="variable">$&#123;IMAGES_LIST&#125;</span></span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> <span class="variable">$&#123;ALL_IMAGES&#125;</span>;<span class="keyword">do</span></span><br><span class="line">        <span class="keyword">if</span> skopeo list-tags docker://<span class="variable">$&#123;image&#125;</span> &amp;&gt; /dev/null; <span class="keyword">then</span></span><br><span class="line">            skopeo list-tags docker://<span class="variable">$&#123;image&#125;</span> | jq -c <span class="string">".Tags"</span> | tr -d <span class="string">'[]\"'</span> \</span><br><span class="line">            | tr <span class="string">','</span> <span class="string">'\n'</span> | sed <span class="string">"s|^|<span class="variable">$&#123;image&#125;</span>:|g"</span> &gt;&gt; <span class="variable">$&#123;IMAGES_LIST&#125;</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">get_manifests</span></span>() &#123;</span><br><span class="line">    mkdir -p manifests</span><br><span class="line">    IFS=$<span class="string">'\n'</span></span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> $(cat <span class="variable">$&#123;IMAGES_LIST&#125;</span>); <span class="keyword">do</span></span><br><span class="line">        <span class="keyword">if</span> skopeo inspect --raw docker://<span class="variable">$&#123;image&#125;</span> | jq  -r <span class="string">'.manifests[].digest'</span> &amp;&gt; /dev/null ; <span class="keyword">then</span></span><br><span class="line">            skopeo inspect --raw docker://<span class="variable">$&#123;image&#125;</span> | jq  -r <span class="string">'.manifests[].digest'</span> \</span><br><span class="line">            |  xargs -L1 -P8 -I % sh -c <span class="string">"skopeo inspect --raw docker://<span class="variable">$&#123;image/:*/&#125;</span>@% &gt; manifests/<span class="variable">$&#123;image&#125;</span>@%.json"</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            skopeo inspect --raw docker://<span class="variable">$&#123;image&#125;</span> &gt; manifests/<span class="variable">$&#123;image&#125;</span>.json</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">get_images_list</span><br><span class="line">get_manifests</span><br></pre></td></tr></table></figure><p>经过一番长时间的刺测试，在获取了 20058   个镜像的 manifest 文件之后依旧没有被限制，于是大胆猜测，runner 里内置的 docker hub 账户 pull library 镜像是没有限制的。估计是 GitHub 和 docker inc 达成了  py 交易，用这个账户去 pull 公共镜像没有限制。</p><p><img src="https://p.k8s.li/image-20210216173003436.png" alt=""></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">runner@fv-az212-267:~/work/runner-test/runner-test$ ls manifests/ | wc</span><br><span class="line">  20058   20058 1875861</span><br></pre></td></tr></table></figure><h3 id="定时同步镜像"><a href="#定时同步镜像" class="headerlink" title="定时同步镜像"></a>定时同步镜像</h3><p>从上述步骤一可知在 GitHub Action runner 机器里自带的 docker login 账户是没有限制，那我们最终就选定使用它来同步镜像到本地 registry 吧。参照 GitHub Action 照葫芦画瓢搓了个 action 的配置文件：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">sync-images</span></span><br><span class="line"></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line">  <span class="attr">push:</span></span><br><span class="line">    <span class="attr">branches:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">sync</span></span><br><span class="line">  <span class="comment"># 设置定时任务，每 6 小时运行一次</span></span><br><span class="line">  <span class="attr">schedule:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">cron:</span> <span class="string">"* */6 * * *"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">sync-images:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-20.04</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Clone</span> <span class="string">repository</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">actions/checkout@v2</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line">          <span class="string">git</span> <span class="string">config</span> <span class="string">user.name</span> <span class="string">github-actions</span></span><br><span class="line">          <span class="string">git</span> <span class="string">config</span> <span class="string">user.email</span> <span class="string">github-actions@github.com</span></span><br><span class="line"></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Sync</span> <span class="string">images</span></span><br><span class="line">        <span class="attr">shell:</span> <span class="string">bash</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="attr">REGISTRY_DOMAIN:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.REGISTRY_DOMAIN</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">REGISTRY_USER:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.REGISTRY_USER</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">REGISTRY_PASSWORD:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.REGISTRY_PASSWORD</span> <span class="string">&#125;&#125;</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line">          <span class="string">sudo</span> <span class="string">skopeo</span> <span class="string">login</span> <span class="string">$&#123;REGISTRY_DOMAIN&#125;</span>  <span class="string">-u</span> <span class="string">$&#123;REGISTRY_USER&#125;</span> <span class="string">-p</span> <span class="string">$&#123;REGISTRY_PASSWORD&#125;</span></span><br><span class="line">          <span class="string">sudo</span> <span class="string">bash</span> <span class="string">sync-images.sh</span> <span class="string">$&#123;REGISTRY_DOMAIN&#125;</span></span><br></pre></td></tr></table></figure><p>既然 GitHub runner 的机器里有 docker login 的配置文件，不如把它<strong>偷</strong>过来，复制粘贴到自家的机器上使用😜？不过我认为这种行为有点不厚道😂，还是别干了。在这里只提供一个思路，实际上可行性还待验证。</p><h3 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h3><p>默认设置的为 6 小时同步一次上游最新的代码，由于定时更新是使用的增量同步，即通过 git diff 的方式将当前分支最新的 commit 和上游 docker hub 官方的 repo 最新 commit 进行比较，找出变化的镜像。因此如果是首次同步，需要全量同步，在同步完成之后会给 repo 打上一个时间戳的 tag ，下次同步的时候就用这个 tag 和上游 repo 最新 commit 做差异比较。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IMAGES=$(git diff --name-only --ignore-space-at-eol --ignore-space-change \</span><br><span class="line">    --diff-filter=AM $&#123;LAST_TAG&#125; $&#123;CURRENT_COMMIT&#125; library | xargs -L1 -I &#123;&#125; sed "s|^|&#123;&#125;:|g" &#123;&#125; \</span><br><span class="line">    | sed -n "s| ||g;s|library/||g;s|:Tags:|:|p;s|:SharedTags:|:|p" | sort -u | sed "/$&#123;SKIPE_IMAGES&#125;/d")</span><br></pre></td></tr></table></figure><h2 id="如何食用？"><a href="#如何食用？" class="headerlink" title="如何食用？"></a>如何食用？</h2><p>如果你也想将 docker hub 上 library repo 的镜像搞到本地镜像仓库，可以参考如下方法：</p><h3 id="劝退三连😂"><a href="#劝退三连😂" class="headerlink" title="劝退三连😂"></a>劝退三连😂</h3><ul><li>首先要本地部署好镜像仓库并配置好 SSL 证书。镜像仓库建议使用 docker registry 或者 harbor，具体的部署方法可以在互联网上找到。</li><li>需要个大盘鸡（大硬盘机器），当前 docker hub 上还在维护的 tag 镜像总大小为 128 GB 左右。</li><li>如果是长期使用，本地镜像仓库的存储空间至少 1TB 以上。</li><li>由于是使用 GitHub action 的机器将镜像 push 到本地镜像仓库，因此本地镜像仓库需要有个公网IP以及域名 + SSL 证书</li></ul><h3 id="增加配置"><a href="#增加配置" class="headerlink" title="增加配置"></a>增加配置</h3><p>首先 fork 官方的 repo <a href="https://github.com/docker-library/official-images" target="_blank" rel="noopener">docker-library/official-images</a>  到自己的 GitHub 账户下；</p><p>然后 fork 这个 repo <a href="https://github.com/muzi502/sync-library-images" target="_blank" rel="noopener">muzi502/sync-library-images</a> 到自己的 GitHub 账户下；</p><p>最后在自己的 sync-library-images 这个 repo 的 <code>Settings &gt;  Secrets</code> 中配置好如下三个变量：</p><ul><li>REGISTRY_DOMAIN 设置为本地镜像仓库的域名</li><li>REGISTRY_USER 本地镜像仓库的用户名</li><li>REGISTRY_PASSWORD 设置为本地镜像仓库的密码</li></ul><p><img src="https://p.k8s.li/image-20210216163441719.png" alt=""></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><p><a href="https://docs.docker.com/docker-hub/official_images/" target="_blank" rel="noopener">Official Images on Docker Hub</a></p></li><li><p><a href="https://hub.docker.com/support/doc/how-do-i-authenticate-with-the-v2-api" target="_blank" rel="noopener">How do I authenticate with the V2 API?</a></p></li><li><p><a href="https://docs.docker.com/docker-hub/download-rate-limit/" target="_blank" rel="noopener">Download rate limit</a></p></li><li><p><a href="https://moelove.info/2020/09/20/%E7%AA%81%E7%A0%B4-DockerHub-%E9%99%90%E5%88%B6%E5%85%A8%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F%E6%9C%8D%E5%8A%A1/" target="_blank" rel="noopener">突破 DockerHub 限制，全镜像加速服务</a></p></li><li><p><a href="https://nova.moe/bypass-docker-hub-429/" target="_blank" rel="noopener">绕过从 Docker Hub pull 镜像时的 429 toomanyrequests</a></p></li><li><p><a href="https://www.chenshaowen.com/blog/how-to-cross-the-limit-of-dockerhub.html" target="_blank" rel="noopener">如何绕过 DockerHub 拉取镜像限制</a></p></li><li><p><a href="https://p3terx.com/archives/ssh-to-the-github-actions-virtual-server-environment.html" target="_blank" rel="noopener">SSH 连接到 GitHub Actions 虚拟服务器</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;恰烂钱？&quot;&gt;&lt;a href=&quot;#恰烂钱？&quot;
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://blog.k8s.li/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="registry" scheme="https://blog.k8s.li/tags/registry/"/>
    
      <category term="images" scheme="https://blog.k8s.li/tags/images/"/>
    
  </entry>
  
  <entry>
    <title>docker registry 迁移至 harbor</title>
    <link href="https://blog.k8s.li/docker-registry-to-harbor.html"/>
    <id>https://blog.k8s.li/docker-registry-to-harbor.html</id>
    <published>2021-01-30T16:00:00.000Z</published>
    <updated>2021-04-17T01:11:01.098Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Registry"><a href="#Registry" class="headerlink" title="Registry"></a>Registry</h2><h3 id="Docker-Distribution"><a href="#Docker-Distribution" class="headerlink" title="Docker Distribution"></a>Docker Distribution</h3><p><a href="https://github.com/distribution/distribution" target="_blank" rel="noopener">Docker Distribution</a> 是第一个是实现了打包、发布、存储和镜像分发的工具，起到 Docker registry 的作用。（目前 Distribution 已经捐赠给了 CNCF）。其中 Docker Distribution 中的 <a href="https://github.com/distribution/distribution/tree/main/docs/spec" target="_blank" rel="noopener">spec 规范</a> 后来也就成为了 OCI <a href="https://github.com/opencontainers/distribution-spec" target="_blank" rel="noopener">distribution-spec</a> 规范。可以认为 Docker Distribution 实现了大部分 OCI 镜像分发的规范，二者在很大程度上也是兼容的。 OCI 的指导思想时先有工业界的实践，再将这些实践总结成技术规范，因此尽管 OCI 的 <a href="https://github.com/opencontainers/distribution-spec" target="_blank" rel="noopener">distribution-spec</a> 规范还没有正式发布（目前版本是<a href="https://github.com/opencontainers/distribution-spec/releases/tag/v1.0.0-rc1" target="_blank" rel="noopener">v1.0.0-rc1</a>），但以 Docker Distribution 作为基础的镜像仓库已经成为普遍采用的方案，Docker registry HTTP API V2 也就成为了事实上的标准。</p><h3 id="Harbor"><a href="#Harbor" class="headerlink" title="Harbor"></a>Harbor</h3><p>Harbor 也是采用了 Docker Distribution （docker registry）作为后端镜像存储服务，在 Harbor 2.0 之前的版本，镜像相关的功能大部分是由 Docker Distribution 来处理，镜像和 OCI 等制品的元数据是 harbor 组件从 docker registry 中提取出来的；Harbor 在 2.0 版本之后，镜像等 OCI 制品相关的元数据由 Harbor 自己来维护，而且<strong>元数据是在 PUSH 这些制品时写入到 harbor 的数据库中的</strong>。也正因得益于此，Harbor 不再仅仅是个用来存储和管理镜像的服务，而一个云原生仓库服务，能够存储和管理符合 OCI 规范的 Helm Chart、CNAB、OPA Bundle 等多种 Artifact 。</p><h3 id="docker-registry-to-harbor"><a href="#docker-registry-to-harbor" class="headerlink" title="docker registry to harbor"></a>docker registry to harbor</h3><p>好了，扯了这么多没用的概念，回到本文要解决的问题：<strong>如何将 docker registry 中的镜像迁移至 harbor？</strong></p><p>假如内网环境中有两台机器，一台机器上运行着 docker registry，域名假设为 registry.k8s.li 。另一台机器运行着 harbor，假设域名为 harbor.k8s.li。现在 docker registry 中存放了五千个镜像。harbor 是刚刚部署的，里面还没有镜像。在磁盘和网络没有限制的情况下，如何高效地将 docker registry 中的镜像迁移到 harbor 中呢？</p><h2 id="获取-registry-所有镜像的列表"><a href="#获取-registry-所有镜像的列表" class="headerlink" title="获取 registry 所有镜像的列表"></a>获取 registry 所有镜像的列表</h2><p>首先在迁移之前我们要拉清单，获取一份 docker registry 中镜像的列表，这样我们才能保证迁移后没有镜像丢失。根据木子在 <a href="https://blog.k8s.li/Exploring-container-image.html">深入浅出容器镜像的一生🤔</a> 文章中提到的 registry 的存储目录结构。在 registry 存储目录中，每个镜像的 tag 都是由 <code>current/index</code> 这个文件指向该 tag 镜像的 manifests 文件的，由此我们可以通过遍历 registry 存储目录中 <code>current/index</code> 文件的方式来得到所有镜像的 tag，由此得到该 registry 中所有镜像的列表。注意，这样只能得到有 tag 的镜像，其他没 tag 的镜像无法获取到。</p><p><img src="https://p.k8s.li/registry-storage.jpeg" alt=""></p><p>可通过如下命令在 registry 存储目录下获取镜像列表：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先进入到 registry 存储的主目录下</span></span><br><span class="line"><span class="built_in">cd</span>  /var/lib/registry</span><br><span class="line">find docker -<span class="built_in">type</span> d -name <span class="string">"current"</span> | sed <span class="string">'s|docker/registry/v2/repositories/||g;s|/_manifests/tags/|:|g;s|/current||g'</span> &gt; images.list</span><br></pre></td></tr></table></figure><h2 id="harbor-创建-project"><a href="#harbor-创建-project" class="headerlink" title="harbor 创建 project"></a>harbor 创建 project</h2><p>对于新部署的 harbor 来说，上面只会有一个默认的 library 的 project，需要手动在 harbor 上创建 docker registry 中对应的 project。docker registry 中镜像的 project 就是 registry 存储目录中 <code>repositories</code> 下的目录名。</p><p>得到了镜像列表，以及在 harbor 上完成了对应 project 的创建，我们就可以做正式的迁移工作啦。根据不同的场景，可使用如下几种方案：</p><h2 id="方案一：docker-retag"><a href="#方案一：docker-retag" class="headerlink" title="方案一：docker retag"></a>方案一：docker retag</h2><p>方案一可能是大多数人首先想到的办法，也是最简单粗暴的方法。就是在一台机器上使用 docker pull 下 docker  registry 中的所有镜像，然后再 docker retag 一下，再 docker push 到 harbor 中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设其中的一个镜像为 library/alpine:latest</span></span><br><span class="line"></span><br><span class="line">docker pull registry.k8s.li/library/alpine:latest</span><br><span class="line"></span><br><span class="line">docker tag registry.k8s.li/library/alpine:latest harbor.k8s.li/library/alpine:latest</span><br><span class="line"></span><br><span class="line">docker push harbor.k8s.li/library/alpine:latest</span><br></pre></td></tr></table></figure><p>如果你之前读过木子曾经写过的 <a href="https://blog.k8s.li/Exploring-container-image.html">深入浅出容器镜像的一生🤔</a> 和 <a href="https://blog.k8s.li/skopeo.html">镜像搬运工 skopeo 初体验</a> 并且已经在日常生活中使用 skopeo ，你一定会很觉着这个方案很蠢，因为 docker pull –&gt; docker tag –&gt; docker pull 的过程中会对镜像的 layer 进行解压缩。对于只是将镜像从一个 registry 复制到另一个 registry 来说，这些 docker 在这些过程中做了很多无用功。详细的原理可以翻看一下刚提到的两篇文章，在此就不再赘述。</p><p>那么为了追求高效，肯定不会使用 docker retag 这么蠢的办法啦，下面就讲一下方案二：</p><h2 id="方案二：skopeo"><a href="#方案二：skopeo" class="headerlink" title="方案二：skopeo"></a>方案二：skopeo</h2><p>在 <a href="https://blog.k8s.li/skopeo.html">镜像搬运工 skopeo 初体验</a> 中介绍过可以使用 skopeo copy 直接从一个 registry 中复制镜像原始 blobs 到另一个 registry 中，在此期间不会涉及镜像 layer 解压缩操作。至于性能和耗时，比使用 docker 的方式高到不知道哪里去了😂。</p><ul><li>使用 skopeo copy</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skopeo copy --insecure-policy --src-tls-verify=<span class="literal">false</span> --dest-tls-verify=<span class="literal">false</span> --src docker://registry.k8s.li/library/alpine:latest docker://harbor.k8s.li/library/alpine:latest</span><br></pre></td></tr></table></figure><ul><li>使用 skopeo sync</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skopeo sync --insecure-policy --src-tls-verify=<span class="literal">false</span> --dest-tls-verify=<span class="literal">false</span> --src docker --dest docker registry.k8s.li/library/alpine:latest harbor.k8s.li/library/alpine:latest</span><br></pre></td></tr></table></figure><p>但还有没有更好的办法？要知道无论是 docker 和 skopeo 本质上都是通过 registry 的 HTTP API 下载和上传镜像的，在这过程中还是多了不少 HTTP 请求的，如果走的是 HTTPS 的话，还涉及了 HTTPS 加密和解密的过程，这期间也是做了很多<del>无用功</del>的。那么还有没有更好的办法？</p><h2 id="方案三：迁移存储目录"><a href="#方案三：迁移存储目录" class="headerlink" title="方案三：迁移存储目录"></a>方案三：迁移存储目录</h2><p>文章开篇提到 harbor 的后端镜像存储也是使用的  docker registry，对于一个 registry 来说，只要是使用的是 Docker Distribution V2 ，它后端的存储目录结构都是长得一摸一样的。那为何不直接将 registry 的存储目录打包复制并解压到 harbor 的 registry 存储目录呢？这样又能保证所有的镜像都迁移过去，不会落下任何一个。</p><p>对于 harbor 1.x 版本来讲，将 docker registry 的存储目录直接迁移到 harbor 的 registry 存储目录，然后删除 harbor 的 redis 数据（因为 harbor 的 redis 缓存了镜像的元数据信息），重启 harbor 就完事儿了。重启 harbor 之后，harbor 会调用后端的 registry 去提取镜像的元数据信息并存储到 redis 中。这样就完成了迁移的工作。</p><p>在 docker registry 机器上备份 registry 存储目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换到 docker registry 的存储目录</span></span><br><span class="line"><span class="built_in">cd</span>  /var/lib/registry</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意，进行备份时无需进行压缩，因为 registry 中镜像的 layer 都是压缩过的</span></span><br><span class="line">tar -cpf docker.tar docker</span><br></pre></td></tr></table></figure><p>备份完成之后将 docker.tar scp 到 harbor 机器上，然后在 harbor 机器上恢复 registry 存储目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换到 harbor 的存储目录</span></span><br><span class="line"><span class="built_in">cd</span> /data/harbor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将备份的 docker 目录解压到 harbor 的 registry 目录下，目录层级一定要对应好</span></span><br><span class="line">tar -xpf docker.tar -C ./registry</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除 harbor 的 regis 数据，重启 harbor 后会重建 redis 数据。</span></span><br><span class="line">rm -f redis/dump.rdb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到 harbor 的安装目录重启 harbor</span></span><br><span class="line"><span class="built_in">cd</span> /opt/harbor</span><br><span class="line">docker-compose restart</span><br></pre></td></tr></table></figure><p>这样迁移之后可能会遇到无法往 harbor push 镜像的问题。因为 docker registry 容器内 registry 存储目录的所属和所属组为 root ，而 harbor registry 容器内 registry 存储目录的所属和所属组为 10000:10000 ,二者权限并不相同，会导致 harbor 无法 push 镜像。因此在迁移完成之后需要修改一下 harbor registry 目录的所属和所属组。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换到 harbor 的存储目录</span></span><br><span class="line"><span class="built_in">cd</span> /data/harbor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改 registry 存储目录的所属和所属组为 10000</span></span><br><span class="line">chown -R 10000:10000 ./registry</span><br></pre></td></tr></table></figure><h2 id="方案四："><a href="#方案四：" class="headerlink" title="方案四："></a>方案四：</h2><p>对于 harbor 2.x 来讲，由于 harbor 强化了 Artifact 的元数据管理能力，即元数据要在 push 或者 sync 到 harbor 时写入到 harbor 自身的数据库中。在 harbor 看来只要数据库中没有这个 Artifact 的 manifest 信息或者没有这一层 layer 的信息，harbor 都会认为该 Artifact 或者 layer 不存在，返回 404 的错误。按照方案三直接而将 docker registry 存储目录解压到 harbor 的 registry 存储目录的方法行不通的。因为是将镜像解压到 registry 存储中的，虽然在 harbor 的 registry 容器看来是有镜像的，但因为 harbor 的数据库中没有镜像，harbor 就会认为没有镜像。那么现在看来只能通过方案二使用 skopeo 将镜像一个一个地 push 到 harbor 中了。</p><p>但对于某些特定的场景下，不能像方案二那样拥有一个 docker registry 的 HTTP 服务，只有一个 docker registry 的压缩包，这如何将 docker registry 的存储目录中的镜像迁移到 harbor 2.0 中呢？</p><p>在 <a href="https://blog.k8s.li/skopeo.html">镜像搬运工 skopeo 初体验</a> 中提到过 skopeo 支持的<code>镜像格式</code>有如下几种：</p><table><thead><tr><th align="left">IMAGE NAMES</th><th align="left">example</th></tr></thead><tbody><tr><td align="left"><strong>containers-storage:</strong></td><td align="left">containers-storage:</td></tr><tr><td align="left"><strong>dir:</strong></td><td align="left">dir:/PATH</td></tr><tr><td align="left"><strong>docker://</strong></td><td align="left">docker://k8s.gcr.io/kube-apiserver:v1.17.5</td></tr><tr><td align="left"><strong>docker-daemon:</strong></td><td align="left">docker-daemon:alpine:latest</td></tr><tr><td align="left"><strong>docker-archive:</strong></td><td align="left">docker-archive:alpine.tar (docker save)</td></tr><tr><td align="left"><strong>oci:</strong></td><td align="left">oci:alpine:latest</td></tr></tbody></table><p>需要注意的是，这几种镜像的名字，对应着镜像存在的方式，不同存在的方式对镜像的 layer 处理的方式也不一样，比如 <code>docker://</code> 这种方式是存在 registry 上的；<code>docker-daemon:</code> 是存在本地 docker pull 下来的；再比如 <code>docker-archive</code> 是通过 docker save 出来的镜像；而 <code>dir:</code> 是镜像以文件夹的形式保存的。同一个镜像有这几种存在的方式就像水有气体、液体、固体一样。可以这样去理解，他们表述的都是同一个镜像，只不过是存在的方式不一样而已。</p><p>既然镜像是存放在 registry 存储目录里的，那么使用 dir 的形式直接从文件系统读取镜像，理论上来讲会比方案二要好一些。虽然 skopeo 支持 dir 格式的镜像，但 skopeo 目前并不支持直接使用 registry 的存储目录，所以还是需要想办法将 docker registry 存储目录里的每一个镜像转换成 skopeo dir 的形式。</p><h3 id="skopeo-dir"><a href="#skopeo-dir" class="headerlink" title="skopeo dir"></a>skopeo dir</h3><p>那么先来看一下 skopeo dir 是什么样子的？</p><p>为了方便测试方案的可行性，先使用 skopeo 命令先从 docker hub 上拉取一个镜像，并保存为 dir，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skopeo copy docker://alpine:latest dir:./alpine</span><br></pre></td></tr></table></figure><p>使用 tree 命令查看一下 alpine 文件夹的目录结构，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">╭─root@sg-02 /var/lib/registry</span><br><span class="line">╰─# tree -h alpine</span><br><span class="line">alpine</span><br><span class="line">├── [2.7M]  4c0d98bf9879488e0407f897d9dd4bf758555a78e39675e72b5124ccf12c2580</span><br><span class="line">├── [1.4K]  e50c909a8df2b7c8b92a6e8730e210ebe98e5082871e66edd8ef4d90838cbd25</span><br><span class="line">├── [ 528]  manifest.json</span><br><span class="line">└── [  33]  version</span><br><span class="line"></span><br><span class="line">0 directories, 4 files</span><br><span class="line">╭─root@sg-02 /var/lib/registry</span><br><span class="line">╰─# file alpine/e50c909a8df2b7c8b92a6e8730e210ebe98e5082871e66edd8ef4d90838cbd25</span><br><span class="line">alpine/e50c909a8df2b7c8b92a6e8730e210ebe98e5082871e66edd8ef4d90838cbd25: ASCII text, with very long lines, with no line terminators</span><br><span class="line"></span><br><span class="line">╭─root@sg-02 /var/lib/registry</span><br><span class="line">╰─# file alpine/4c0d98bf9879488e0407f897d9dd4bf758555a78e39675e72b5124ccf12c2580</span><br><span class="line">alpine/4c0d98bf9879488e0407f897d9dd4bf758555a78e39675e72b5124ccf12c2580: gzip compressed data</span><br></pre></td></tr></table></figure><p>从文件名和大小以及文件的内省我们可以判断出，manifest 文件对应的就是镜像的 manifests 文件；类型为 <code>ASCII text</code> 的文件正是镜像的 image config 文件，里面包含着镜像的元数据信息。而另一个 <code>gzip compressed data</code> 文件不就是经过 gzip 压缩过的镜像 layer 嘛。看一下 manifest 文件的内容也再次印证了这个结论：</p><ul><li>镜像的 config 字段对应的正是 e50c909a8df2，而文件类型正是 <code>image.v1+json</code> 文本文件。</li><li>镜像的 layer 字段对应的也正是  4c0d98bf9879 而文件类型正是  <code>.tar.gzip</code> gzip 压缩文件。</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">alpine/4c0d98bf9879488e0407f897d9dd4bf758555a78e39675e72b5124ccf12c2580: gzip compressed data</span><br><span class="line">╭─root@sg-02 /var/lib/registry</span><br><span class="line">╰─# cat alpine/manifest.json</span><br><span class="line">&#123;</span><br><span class="line">   <span class="attr">"schemaVersion"</span>: <span class="number">2</span>,</span><br><span class="line">   <span class="attr">"mediaType"</span>: <span class="string">"application/vnd.docker.distribution.manifest.v2+json"</span>,</span><br><span class="line">   <span class="attr">"config"</span>: &#123;</span><br><span class="line">      <span class="attr">"mediaType"</span>: <span class="string">"application/vnd.docker.container.image.v1+json"</span>,</span><br><span class="line">      <span class="attr">"size"</span>: <span class="number">1471</span>,</span><br><span class="line">      <span class="attr">"digest"</span>: <span class="string">"sha256:e50c909a8df2b7c8b92a6e8730e210ebe98e5082871e66edd8ef4d90838cbd25"</span></span><br><span class="line">   &#125;,</span><br><span class="line">   <span class="attr">"layers"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="attr">"mediaType"</span>: <span class="string">"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,</span><br><span class="line">         <span class="attr">"size"</span>: <span class="number">2811321</span>,</span><br><span class="line">         <span class="attr">"digest"</span>: <span class="string">"sha256:4c0d98bf9879488e0407f897d9dd4bf758555a78e39675e72b5124ccf12c2580"</span></span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="从-registry-存储目录中捞镜像出来"><a href="#从-registry-存储目录中捞镜像出来" class="headerlink" title="从 registry 存储目录中捞镜像出来"></a>从 registry 存储目录中捞镜像出来</h3><p>接下来到本文的较为精彩的地方了。如何从 registry 存储里的 <code>捞</code> 镜像出来，转换成 skopeo 所支持的 dir 格式。</p><p><img src="https://p.k8s.li/registry-storage.jpeg" alt=""></p><ul><li>首先要得到镜像的 manifests 文件，从 manifests 文件中可以得到该镜像的所有 blob 文件。例如对于 registry 存储目录中的 <code>library/alpine:latest</code> 镜像来讲，它在 registry 中是这样存放的：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">╭─root@sg-02 /var/lib/registry/docker/registry/v2</span><br><span class="line">╰─# tree</span><br><span class="line">.</span><br><span class="line">├── blobs</span><br><span class="line">│   └── sha256</span><br><span class="line">│       ├── 21</span><br><span class="line">│       │   └── 21c83c5242199776c232920ddb58cfa2a46b17e42ed831ca9001c8dbc532d22d</span><br><span class="line">│       │       └── data</span><br><span class="line">│       ├── a1</span><br><span class="line">│       │   └── a143f3ba578f79e2c7b3022c488e6e12a35836cd4a6eb9e363d7f3a07d848590</span><br><span class="line">│       │       └── data</span><br><span class="line">│       └── be</span><br><span class="line">│           └── be4e4bea2c2e15b403bb321562e78ea84b501fb41497472e91ecb41504e8a27c</span><br><span class="line">│               └── data</span><br><span class="line">└── repositories</span><br><span class="line">    └── library</span><br><span class="line">        └── alpine</span><br><span class="line">            ├── _layers</span><br><span class="line">            │   └── sha256</span><br><span class="line">            │       ├── 21c83c5242199776c232920ddb58cfa2a46b17e42ed831ca9001c8dbc532d22d</span><br><span class="line">            │       │   └── link</span><br><span class="line">            │       └── be4e4bea2c2e15b403bb321562e78ea84b501fb41497472e91ecb41504e8a27c</span><br><span class="line">            │           └── link</span><br><span class="line">            ├── _manifests</span><br><span class="line">            │   ├── revisions</span><br><span class="line">            │   │   └── sha256</span><br><span class="line">            │   │       └── a143f3ba578f79e2c7b3022c488e6e12a35836cd4a6eb9e363d7f3a07d848590</span><br><span class="line">            │   │           └── link</span><br><span class="line">            │   └── tags</span><br><span class="line">            │       └── latest</span><br><span class="line">            │           ├── current</span><br><span class="line">            │           │   └── link</span><br><span class="line">            │           └── index</span><br><span class="line">            │               └── sha256</span><br><span class="line">            │                   └── a143f3ba578f79e2c7b3022c488e6e12a35836cd4a6eb9e363d7f3a07d848590</span><br><span class="line">            │                       └── link</span><br><span class="line">            └── _uploads</span><br><span class="line"></span><br><span class="line">26 directories, 8 files</span><br></pre></td></tr></table></figure><ol><li>通过 <code>repositories/library/alpine/_manifests/tags/latest/current/link</code> 文件得到 alpine 镜像 lasts 这个 tag 的 manifests 文件的 sha256 值，然后根据这个 sha256 值去 blobs 找到镜像的 manifests 文件;</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">╭─root@sg-02 /var/lib/registry/docker/registry/v2/repositories/library/alpine/_manifests/tags/latest/current/</span><br><span class="line">╰─# cat link</span><br><span class="line">sha256:39eda93d15866957feaee28f8fc5adb545276a64147445c64992ef69804dbf01#</span><br></pre></td></tr></table></figure><ol start="2"><li>根据 <code>current/link</code> 文件中的 sha256 值在 blobs 目录下找到与之对应的文件，blobs 目录下对应的 manifests 文件为 blobs/sha256/39/39eda93d15866957feaee28f8fc5adb545276a64147445c64992ef69804dbf01/data;</li></ol><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">╭─root@sg-02 /var/lib/registry/docker/registry/v2/repositories/library/alpine/_manifests/tags/latest/current</span><br><span class="line">╰─# cat /var/lib/registry/docker/registry/v2/blobs/sha256/39/39eda93d15866957feaee28f8fc5adb545276a64147445c64992ef69804dbf01/data</span><br><span class="line">&#123;</span><br><span class="line">   <span class="attr">"schemaVersion"</span>: <span class="number">2</span>,</span><br><span class="line">   <span class="attr">"mediaType"</span>: <span class="string">"application/vnd.docker.distribution.manifest.v2+json"</span>,</span><br><span class="line">   <span class="attr">"config"</span>: &#123;</span><br><span class="line">      <span class="attr">"mediaType"</span>: <span class="string">"application/vnd.docker.container.image.v1+json"</span>,</span><br><span class="line">      <span class="attr">"size"</span>: <span class="number">1507</span>,</span><br><span class="line">      <span class="attr">"digest"</span>: <span class="string">"sha256:f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a"</span></span><br><span class="line">   &#125;,</span><br><span class="line">   <span class="attr">"layers"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="attr">"mediaType"</span>: <span class="string">"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,</span><br><span class="line">         <span class="attr">"size"</span>: <span class="number">2813316</span>,</span><br><span class="line">         <span class="attr">"digest"</span>: <span class="string">"sha256:cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08"</span></span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>使用正则匹配，过滤出 manifests 文件中的所有 sha256 值，这些 sha256 值就对应着 blobs 目录下的 image config 文件和 image layer 文件;</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">╭─root@sg-02 /var/lib/registry/docker/registry/v2/repositories/library/alpine/_manifests/tags/latest/current</span><br><span class="line">╰─<span class="comment"># grep -Eo "\b[a-f0-9]&#123;64&#125;\b" /var/lib/registry/docker/registry/v2/blobs/sha256/39/39eda93d15866957feaee28f8fc5adb545276a64147445c64992ef69804dbf01/data</span></span><br><span class="line">f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a</span><br><span class="line">cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08</span><br></pre></td></tr></table></figure><ol start="4"><li>根据 manifests 文件就可以得到 blobs 目录中镜像的所有 layer 和 image config 文件，然后将这些文件拼成一个 dir 格式的镜像，在这里使用 cp 的方式将镜像从 registry 存储目录里复制出来，过程如下：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 首先创建一个文件夹，为了保留镜像的 name 和 tag，文件夹的名称就对应的是 NAME:TAG</span></span><br><span class="line">╭─root@sg-02 /var/lib/registry/docker</span><br><span class="line">╰─# mkdir -p skopeo/library/alpine:latest</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制镜像的 manifest 文件</span></span><br><span class="line">╭─root@sg-02 /var/lib/registry/docker</span><br><span class="line">╰─# cp /var/lib/registry/docker/registry/v2/blobs/sha256/39/39eda93d15866957feaee28f8fc5adb545276a64147445c64992ef69804dbf01/data skopeo/library/alpine:latest/manifest</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制镜像的 blob 文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cp /var/lib/registry/docker/registry/v2/blobs/sha256/f7/f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a/data skopeo/library/alpine:latest/f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cp /var/lib/registry/docker/registry/v2/blobs/sha256/cb/cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08/data skopeo/library/alpine:latest/cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08</span></span><br></pre></td></tr></table></figure><p>最终得到的镜像格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">╭─root@sg-02 /var/lib/registry/docker</span><br><span class="line">╰─<span class="comment"># tree skopeo/library/alpine:latest</span></span><br><span class="line">skopeo/library/alpine:latest</span><br><span class="line">├── cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08</span><br><span class="line">├── f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a</span><br><span class="line">└── manifest</span><br><span class="line"></span><br><span class="line">0 directories, 3 files</span><br></pre></td></tr></table></figure><p>和上面的 skopeo copy 出来的 dir 文件夹对比一下，除了一个无关紧要的 version 文件，其他的都一摸一样。</p><ol start="5"><li>再优化一下，将步骤 4 中的 cp 操作修改成硬链接操作，能极大减少磁盘的 IO 操作。需要注意：硬链接文件不能跨分区，所以要和 registry 存储目录在同一个分区下才行。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">╭─root@sg-02 /var/lib/registry/docker</span><br><span class="line">╰─# ln /var/lib/registry/docker/registry/v2/blobs/sha256/39/39eda93d15866957feaee28f8fc5adb545276a64147445c64992ef69804dbf01/data skopeo/library/alpine:latest/manifest</span><br><span class="line"><span class="meta">#</span><span class="bash"> ln /var/lib/registry/docker/registry/v2/blobs/sha256/f7/f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a/data skopeo/library/alpine:latest/f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ln /var/lib/registry/docker/registry/v2/blobs/sha256/cb/cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08/data skopeo/library/alpine:latest/cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08</span></span><br><span class="line">╭─root@sg-02 /var/lib/registry/docker</span><br><span class="line">╰─# tree skopeo/library/alpine:latest</span><br><span class="line">skopeo/library/alpine:latest</span><br><span class="line">├── cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08</span><br><span class="line">├── f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a</span><br><span class="line">└── manifest</span><br><span class="line"></span><br><span class="line">0 directories, 3 files</span><br></pre></td></tr></table></figure><p>然后使用 skopeo copy 或者 skopeo sync 将捞出来的镜像 push 到 harbor</p><ul><li>使用 skopeo copy</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">skopeo copy  --insecure-policy --src-tls-verify=false --dest-tls-verify=false \</span><br><span class="line">dir:skopeo/library/alpine:latest docker://harbor.k8s.li/library/alpine:latest</span><br></pre></td></tr></table></figure><ul><li>使用 skopeo sync</li></ul><p>需要注意的是，skopeo sync 的方式是同步 project 级别的，镜像的 name 和 tag 就对应的是目录的名称</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">skopeo sync --insecure-policy --src-tls-verify=false --dest-tls-verify=false \</span><br><span class="line">--src dir --dest docker skopeo/library/ harbor.k8s.li/library/</span><br></pre></td></tr></table></figure><h3 id="实现脚本"><a href="#实现脚本" class="headerlink" title="实现脚本"></a>实现脚本</h3><p>大叫一声 shell 大法好！😂</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">REGISTRY_DOMAIN="harbor.k8s.li"</span><br><span class="line">REGISTRY_PATH="/var/lib/registry"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 切换到 registry 存储主目录下</span></span><br><span class="line">cd $&#123;REGISTRY_PATH&#125;</span><br><span class="line"></span><br><span class="line">gen_skopeo_dir() &#123;</span><br><span class="line"><span class="meta">   #</span><span class="bash"> 定义 registry 存储的 blob 目录 和 repositories 目录，方便后面使用</span></span><br><span class="line">    BLOB_DIR="docker/registry/v2/blobs/sha256"</span><br><span class="line">    REPO_DIR="docker/registry/v2/repositories"</span><br><span class="line">    # 定义生成 skopeo 目录</span><br><span class="line">    SKOPEO_DIR="docker/skopeo"</span><br><span class="line">    # 通过 find 出 current 文件夹可以得到所有带 tag 的镜像，因为一个 tag 对应一个 current 目录</span><br><span class="line">    for image in $(find $&#123;REPO_DIR&#125; -type d -name "current"); do</span><br><span class="line">        # 根据镜像的 tag 提取镜像的名字</span><br><span class="line">        name=$(echo $&#123;image&#125; | awk -F '/' '&#123;print $5"/"$6":"$9&#125;')</span><br><span class="line">        link=$(cat $&#123;image&#125;/link | sed 's/sha256://')</span><br><span class="line">        mfs="$&#123;BLOB_DIR&#125;/$&#123;link:0:2&#125;/$&#123;link&#125;/data"</span><br><span class="line">        # 创建镜像的硬链接需要的目录</span><br><span class="line">        mkdir -p "$&#123;SKOPEO_DIR&#125;/$&#123;name&#125;"</span><br><span class="line">        # 硬链接镜像的 manifests 文件到目录的 manifest 文件</span><br><span class="line">        ln $&#123;mfs&#125; $&#123;SKOPEO_DIR&#125;/$&#123;name&#125;/manifest.json</span><br><span class="line">        # 使用正则匹配出所有的 sha256 值，然后排序去重</span><br><span class="line">        layers=$(grep -Eo "\b[a-f0-9]&#123;64&#125;\b" $&#123;mfs&#125; | sort -n | uniq)</span><br><span class="line">        for layer in $&#123;layers&#125;; do</span><br><span class="line">          # 硬链接 registry 存储目录里的镜像 layer 和 images config 到镜像的 dir 目录</span><br><span class="line">            ln $&#123;BLOB_DIR&#125;/$&#123;layer:0:2&#125;/$&#123;layer&#125;/data $&#123;SKOPEO_DIR&#125;/$&#123;name&#125;/$&#123;layer&#125;</span><br><span class="line">        done</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sync_image() &#123;</span><br><span class="line">    # 使用 skopeo sync 将 dir 格式的镜像同步到 harbor</span><br><span class="line">    for project in $(ls $&#123;SKOPEO_DIR&#125;); do</span><br><span class="line">        skopeo sync --insecure-policy --src-tls-verify=false --dest-tls-verify=false \</span><br><span class="line">        --src dir --dest docker $&#123;SKOPEO_DIR&#125;/$&#123;project&#125; $&#123;REGISTRY_DOMAIN&#125;/$&#123;project&#125;</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gen_skopeo_dir</span><br><span class="line">sync_image</span><br></pre></td></tr></table></figure><p>其实魔改一下 skopeo 的源码也是可以无缝支持 registry 存储目录的，目前正在研究中😃</p><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><table><thead><tr><th></th><th>方法</th><th>适用范围</th><th>缺点</th></tr></thead><tbody><tr><td>一</td><td>docker retag</td><td>两个 registry 之间同步镜像</td><td></td></tr><tr><td>二</td><td>skopeo</td><td>两个 registry 之间同步镜像</td><td></td></tr><tr><td>三</td><td>解压目录</td><td>registry 存储目录到另一个 registry</td><td>harbor 1.x</td></tr><tr><td>四</td><td>skopeo dir</td><td>registry 存储目录到另一个 registry</td><td>适用于 harbor 2.x</td></tr></tbody></table><p>对比总结一下以上几种方案：</p><ul><li>方案一：上手成本低，适用于镜像数量比较多少，无需安装 skopeo 的情况，缺点是性能较差；</li><li>方案二：适用于两个 registry 之间同步复制镜像，如将 docker hub 中的一些公共镜像复制到公司内网的镜像仓库中。</li><li>方案三：适用于镜像仓库之间进行迁移，性能是所有方案里最好的，需要额外注意的是如果目的镜像仓库是 harbor 2.x，是无法使用这种方式的。</li><li>方案四：是方案三的妥协版，为了适配 harbor 2.0 ，因为需要重新将镜像 push 到 harbor ，所以性能上要比方案三差一些。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="">《harbor权威指南</a></li><li><a href="https://goharbor.io/blog/harbor-2.0/" target="_blank" rel="noopener">Harbor 2.0 takes a giant leap in expanding supported artifacts with OCI support</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;Registry&quot;&gt;&lt;a
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://blog.k8s.li/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="registry" scheme="https://blog.k8s.li/tags/registry/"/>
    
      <category term="harbor" scheme="https://blog.k8s.li/tags/harbor/"/>
    
      <category term="镜像" scheme="https://blog.k8s.li/tags/%E9%95%9C%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>2020 年读书笔记和思考</title>
    <link href="https://blog.k8s.li/2020-booklist.html"/>
    <id>https://blog.k8s.li/2020-booklist.html</id>
    <published>2020-12-30T16:00:00.000Z</published>
    <updated>2021-01-09T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>首先给各位关注我博客的小伙伴说声抱歉，已经很长时间（将近 4 个月）没有更新博客了，实在是对不住大家，自己一直在偷懒没能坚持创作。2021 年刚开始，决定决定以后还是要坚持创作下去，于是最近抽出点时间整理了下 2020 年读过的书分享给大家，希望能帮助到大家找到些有意思的书来读。内容有点多，大概 2 万多字🙃。</p><h2 id="书单"><a href="#书单" class="headerlink" title="书单"></a>书单</h2><p>由于疫情的影响，节假日和周末都不怎么出去，一直宅在家里，所以大部分的闲暇时间都是捧着 kindle 看会书，亦或者刷一会 Pixiv 和 Twitter 收集一些纸片人插画，俨然成了一个标准的死肥宅。2020 年一整年留给自己的时间比较多，所以总体上来讲 2020 年读过的书比 2019 年多了将近一倍，有兴趣的可以翻开一下 2019 年的读书总结 <a href="https://blog.k8s.li/2019-reading-notes.html">2019 年读书笔记和思考</a> 。下面的表格是我参考 kindle 上的标注时间整理的 2020 年读完的书（共计 68 本书）。</p><table><thead><tr><th align="center">书名</th><th align="center">作者</th><th align="center">start</th><th align="center">end</th><th align="center">时长</th></tr></thead><tbody><tr><td align="center">论人类不平等的起源和基础</td><td align="center">【法】让-雅克·卢梭</td><td align="center">01-01</td><td align="center">01-05</td><td align="center">6h</td></tr><tr><td align="center">社会主义：经济学与社会学的分析</td><td align="center">【奥】 路德维希·冯·米瑟斯</td><td align="center">01-01</td><td align="center">01-10</td><td align="center">10h</td></tr><tr><td align="center">心理测量者</td><td align="center">【日】深真见</td><td align="center">01-03</td><td align="center">01-05</td><td align="center">6h</td></tr><tr><td align="center">论革命</td><td align="center">【德】汉娜·阿伦特</td><td align="center">01-05</td><td align="center">01-20</td><td align="center">12h</td></tr><tr><td align="center">新常识：一党专政的性质和后果</td><td align="center">张雪忠</td><td align="center">01-15</td><td align="center">01-20</td><td align="center">4h</td></tr><tr><td align="center">论科学与艺术的复兴是否有助于使风俗日趋纯朴</td><td align="center">【法】让-雅克·卢梭</td><td align="center">01-21</td><td align="center">01-25</td><td align="center">4h</td></tr><tr><td align="center">地球脉动：前所未见的自然之美</td><td align="center">【英】阿拉斯泰尔·福瑟吉尔</td><td align="center">01-22</td><td align="center">01-25</td><td align="center">2h</td></tr><tr><td align="center">社会契约论 (译林人文精选)</td><td align="center">【法】让-雅克·卢梭</td><td align="center">01-23</td><td align="center">01-25</td><td align="center">4h</td></tr><tr><td align="center">中国国家治理的制度逻辑：一个组织学研究</td><td align="center">周雪光</td><td align="center">01-28</td><td align="center">02-07</td><td align="center">8h</td></tr><tr><td align="center">病毒星球</td><td align="center">【美]】尔·齐默</td><td align="center">01-28</td><td align="center">01-30</td><td align="center">4h</td></tr><tr><td align="center">病毒来袭</td><td align="center">【美】内森•沃尔夫</td><td align="center">01-29</td><td align="center">01-31</td><td align="center">2h</td></tr><tr><td align="center">血疫：埃博拉的故事</td><td align="center">理查德·普雷斯顿</td><td align="center">02-01</td><td align="center">02-08</td><td align="center">8h</td></tr><tr><td align="center">远古的葱茏：古植物王国</td><td align="center">周志炎</td><td align="center">02-05</td><td align="center">05-08</td><td align="center">4h</td></tr><tr><td align="center">古生物学简明教程</td><td align="center">朱才伐</td><td align="center">02-06</td><td align="center">02-10</td><td align="center">3h</td></tr><tr><td align="center">上帝造人有多难：生命的密钥</td><td align="center">朱钦士</td><td align="center">02-07</td><td align="center">02-12</td><td align="center">6h</td></tr><tr><td align="center">朱钦士的个人博客</td><td align="center">朱钦士</td><td align="center">02-08</td><td align="center">03-30</td><td align="center">8h</td></tr><tr><td align="center">远古的辉煌：生物大幅射</td><td align="center">戎嘉余</td><td align="center">02-13</td><td align="center">05-15</td><td align="center">6h</td></tr><tr><td align="center">牛津通识读本：地球</td><td align="center">【英】马丁·雷德芬</td><td align="center">02-13</td><td align="center">02-15</td><td align="center">6h</td></tr><tr><td align="center">生命活动的摇篮：细胞</td><td align="center">王耀发</td><td align="center">02-16</td><td align="center">02-18</td><td align="center">4h</td></tr><tr><td align="center">地球脉动2：奇迹世界</td><td align="center">【英】胡·科里</td><td align="center">02-24</td><td align="center">02-27</td><td align="center">3h</td></tr><tr><td align="center">一想到还有95<em>%的</em>问题留给人类，我就放心了</td><td align="center">【巴拿马】豪尔赫•陈</td><td align="center">03-07</td><td align="center">03-15</td><td align="center">4h</td></tr><tr><td align="center">历史的终结及最后之人</td><td align="center">【美】弗朗西斯·福山</td><td align="center">03-03</td><td align="center">03-10</td><td align="center">10h</td></tr><tr><td align="center">我無罪：劉曉波傳</td><td align="center">余杰</td><td align="center">03-13</td><td align="center">03-20</td><td align="center">8h</td></tr><tr><td align="center">神奇的生物化学</td><td align="center">神奇的生物化学</td><td align="center">03-23</td><td align="center">03-25</td><td align="center">4h</td></tr><tr><td align="center">费马最终定理</td><td align="center">【日】日冲樱皮</td><td align="center">03-26</td><td align="center">03-28</td><td align="center">3h</td></tr><tr><td align="center">被讨厌的勇气</td><td align="center">【日】岸見一郎</td><td align="center">03-28</td><td align="center">03-30</td><td align="center">4h</td></tr><tr><td align="center">鸟瞰古文明</td><td align="center">【法】 让-克劳德·戈尔万</td><td align="center">04-03</td><td align="center">04-10</td><td align="center">8h</td></tr><tr><td align="center">自由宪章</td><td align="center">【奥】弗里德里希·哈耶克</td><td align="center">04-01</td><td align="center">04-20</td><td align="center">16h</td></tr><tr><td align="center">盗火者：中国教育革命静悄悄</td><td align="center">邓康延 梁罗兴</td><td align="center">04-11</td><td align="center">04-20</td><td align="center">6h</td></tr><tr><td align="center">我们最幸福：北韩人民的真实生活</td><td align="center">【美】芭芭拉·德米克</td><td align="center">04-23</td><td align="center">04-26</td><td align="center">6h</td></tr><tr><td align="center">哈维尔文集</td><td align="center">【捷克】哈维尔</td><td align="center">04-24</td><td align="center">04-30</td><td align="center">8h</td></tr><tr><td align="center">布达佩斯往事：冷战时期一个东欧家庭的秘密档案</td><td align="center">【美】 卡蒂·马顿</td><td align="center">04-26</td><td align="center">04-30</td><td align="center">6h</td></tr><tr><td align="center">致命的自负：社会主义的谬误</td><td align="center">【奥】弗里德里希·哈耶克</td><td align="center">05-01</td><td align="center">05-30</td><td align="center">10h</td></tr><tr><td align="center">地球的演变故事</td><td align="center">姚建明</td><td align="center">05-02</td><td align="center">05-05</td><td align="center">4h</td></tr><tr><td align="center">图解科技译丛：漫画元素118</td><td align="center">【日】斋腾胜裕</td><td align="center">05-02</td><td align="center">05-03</td><td align="center">2h</td></tr><tr><td align="center">颓废与沉默：透视犬儒文化</td><td align="center">徐贲</td><td align="center">05-02</td><td align="center">05-10</td><td align="center">4h</td></tr><tr><td align="center">统治与教育：从国民到公民</td><td align="center">徐贲</td><td align="center">05-03</td><td align="center">05-25</td><td align="center">8h</td></tr><tr><td align="center">三角距离无限为零1-4</td><td align="center">【日】岬鹭宫</td><td align="center">05-05</td><td align="center">05-25</td><td align="center">10h</td></tr><tr><td align="center">被禁锢的头脑</td><td align="center">【立】切斯瓦夫·米沃什</td><td align="center">05-05</td><td align="center">05-10</td><td align="center">6h</td></tr><tr><td align="center">人以什么理由来记忆</td><td align="center">徐贲</td><td align="center">05-02</td><td align="center">05-10</td><td align="center">10h</td></tr><tr><td align="center">宇宙从一粒尘埃开始：9堂极简宇宙课</td><td align="center">【英】布莱恩•考克斯</td><td align="center">05-25</td><td align="center">05-30</td><td align="center">5h</td></tr><tr><td align="center">通往尊严的公共生活</td><td align="center">徐贲</td><td align="center">05-25</td><td align="center">05-30</td><td align="center">10h</td></tr><tr><td align="center">宇宙从起源到未来</td><td align="center">【美】约翰·布罗克曼</td><td align="center">06-18</td><td align="center">06-25</td><td align="center">5h</td></tr><tr><td align="center">kubernetes 网络权威指南</td><td align="center">杜军</td><td align="center">06-20</td><td align="center">06-27</td><td align="center">6h</td></tr><tr><td align="center">Linux开源网络全栈详解：从DPDK到OpenFlow</td><td align="center">英特尔亚太研发有限公司</td><td align="center">06-20</td><td align="center">06-23</td><td align="center">3h</td></tr><tr><td align="center">大话处理器</td><td align="center">万木杨</td><td align="center">06-21</td><td align="center">06-21</td><td align="center">2h</td></tr><tr><td align="center">三角的距离无限为零5</td><td align="center">【日】岬鹭宫</td><td align="center">06-24</td><td align="center">06-25</td><td align="center">2.5h</td></tr><tr><td align="center">大话存储</td><td align="center">张冬</td><td align="center">06-27</td><td align="center">07-21</td><td align="center">18h</td></tr><tr><td align="center">布拉格精神</td><td align="center">【捷】伊凡·克里玛</td><td align="center">07-01</td><td align="center">07-10</td><td align="center">6h</td></tr><tr><td align="center">徐贲文集</td><td align="center">徐贲</td><td align="center">07-10</td><td align="center">07-30</td><td align="center">30h</td></tr><tr><td align="center">生命通史</td><td align="center">朱钦士</td><td align="center">04-10</td><td align="center">08-20</td><td align="center">60h</td></tr><tr><td align="center">Kubernetes 源码剖析</td><td align="center">郑东旭</td><td align="center">08-01</td><td align="center">08-10</td><td align="center">10h</td></tr><tr><td align="center">Kubernetes 指南第四版</td><td align="center">龚正，吴治辉，崔秀龙</td><td align="center">08-10</td><td align="center">08-30</td><td align="center">8h</td></tr><tr><td align="center">媒介批判三部曲</td><td align="center">【美】尼尔·波兹曼</td><td align="center">09-01</td><td align="center">09-30</td><td align="center">20h</td></tr><tr><td align="center">时光沙漏</td><td align="center">【日】さと(</td><td align="center">09-13</td><td align="center">09-13</td><td align="center">1h</td></tr><tr><td align="center">Just Because!</td><td align="center">【日】鸭志田一</td><td align="center">09-13</td><td align="center">09-14</td><td align="center">4h</td></tr><tr><td align="center">我的青春戀愛物語果然有問題</td><td align="center">【日】渡航</td><td align="center">09-15</td><td align="center">09-30</td><td align="center">30h</td></tr><tr><td align="center">kubernetes 源码分析</td><td align="center">郑东旭</td><td align="center">10-01</td><td align="center">10-07</td><td align="center">15h</td></tr><tr><td align="center">安达与岛村 1-8</td><td align="center">【日】入间人间</td><td align="center">11-15</td><td align="center">11-20</td><td align="center">20h</td></tr><tr><td align="center">复杂生命的起源</td><td align="center">【英】 尼克·莱恩</td><td align="center">11-30</td><td align="center">12-07</td><td align="center">15h</td></tr><tr><td align="center">来自新世界</td><td align="center">【日】贵志祐介</td><td align="center">11-30</td><td align="center">12-10</td><td align="center">20h</td></tr><tr><td align="center">政宗君的復仇</td><td align="center">【日】竹冈叶月</td><td align="center">12-05</td><td align="center">12-07</td><td align="center">6h</td></tr><tr><td align="center">星际穿越</td><td align="center">【美】基普·索恩</td><td align="center">12-10</td><td align="center">12-12</td><td align="center">4h</td></tr><tr><td align="center">Life 生命</td><td align="center">【美】约翰·布罗克曼</td><td align="center">12-12</td><td align="center">12-23</td><td align="center">8h</td></tr><tr><td align="center">美丽新世界</td><td align="center">【英】阿道司·赫胥黎</td><td align="center">12-14</td><td align="center">12-18</td><td align="center">8h</td></tr><tr><td align="center">樱花庄的宠物女孩</td><td align="center">【日】鸭志田一</td><td align="center">12-13</td><td align="center">12-21</td><td align="center">36h</td></tr><tr><td align="center">生命的跃升</td><td align="center">【英]】尼克·莱恩</td><td align="center">12-22</td><td align="center">12-26</td><td align="center">8h</td></tr><tr><td align="center">消失的微生物：滥用抗生素引发的危机</td><td align="center">【美】马丁•布莱泽</td><td align="center">12-28</td><td align="center">01-02</td><td align="center">8h</td></tr></tbody></table><h2 id="推荐"><a href="#推荐" class="headerlink" title="推荐"></a>推荐</h2><ul><li>社会契约论</li><li>论人类不平等的起源和基础</li><li>论科学与艺术的复兴是否有助于使风俗日趋纯朴</li><li>致命的自负：社会主义的谬误</li><li>社会主义：经济学与社会学的分析</li><li>中国国家治理的制度逻辑：一个组织学研究</li><li>我们最幸福：北韩人民的真实生活</li><li>布达佩斯往事：冷战时期一个东欧家庭的秘密档案</li><li>被讨厌的勇气</li><li>颓废与沉默：透视犬儒文化</li><li>统治与教育：从国民到公民</li><li>人以什么理由来记忆</li><li>通往尊严的公共生活</li><li>布拉格精神</li><li>徐贲文集</li><li>生命通史</li><li>复杂生命的起源</li><li>生命的跃升</li><li>来自新世界</li></ul><h2 id="政治-哲学"><a href="#政治-哲学" class="headerlink" title="政治/哲学"></a>政治/哲学</h2><h3 id="社会主义：经济学与社会学的分析"><a href="#社会主义：经济学与社会学的分析" class="headerlink" title="社会主义：经济学与社会学的分析"></a>社会主义：经济学与社会学的分析</h3><p>这本书是 2020 年读的第一本书，这本书可以和哈耶克的《通往奴役之路》结合着读。本书出版于 1922 年，分别从多个领域（政治、经济、文化、伦理、宗教…）论述了社会主义必定失败的悲惨结局，对当时的社会尤其青年学生来讲冲击相当的大，那时候 CCP 刚刚成立才 1 年哦。</p><p>先说一下作者，路德维希·冯·米塞斯作为“<a href="https://zh.wikipedia.org/wiki/奧地利經濟學派" target="_blank" rel="noopener">奥地利经济学派</a>的院长”，现代<a href="https://zh.wikipedia.org/wiki/自由意志主義" target="_blank" rel="noopener">自由意志主义</a>运动的主要领导人，也是<a href="https://zh.wikipedia.org/wiki/古典自由主義" target="_blank" rel="noopener">古典自由主义</a>第一把交椅，其影响力不言而喻。他的学生更是青出于蓝胜于蓝：弗里德里希·冯·哈耶克、弗里茨·马克卢普、戈特弗里德·冯·哈伯勒、奥斯卡·摩根斯坦、威廉·勒普克、理查德·冯·施特里戈尔、艾尔弗雷德·舒茨、费里克斯·考夫曼、埃里克·沃格林、格奥尔格·哈尔姆、保罗·罗森斯坦-罗丹、莱昂内尔·罗宾斯。在他的学生当中，哈耶克获诺贝尔经济学奖，弗里茨·马克卢普、戈特弗里德·冯·哈伯勒曾先后任美国经济学会会长。</p><blockquote><p>我们感到，我们成长于其中的那个文明已经崩溃。我们立志建设一个更美好的世界，而正是这种再造社会的渴望，鞭策我们投身经济学研究。社会主义许诺给我们一个更加理性、更加公正的世界。此时，《社会主义》问世了，我们的信念坍塌了。《社会主义》对我们说，我们的方向错了。</p></blockquote><p><code>摘抄</code> <a href="https://t.co/mSj0qay7jW" target="_blank" rel="noopener">社会主义：经济学与社会学的分析</a></p><blockquote><p>米塞斯在书中分别从多个领域（政治、经济、文化、伦理、宗教…）对【各种流派】的社会主义进行猛烈批判。其抨击的火力之猛，实属罕见。</p></blockquote><p>另外推荐读一下 <a href="https://program-think.blogspot.com/2018/09/Book-Review-The-Errors-of-Marxism-Leninism.html" target="_blank" rel="noopener">为什么马克思是错的？——全面批判马列主义的知名著作导读</a> 。</p><blockquote><p>作者<a href="https://zh.wikipedia.org/wiki/路德維希·馮·米塞斯" target="_blank" rel="noopener">路德维希·冯·米塞斯</a>是奥地利学派的干将，并对同一学派的哈耶克有重大影响。在哈耶克的很多著作和理论中，都可以看到米塞斯的影子。<br>　　米塞斯的成就长期被学术界忽视（甚至是排斥）。一方面是他的理论太超前，另一方面是他的性格太激烈——与人交流时总是一针见血，不留情面，毫不顾忌他人感受。<br>　　说到【超前性】，他可能是经济学界最早意识到“【博弈论】重要性”的那个人（时间是20世纪初期）。几十年后，与冯·诺依曼共同发表划时代论文《博弈论与经济行为》的那个摩根斯坦（前面俺提过此人），就是米塞斯的学生。</p></blockquote><h3 id="论人类不平等的起源和基础"><a href="#论人类不平等的起源和基础" class="headerlink" title="论人类不平等的起源和基础"></a>论人类不平等的起源和基础</h3><p>这本书是我在看《心理测量者》动画的时候提到的，在看小说的时候也见到过。于是就拿来读了一下，<code>Kindle Unlimited</code>  的会员可以在 Amazon 商店免费借阅到。</p><p>《论人类不平等起源和基础》是卢梭应法国第戎科学院的征文而撰写的第二论文，第一篇论文是《论科学与艺术的复兴是否有助于使风俗日趋纯朴》。在本书中，卢梭阐发了自身的政治哲学，为《社会契约论》的写作奠定了基础。卢梭将人类历史的发展过程视作进步与退化的矛盾统一体。他一方面借助当时有关自然状态下人的人类学材料，一方面展开辩证的想象，回顾了人类由自然状态向社会状态过渡的历史进程，指出人类的进步史同时也是人类的堕落史，因为人类每向前发展一步，不平等的程度即加深一步。而私有制的确立，是造成人类不平等及其后果的关键环节。</p><p>正是这样的假设，使人们得以明白“我们并非生来如此”，只是“已然如此”。既然处于自然状态下的人类只是一个抽象化的形象，即一种“无”的境界，那么我们当然不能说卢梭的目的是让人类回到这个本就不存在的形象了。他只是企图以这个“无”的境界为起点，向人们展示出人类是如何一步步变成现在的样子，从而进一步思考，要想摆脱现在的困境，我们所需要做出的努力。本文为我们提供的反思就像那高速路上的缓冲带，只有停留在缓冲带上的那一秒钟，人类才终于真正地思考。</p><p><code>摘抄</code> <a href="https://t.co/oTmpnrHLKS" target="_blank" rel="noopener">论人类不平等的起源和基础</a></p><h3 id="论科学与艺术的复兴是否有助于使风俗日趋纯朴"><a href="#论科学与艺术的复兴是否有助于使风俗日趋纯朴" class="headerlink" title="论科学与艺术的复兴是否有助于使风俗日趋纯朴"></a>论科学与艺术的复兴是否有助于使风俗日趋纯朴</h3><p><code>摘抄</code> <a href="https://t.co/Vsq6Lc1FeW" target="_blank" rel="noopener">论科学与艺术的复兴是否有助于使风俗日趋纯朴</a></p><h3 id="社会契约论"><a href="#社会契约论" class="headerlink" title="社会契约论"></a>社会契约论</h3><p>按照卢梭的第一篇论文《论科学与艺术的复兴是否有助于使风俗日趋纯朴》和第二篇论文《论人类不平等的起源和基础 》的分析，人本来是纯朴善良的，由于有缺陷的社会制度，生活于社会中的人才变坏，并堕入罪恶的深渊。由文明引发的问题必须通过新的政治组织形式来加以克服。《社会契约论》要做的工作是，通过建立一个健全的社会政治制度，帮助人们恢复自然良善（natural goodness）。</p><p>《社会契约论》的核心思想是：合法的国家必须根据普遍意志来进行管理。想要读懂这本书还需要读卢梭的另外两篇论文，第一论文（《论艺术与科学》）和第二论文论人类不平等的起源和基础》，卢梭主要思考的是文明社会中种种罪恶与不幸，并解释它们的起源；那么，从《社会契约论》开始，卢梭则致力于思考如何改变这种状况。</p><p>什么样的社会政治制度才是健全的呢？这就要追问一个核心问题：正义与合法的政治秩序及其基础是什么？《社会契约论》所有其他的问题均是从这里生发出来，并与之关联在一起的。《社会契约论》共有四卷，第一卷讨论的是合法的政治秩序的基础；第二卷讨论的主题是法律和立法；第三卷的主题是普遍意志运用于特定情形即政府的机制；第四卷，这一卷以对罗马的政治制度的描述为核心内容，以此来探讨政治共同体的凝聚力问题，最后以公民宗教结束全书。</p><p>《社会契约论》的核心思想就是<strong>合法的国家必须根据普遍意志来进行管理，即已提出</strong>。《爱弥儿》背后的一个基本预设是：没有文化做支撑，制度是没有办法有效运行的。因此，最重要的任务是：通过教育，将“人”转变为“公民”，像爱弥儿一样的公民。唯其如此，普遍意志才有可能，正义而合法的政治秩序才有可能。</p><p>按照第一论文和第二论文的分析，人本来是纯朴善良的，由于有缺陷的社会制度，生活于社会中的人才变坏，并堕入罪恶的深渊。由文明引发的问题必须通过新的政治组织形式来加以克服。《社会契约论》要做的工作是，<strong>通过建立一个健全的社会政治制度，帮助人们恢复自然良善。</strong> 找到一种结合形式，凭借它可以运用所有共同的力量来捍卫和保护每个结合者的人身和财产，这种形式使得每个结合者虽然与所有人结合在一起，但是只服从自己，并且一如既往地自由。”这就是社会契约所要解决的根本性问题。社会契约可以简化为如下词句：<strong>我们中的每个人将其自身及其所有的力量共同置于普遍意志的最高领导之下，而将每个成员作为整体不可分割的部分纳入整体。</strong> 在《爱弥儿》背后的一个基本预设是：没有文化做支撑，制度是没有办法有效运行的。因此，最重要的任务是：通过教育，将“人”转变为“公民”，像爱弥儿一样的公民。唯其如此，普遍意志才有可能，正义而合法的政治秩序才有可能。所依理解卢梭的思想，最好是从第一篇论文、第二篇论文、社会契约论、爱弥尔 这样的顺序读完。</p><p>所以卢梭的这几本书连贯性很强，都读完才能理解卢梭的政治哲学思想。</p><p><code>摘抄</code> <a href="https://kindle.502.li/" target="_blank" rel="noopener">社会契约论</a></p><h3 id="新常识：一党专政的性质与后果"><a href="#新常识：一党专政的性质与后果" class="headerlink" title="新常识：一党专政的性质与后果"></a>新常识：一党专政的性质与后果</h3><p>这本书是张雪忠教授写的，写作风格和张千帆、许章润、张维迎他们一样。比较喜欢这样的老师，关于张雪忠教授，维基百科上有一段：</p><blockquote><p>2013年5月，张雪忠首先在网络公开一份中国官方的“<a href="https://zh.wikipedia.org/wiki/七不讲" target="_blank" rel="noopener">七不讲</a>”的内部材料的内容。其后得到其他学者和教授的证实。“七不讲”是中共中央在2013年在意识形态领域的指令，确定七个领域为禁区：<a href="https://zh.wikipedia.org/wiki/普世价值" target="_blank" rel="noopener">普世价值</a>、<a href="https://zh.wikipedia.org/wiki/新闻自由" target="_blank" rel="noopener">新闻自由</a>、<a href="https://zh.wikipedia.org/wiki/公民社会" target="_blank" rel="noopener">公民社会</a>、<a href="https://zh.wikipedia.org/wiki/公民权利" target="_blank" rel="noopener">公民权利</a>、中国共产党的历史错误、<a href="https://zh.wikipedia.org/wiki/权贵资产阶级" target="_blank" rel="noopener">权贵资产阶级</a>、<a href="https://zh.wikipedia.org/wiki/司法獨立" target="_blank" rel="noopener">司法独立</a>。随后“七不讲”成为网络禁词，张的新浪微博再次被删号。<a href="https://zh.wikipedia.org/wiki/张雪忠#cite_note-rfa2-6" target="_blank" rel="noopener">[6]</a></p></blockquote><p>这一件事不得报道、那一本书不得出版、这句话不能讲，删贴封号等，表面上言论审查是在侵犯言论自由，但实质上却是在贬低全体国民的人格和尊严。言论审查完全是在向全体国民宣告：“你们这帮屁民根本就没有资格了解这件事情的真相，也没有资格去思考和辨别信息的真假。”，价值判断的标准由真理部说了算。一个人与一头猪的最大区别，就在于人具有猪所没有的理智，而言论审查恰恰是在剥夺人们自由运用理智的资格，也就是尽量缩小人与猪之间的差别。专制统治者确实希望国民忘记自己是有理智的动物，并能像猪一样容易满足，只需有足以果腹的食物，就会对统治者感恩戴德。</p><blockquote><p>全体国民作为主权者组建政府并选任执政者，本是为了更好地保护自己的生命、财产和自由。政府的目的和执政者的使命，是保护主权者本来就享有的权利和自由，而不是赐予主权者本来不享有的权利和自由。执政者认为国民的权利和追求幸福的机会，是源于自己的赏赐，就像子女认为父母的存在是出于自己的意志一样荒谬和悖理。</p></blockquote><p><code>摘抄</code> <a href="https://t.co/1vyK1t0NMr" target="_blank" rel="noopener">新常识：一党专政的性质与后果</a></p><h3 id="中国国家治理的制度逻辑：一个组织学研究"><a href="#中国国家治理的制度逻辑：一个组织学研究" class="headerlink" title="中国国家治理的制度逻辑：一个组织学研究"></a>中国国家治理的制度逻辑：一个组织学研究</h3><p>这本书是春节的时候在家读完的，较之于张雪忠教授的《新常识：一党专政的性质和后果》，周雪光教授从组织学角度来进行分析中共国家治理得逻辑。对于这次得疫情来讲，再一次印证了书中所阐释的内容。<strong>即一统体制与有效治理：中国国家治理的一个深刻矛盾</strong>。不做过多评论，此书如同推特上的一些人推荐一样，很适合当下去看看，去分析一下这个官僚体制是多么地腐败和无能。就如《心理测量者》中所说的，<strong>我们始终承担着政府强加给我们的风险</strong>，这是权力集中化的必然结果。那些已经集中起来的权力绝对不会因为他美好的愿景而变得无害。那些死在武汉肺炎病毒之外的人不正是我们每个人都要承担的风险吗</p><p>在专制国家，权力不受约束的统治者，是普遍的政府腐败和各种社会问题的根由，也是人类文明社会最大的<code>病毒</code> 。也正是正是这个腐败无能的官僚体制欺上瞒下、删帖封号、维稳抓人、封杀言论、拘留记者、抓捕律师、造谣式辟谣等等作恶行为才导致的全球疫情大爆发。其实这些时刻伴随着我们，只不过是这次的病毒将这个体制的一个阴暗面揭露了出来而已，它腐烂到根里已经很久很久……</p><p>在极权主义体制下，国家一方面用意识形态蛊惑和麻醉人民，另一方面又用利用国家机器限制社会内部的直接交往，使之保持有利于国家控制的“原子化”状态。基于国家的绝对权力和整个社会的非结构化，国家能够根据自己的意志发起任何行动，包括政治或社会运动。这次的<code>疫情防卫战疫</code>不就是这个官僚体制发起的政治运动嘛？感染死亡人数作假，公信力不断地丧失。你能在这本书里找到很好的解释，书中也提到过上级来视察的时候，地方政府如何忽悠中央，以及各种权利关系之间如何共谋达到<strong>上有政策下有对策的</strong>。</p><p>『卡理斯玛权威的核心是，领袖以其超凡禀赋而得到追随者的拥戴和服从；而领袖则通过不断地创造“奇迹”来显示其超凡禀赋，以延续和强化这一合法性基础。 在经过了战争动荡，民生凋敝，丧权辱国的民族危机之后，中国大地有期冀奇迹、崇尚伟人的卡理斯玛权威的肥沃土壤。』</p><p>『任何挑战卡理斯玛权威的话语都会弱化甚至瓦解其合法性基础，因此话语垄断权是维系卡理斯玛权威的关键所在。建国以后，国家逐步通过官僚体制介入、控制以至垄断意识形态相关的领域，有效地杜绝了质疑或挑战卡理斯玛权威的潜在可能性』 这也是言论审查的根本原因吧，维护统治者的权力合法性。</p><p>在政治运行过程中，我们不难看到地方政府的各种做法（如在拆迁、严打、城管、信访等等过程中的具体所为）常常与法律条文相悖。地方政府的这些做法在很大程度上增强了基层政府解决实际问题的能力，但与此同时，它们不断地侵蚀弱化法治基础和法理观念。</p><p><code>摘抄</code> <a href="https://t.co/tl1mmh7z3t" target="_blank" rel="noopener">中国国家治理的制度逻辑：一个组织学研究</a></p><h3 id="国家建设与政府行为"><a href="#国家建设与政府行为" class="headerlink" title="国家建设与政府行为"></a>国家建设与政府行为</h3><p>读完《中国国家治理的制度逻辑：一个组织学研究》后在 Amazon 上搜索周雪光作者找到的书。与其说是一本书，其实更像是一册研究中国官僚体制的论文集，从学术角度来分析一些体制问题。</p><blockquote><p>作为所有权力集于一身的中央政府，主要需要完成两项基本任务：一是为广大百姓提供基本的公共服务，维持政权的长期稳定；二是保证下放给行政代理人的权力不被滥用，中央的政令能够畅通无阻。这两项任务本质上是冲突的：一方面，为了给广大百姓更好地提供公共服务，就必须尽可能把权力下放给基层政府，因为基层政府相对来说更了解当地民众对公共服务的偏好，更了解当地的具体条件；从公共服务的角度，集权者应该尽可能选择分权。另一方面，给定下级政府的官员目标和利益不同于中央政府，下级官员的行为不易监督，权力下放就意味着权力被滥用的危险，甚至被架空，而且权力下放越是到基层，监督就越困难，权力被滥用的威胁也就越大。</p><p>当政府默许或鼓励下级政府因地制宜时，后者可能按自己意图解读实施政策，随着政策实施过程的展开，执行灵活性越来越大，与这一主线的偏差距离越来越大，导致与原政策相去甚远的结果。</p></blockquote><p>结合这次疫情，不难理解为什么地方政府擅自封路封城的举措，即便这些举措已经明显地违反了法律（国务院颁布的规定），即便是因为封路而造成人员意外身亡，即便是一家四口在家打麻将也要被拉上街被<code>批斗</code>……中央政府也不会处罚地方政府。在这次疫情中，地方政府的一些行为已经违反了宪法，简称违宪行为，而所谓的<code>红袖章</code>仗着点手中的特权肆意侵犯着公民的权力。就如剩余价值被封杀的那期中罗新老师提到的：</p><blockquote><p>我们现在听很多人大谈<strong>战时状态</strong>，但随便一个行政官员就能够宣布”战时状态”吗？这必须是要经过最高立法机构决定的。封城或者诸如此类的极端措施带来的伤害，一定会比病毒本身还要大。</p></blockquote><p><code>摘抄</code> <a href="https://t.co/7oYY1ZTdAL" target="_blank" rel="noopener">国家建设与政府行为</a></p><h3 id="我们最幸福：北朝鲜人民的真实生活"><a href="#我们最幸福：北朝鲜人民的真实生活" class="headerlink" title="我们最幸福：北朝鲜人民的真实生活"></a>我们最幸福：北朝鲜人民的真实生活</h3><p>读完这本书就感觉到当今的朝鲜就如上世纪的中国<strong>十年文革基础上再加上三年大饥荒</strong>一样悲惨，这种纪实类的写作和《切尔诺贝利的悲鸣》以及《十个人的一百年》一样，沉重的历史感。我们都是被共产主义的极权专制独裁暴政统治蹂躏过的民族，感同身受的历史记忆，彷佛就在映射着当下一样，让人有种身在历史中感受它的存在一样。看看下面这几段摘抄，和文革时期的我们以及当下的我们又是何其的相似：</p><blockquote><p>  由于北韩太贫困，电力供应不足以维持电子监控，所以国家安全必须仰赖人力情报——告密。报纸偶尔会出现文情并茂的报导，描述勇敢的孩子纠举父母的违法行为。由此看来，因发表对当局不满的言论而被邻居告发也就不觉得奇怪了。</p></blockquote><blockquote><p>  北韩人学会吞下自己的自尊与捏住自己的鼻子。他们从农村动物的排泄物中挑出来未被消化的玉米粒。船厂工人发展处一种技术，原本储存粮食的货仓底部残留着腐臭黏腻的东西，他们将这些东西刮起了，放在地面晾干，从中可以拾取一点未烹煮过的稻米与其他可食用的谷物。</p></blockquote><blockquote><p>  孩子睡觉时要提防其他帮派偷走他们的少许余粮。此外也流传着许多诡异的故事，提到成年人把孩子当成猎物。不只用来发泄性欲，也当成食物。金赫听说有人对孩子下毒，杀死孩子，大卸八块吃下肚。在火车站后面，靠近铁道边，有些小贩在小火炉上煮汤煮面，据说浮在上面的灰色肉块就是人肉。</p></blockquote><blockquote><p>  各级督导例行性地捏造农业生产与工业产出的统计数据，因为他们不敢告诉长官实情。为了圆谎，只好说更多的谎，从基层传达到高层的讯息没有一件是真的，所以可以想见金日成本人恐怕完全不知道经济的状况有多糟。</p></blockquote><p>看完这本书也可以去看另外一本书《黄长烨回忆录》</p><blockquote><p>  我在一个充满了虚伪和欺骗的社会生活了很久，一开始我以为虚伪和欺骗是为了解放勤劳的人民大众，即为了取得与剥削阶级斗争的胜利而必须采用的手段。 但是，后来我意识到，虚伪与欺骗已经与独裁者的利己主义结合起来。独裁者的利己主义集中体现为个人崇拜思想，北朝鲜是全世界个人崇拜和阶级主义最严重的国家。 我身处北朝鲜统治体制的中枢，是整个虚伪宣传的动员和组织者（作者是北朝鲜马克思主义和意识形态领域的权威，译者注）。虚伪曾经一度取代真理占据一个学者的良心，与学者的灵魂对立。 我（在书中）不会因为讨厌我和让我讨厌的人而夸大、丑化事实，也不会因为爱我和让我爱的人而毫无原则的美化现实。 历史就摆在那里，对历史来说，歪曲是最大的犯罪。我不认为我说的就是绝对（正确），我反倒更希望读者带着批判的态度来阅读本书。 对于与大众利益毫无关系的个人生活，或者有干涉它国内政之嫌的言论，我会尽量避免。来到韩国之后，我在努力学习新事物，开始新的体验。 但是，我已经老了，学到的新知识和新经验对我思考方法的影响有限。在本书中，我还是想将在北朝鲜经历过的、体验过的写出来。</p></blockquote><p>摘抄<a href="https://t.co/LWaF4VeGVq" target="_blank" rel="noopener">我们最幸福：北朝鲜人民的真实生活</a></p><h3 id="哈维尔文集"><a href="#哈维尔文集" class="headerlink" title="哈维尔文集"></a>哈维尔文集</h3><p>三月份在读《我无罪：刘晓波传》的时候意外收获到的这本书。这本书并没有在大陆公开出版，只能找到一点电子版的来看。本书的作者是哈维尔，大陆的译者是崔卫平。先说一下作者哈维尔，他是东欧人民战胜共产主义之后，1989年12月当选的总统。在他主持下，捷克和斯洛伐克和平分离，他又当选为捷克共和国首任总统，直到2003年连任期满，才卸任总统职务。</p><p>作为一位戏剧家、作家和哲学家，他是著名《七七宪章》运动的发起者和最早的发言人之一，他的思想深刻地影响了中国自由知识界。1998年一批中国的自由知识分子，要出版《哈维尔文集》，八九民主运动中“不在枪口下做官”的前中国社会科学院副院长 <a href="https://zh.wikipedia.org/wiki/%E6%9D%8E%E6%85%8E%E4%B9%8B" target="_blank" rel="noopener">李慎之</a>，为该书写了序——<a href="http://www.aisixiang.com/data/1724.html" target="_blank" rel="noopener">《无权者的权力和反政治的政治：后极权主义时代的人生哲学》</a>。</p><p>李慎之称哈维尔是“我们时代杰出的思想家”。 哈维尔提出“无权者的权利”的哲学命题，揭示了“<strong>因为恐惧，整个社会的谎言有了最现实也最妥当的理由，其结果就是责任感，对自己的良知的责任感，对社会正义的责任感的丧失</strong>。”李慎之认为哈维尔的这一学说“至今仍旧是对极权制度最深刻的批判。”哈维尔发动的《七七宪章》运动，就是公民行使自己的权利，敢于讲真话的运动。李慎之称赞哈维尔：“他最大的功绩就在于教导人们如何在后极权主义社会尊严地生活，做一个真正的人。”</p><blockquote><p>  因为恐惧。每个人都有东西可以失去，因此每个人都有理由恐惧：“因为害怕失去自己的工作。中学老师讲授他自己并不相信的东西，因为怕自己的前途不稳；学生跟在老师后面重复他的话，因为怕自己不被允许继续学业；青年人加入共青团，参加不论是否必要的活动。在这种畸形的制度下，因为恐惧自己的儿子或女儿无法在学校里取得必要的升学总分，使得父亲采用‘自愿’的方式去做每一件被要求的事。恐惧的结果，导致人们参加选举、给推荐出来的候选人投票，并且假装他们认为这种形同虚设的走过场是真正的选举。出于对生计、地位或者前程的恐惧，他们投票赞成每一项决议，或者至少保持沉默……。”</p><p>  怎样才能打破这种因处于恐惧之中而凭借谎言生活的现实呢?哈维尔的答案十分简单，即“在真实中生活”，或曰“在真理中生活”，英文是Living in Truth!这句话看起来太理想、太虚无飘渺，但是我倒也不想建议译者改变译文，因为如果用大白话来说，它无非是指“过说真话的日子”或者是“生活在真话中”、“做一个说真话的人”而已。</p></blockquote><p>摘抄<a href="https://t.co/3yjW5T3OW4" target="_blank" rel="noopener">哈维尔文集</a></p><h3 id="布达佩斯往事：冷战时期一个东欧家庭的秘密档案"><a href="#布达佩斯往事：冷战时期一个东欧家庭的秘密档案" class="headerlink" title="布达佩斯往事：冷战时期一个东欧家庭的秘密档案"></a>布达佩斯往事：冷战时期一个东欧家庭的秘密档案</h3><p>在二月份的时候剩余价值里的一期节目中提到过《布达佩斯往事：冷战时期一个东欧家庭的秘密档案》。本书通过冷战时期匈牙利秘密警察长达20年的档案，所揭开的是一部隐藏了几十年的家庭历史和时代侧记。</p><p>冷战时期，苏联集团中的匈牙利，秘密警察通过庞大的告密网，试图全面渗透控制匈牙利的政治生活。作者的父母原是匈牙利著名记者，他们的报道是西方了解匈牙利的重要信息来源。因此他们被视为“人民的敌人”，长期受秘密警察的监控，终因叛国和间谍罪而先后入狱。一家移居美国后，匈牙利政府却又异想天开地试图招募他们当间谍，而美国也对他们进行了几年的监控。书中不只还原了马顿夫妇被告密者包围的经历和遭遇，他们的抗争、坚守、脆弱和勇气，也展现了他们情感和内心的矛盾——夫妻之间相互的感情背叛与灾难中的支撑，父母子女之间的爱与亲情，人性的坚强与软弱，从而使得这本书更为丰富、复杂，具有血肉。</p><p>值得一提的是这本书，而这本书的序言正是徐贲老师写的。</p><blockquote><p>  这种统治下的恐惧、屈辱、压抑和绝望，这样的苦难让熬过来的和还未熬过来的人们都更加期待一个能让所有人自由、平等、有尊严的生活世界，也更加期待一种人与人能够彼此信任，而不是相互背叛、出卖的生存方式。这种期待中包含着对人类未来的希望，《布达佩斯往事》之所以感人，正是因为它传递了这样的希望讯息。</p></blockquote><p>摘抄 <a href="https://t.co/NmRoJATcau" target="_blank" rel="noopener">布达佩斯往事：冷战时期一个东欧家庭的秘密档案</a></p><h3 id="人以什么理由来记忆"><a href="#人以什么理由来记忆" class="headerlink" title="人以什么理由来记忆"></a>人以什么理由来记忆</h3><p>之前我也读过徐贲的论文 <a href="https://matters.news/@philosophia1979/徐贲-中国的-新极权主义-及其末世景象-野兽荐读-bafyreiegbg5tti3ljc7newaah5wp36ncf7fvb2oaovd6p7elc4xqfhbcd4" target="_blank" rel="noopener">《中国的“新极权主义”及其末世景象》</a>) ，所以对他关注的内容也有所了解。总感觉这本书更像是阿伦特、加缪、萨特、哈维尔等人对于极权主义著作及思想的解析。就像在剩余价值里提到的，我们读这些历史的时候，而当下就仿佛置身于历史之中一样。书中记录苏联和纳粹德国极权统治改造人性的言论审查、秘密警察、集中营、无言论自由和新闻自由、党媒愚民洗脑等，这些描述极权统治的历史，再看一看当下，我们不正置身于其中吗？</p><ul><li><strong>比瘟疫更可怕的是謊言，比災難更可怕的是遺忘</strong></li></ul><blockquote><p>  <strong>剩余价值：</strong> 李海鹏之前发了一条微博，大概是说，一个举国体制的隐患到最后可能又会变成一个举国体制的胜利。</p><p>  <strong>罗新：</strong>历史学者认为，在西方，你看到所有的战争、灾难性的革命或者是体制性的崩溃，其后果可能是引起了一波新的历史上升期。比如美国在经济大萧条之后，经济反而有所回升，反而开通了一条向上爬的新的道路。但是研究者也发现，在东方不一定是这样，灾难之后可能是更大的灾难，更大的灾难后面还有更大的灾难，引发灾难的那些因素不仅得不到修正，还得到了加强化。这是我们要注意的。人们说，都发生了这么大的事，我们该不该反思了？要小心，可能没有反思，可能是强化。</p></blockquote><p>一场灾难变成了一场举国体制的胜利，是我们的悲哀也是全世界被新冠病毒折磨人的不幸。一些无耻的人丧尽天良还在宣传什么正确的集体记忆，抗疫主旋律，好多人的生命就这样被宏大叙事抹杀掉了。</p><blockquote><p>  因为抗疫叙事不能被谎言误导玷污，而应留下正确的人类集体记忆</p></blockquote><p><img src="https://p.k8s.li/image-20210106235706623.png" alt=""></p><p><img src="https://p.k8s.li/image-20210106235547786.png" alt=""></p><blockquote><p>  “对于一个民族来说，记忆对遗忘的抗拒，首先是知识精英的良知对强权的抗拒。否则的话，我们非但无法把六四大屠杀的真相、进而把独裁制度的罪恶变成民众的历史常识，也无法防止类似大悲剧的重演。难道中国历史在专制下恶性循环的时间还不够长吗？”</p></blockquote><p>最终，因为遗忘罪恶历史而受害的，只会是中国人自己。</p><p><strong>“用民间记忆抗拒官方的强制遗忘，就是为我们这个历尽苦难的民族保存记忆和良知。”</strong></p><blockquote><p>  人民“获得”的“国家历史”是那些记录下来，或者说被权力允许记录下来的“事件”，而那些没有被记录或不被允许记录下来的事件，就此被武断地从国家历史中剔除，也从族群记忆中排斥出去了。因此，对历史真实保持沉默，虽然是从改写历史开始，但最终却表现为族群的集体忘却。每个沉默的个人，每个在族群中按权力意志来记忆或忘却的人，都参与在以沉默代替真实，以沉默维持谎言的共谋之中。</p></blockquote><p>想起了 《1984》 里的一段话，或许用极权主义来解释当下最适合不过了：<strong>极权最有效的统治术是仇恨教育，塑造一个远在天边的外在敌人，人们就会忘记身边的痛苦。</strong></p><p>摘抄 <a href="https://t.co/qZ2ID5XeuR" target="_blank" rel="noopener">人以什么理由来记忆</a></p><h3 id="颓废与沉默：透视犬儒文化"><a href="#颓废与沉默：透视犬儒文化" class="headerlink" title="颓废与沉默：透视犬儒文化"></a>颓废与沉默：透视犬儒文化</h3><p>恰好读完这本书之后不久 B 站就上映了后浪洗脑宣传片，不料微博评论区也是翻车现场🤣</p><p>第一次听说到后浪的时候我就觉着，这类身居高位的犬儒知识份子，如胡锡进、胡鞍钢、金灿荣、张维为这类，为当权者歌功赞德、拍马溜须、谄媚献媚、阿谀奉承。这类人应该比任何人都清楚在这太平盛世的背后，抓捕了多少维权律师、迫害了多少异议人士、关押了多少公民记者、处分了多少直言教师。然这些知识分子、教授、专家在说假话，用所谓的”学术”来取悦和投靠权力和当权者,谋取私利，以貌似高深、渊博、精致的理论包装普通人用常识就能看穿的慌言，有的甚至还相当”富有创意”，善于”理论更新”,或有”理论建树”。</p><p><img src="https://p.k8s.li/image-20210106235133212.png" alt=""></p><p>在政治意识形态主导一切,权力可以操控一切的社会里,不存在所谓的”独立学术”,尤其不存在独立的人文学术。一些知识分子因为不得已而做”纯学问”,是一种憋屈的学术”自宫”。权力的咸胁与利诱造就体制性的”学术义儒”,它往往是一种在清醒状态下的装傻——一面自嘲,一面配合体制,积极自我审査；一面咒骂,一面迎合体制的无理要求；一面鄙视不懂学术的顶头上司,一面顺从他们的领导权威；一面嘲笑,一面参与为官员授予各种真的假学位和假头衔。</p><blockquote><p>  阿伦特在1963年7月24日给友人卡斯贝尔（Gerhard Casper）的信里写道:”人们经常发现,洗脑欺骗最肯定的长期后果就是造成犬儒主义——绝对不相信任何事情可能是真的,哪怕是确有实据的真实,也照样不相信。换言之,完全用谎言来代替事实真相的结果不是人们会把谎言当作真实,或者真实会被当作为谎言,而是我们赖以在真实世界里存在的知觉会被完全摧毁。人类为了生存,必须具备基本知觉,其中就有对真和假的识别。”</p></blockquote><blockquote><p>  阿伦特认为,社会中的多数人集体投向犬儒主义,是因为政治权力长期用谎言来代替真实,大规模地对群众进行洗脑并欺骗他们。这是20世纪才有的统治方式,最典型的例子就是斯大林统治时期否认托洛茨基曾对俄罗斯革命有过任何贡献。阿伦特称此为”极权谎言”,它要编造的是一种完全虚假的,因此彻底颠覆真伪区别的”真实”。</p></blockquote><p><strong>犬儒主义：</strong></p><ul><li>（1）娱乐至死（没有目标或信仰,得过且过）；</li><li>（2）看客心态（看穿、冷漠、围观,管了也没用,不如不管）；</li><li>（3）习惯性怀疑（上至政府,下至朋友,对谁都不信任,都不相信）；</li><li>（4）审丑心理（在一个是非不分的环境里,美丑、善恶、真假也无法辨别,何必要坚持真、善、美）；</li><li>（8）”鸵鸟心态”（多一事不如少一事,被宣传的现实反正是假的,不如”躲进小楼成一统”）;</li><li>（9）思考恐惧症（多思多惹事,有的是前车之鉴,你要我怎么说,我就怎么说,这才是安身保命之道）；</li><li>（11）炫富心态（看穿一些道德、理想、未来展望的虚妄,只有钱才是实在的,才是世人认可的唯一价值）；</li><li>（12）初老症（没有前途、没有未来、没有追求,过一天算一天,坐吃等死）；</li><li>（13）自虐心态（这个说法并不确实,因为一般人既非共产党又非体制,不是”自虐”,这种顾左右而言他的说法,明白人说糊涂话,既不诚实,也不真实,它本身就是犬儒主义的）。</li></ul><blockquote><p>  对犬儒的现代定义是有代表性的:一、挑刺、嘲笑、讽刺；二、不相信或装着不相信普通人接受的道德价值观和人类行为真诚的善良动机,把自私自利认作唯一可能的动机；轻蔑、鄙视、嘲讽的怀疑和不相信。</p></blockquote><p>刘晓波曾在 <a href="http://www.liu-xiaobo.org/blog/archives/12412" target="_blank" rel="noopener">刘晓波：在刀锋上行走——狱中读《布拉格精神》</a> 写过：</p><blockquote><p>  据克里玛的介绍，在前苏东极权下的捷克知识分子群体中，不仅出现了哈维尔这样的道义示范，而且有95％以上的人为了自由和良知而进行着各种形式的拒绝，只有不到5%的人甘愿堕落为卖身投靠者。这当然是让中国知识分子自觉羞愧的表现。我们没有捷克人那种清醒和坚韧，仅仅十年的时间，六四的伤口便被遗忘，这不光是因为官方的强制，也是民族灵魂的冷漠。知识分子群体不能以言行来洗刷耻辱，既源于外在的政治恐怖，更源于他们生命中洗刷耻辱的冲动已经死亡。</p></blockquote><p>摘抄<a href="https://t.co/3C2OUjki3P" target="_blank" rel="noopener">颓废与沉默：透视犬儒文化</a></p><h3 id="统治与教育：从国民到公民"><a href="#统治与教育：从国民到公民" class="headerlink" title="统治与教育：从国民到公民"></a>统治与教育：从国民到公民</h3><blockquote><p>  极权政体彻底控制与思想、言论、新闻有关的要害领域，教育是被管制得最严厉的领域之一，和宣传一样，被严格控制。这样的教育虽然与民主国家的教育一样被称为“教育”，但实际上已经成为政治权力控制国民思想和培养子民的工具。这与民主国家中学校教育作为公民社会文化机制的一部分，起到培养民主公民的作用，是完全不同的。</p></blockquote><blockquote><p>  纳粹统治德国，依靠的不仅是完全由纳粹控制和操纵的国家机器，政府、各级纳粹党组织、党卫军、冲锋队、警察等，而且更是无处不在的纳粹意识形态，它渗透到德国社会、文化、教育和家庭生活的每一个角落，确保纳粹政党成为德国主权的内核。正是由于纳粹政党实际上已经成为德国主权的内核，德国的国家主义才会按照纳粹的意志转变为符合纳粹党利益，并为它的利益服务的党国主义。</p></blockquote><blockquote><p>  在纳粹的极权统治制度中，学校进行的是一种由统治政党意识形态指挥的党化教育。这种党化教育渗透到教育的每一个环节之中，而在每一个环节中使这种党化意识形态顺利发生作用的正是无数直接从事教学工作的教师。党化教育迫使人们不断进行思想的相互纯洁和自我纯洁，它在课堂里发生之前，早就先已经在许多教师的头脑中发生了，并成为他们的思维和行为习惯。没有这样的教师，党化教育是不可能在学校里有效贯彻的。</p></blockquote><blockquote><p>  在极权国家里，国民必须有相同的正确表现，教师在学校里的行为被完全模式化了。教师们都忠于党，按党的要求去做，他们在学校的行为并不仅仅是“好教师”行为，同时也是“好国民”行为。当一个“好国民”，就是像所有其他国民一样对领袖、党和党国表现绝对的忠诚。“</p></blockquote><blockquote><p>  纳粹德国实行的是一种彻底的以国家主义为旗号的党化教育，这种教育从儿童开始，在课程、教学、教材、师生关系的每一个环节上都贯彻纳粹的极权统治原则。</p></blockquote><blockquote><p>  在《极权主义的起源》一书中，汉娜·阿伦特从极权主义原型的特点中概括出它成功统治的三大要素，它们分别是暴力和恐惧的统治，迫使人民成为相互隔绝的、无助无援的散沙个体，以及充分运用“组织”和“宣传”的力量。阿伦特亲身经历过她所思考的极权主义中最为成功的一种，那就是德国纳粹的极权。她对极权主义三要素的总结便是从她的直接经验中观察得出的。</p></blockquote><blockquote><p>  党的宣传要求新闻从“正面报道”，所以总是尽量不让坏消息曝光。它认为，坏消息不利于稳定人心，也可能被别人利用，所以，坏消息也成为一种不能泄露的“国家机密”。</p></blockquote><p>摘抄 <a href="https://t.co/PoWTqUQOQ7" target="_blank" rel="noopener">统治与教育：从国民到公民</a></p><h3 id="我無罪：劉曉波傳"><a href="#我無罪：劉曉波傳" class="headerlink" title="我無罪：劉曉波傳"></a>我無罪：劉曉波傳</h3><p>这本书是我在 <a href="https://twitter.com/linyujing" target="_blank" rel="noopener">林愈靜</a> 立场新闻的文章里上发现的。之前我是知道刘晓波是诺贝尔和平奖得主，也知道他的一些事迹，但通过这本传记才真真切切地了解到刘晓波是一位多么坚强的知识份子。包括独立中文笔会的发展，都离不开刘晓波先生的付出。</p><blockquote><p>劉曉波承認：「類似的殘忍行為以及對殘忍的自得其樂，我小時候沒少幹。這種行為與專門打砸搶、揪鬥別人的紅衛兵沒有什麼實質的區別。我們這些人，在一種野蠻的制度和教育之下長大，它崇尚暴力、培養仇恨、鼓勵殘忍、縱容無情，教給孩子們一種從娘胎裡帶出來的不拿人當人的殘暴兇狠。在視生命如草芥的年代，我們都在不同的程度上充當過劊子手和幫兇，誰也脫不掉責任，洗不清自己！」</p></blockquote><blockquote><p>我的整個青春期生長於文化沙漠之中，我所賴以寫作的文化滋養，除了仇恨、暴力、狂妄，就是說謊、無賴、犬儒，這些黨文化的毒素餵養了整整幾代人，我便是其中之一，即便在思想解放的八○年代，也並沒有完全擺脫黨文化。</p></blockquote><blockquote><p>劉曉波強調了言論自由的重要性：「一個政權不可能靠壓抑不同政見來建立合法性，也不可能靠文字獄來達成長治久安。」他呼籲中國早日告別文字獄：「只有從制度上根絕文字獄，憲法所規定的言論自由權利才能落實到每一位國民身上；只有當國民的言論自由權利得到制度化的現實保障，文字獄才會在中國大地上滅絕。」</p></blockquote><p><code>摘抄</code> <a href="https://t.co/eefs4gZspV" target="_blank" rel="noopener">我無罪：劉曉波傳</a></p><h3 id="Age-of-Ambition"><a href="#Age-of-Ambition" class="headerlink" title="Age of Ambition"></a>Age of Ambition</h3><p><code>摘抄</code> <a href="https://t.co/uvCqxbUb0i" target="_blank" rel="noopener">Age of Ambition</a></p><h3 id="自由宪章"><a href="#自由宪章" class="headerlink" title="自由宪章"></a>自由宪章</h3><p>《自由宪章》是这大半年来最难啃的书，哈耶克的书对于木子这种菜鸡来说读起来就是头大啊，和我在一月份读的《自由与繁荣的国度》味道一样。</p><p><strong>弗里德里希·哈耶克</strong>（Friedrich A·Hayek）是奥地利经济学家和政治哲学家。身为1974年的诺贝尔经济学奖的获得者之一，他主张以市场为基础的自由资本主义和有限的政府。此外，他还于1991年获得了总统自由勋章。</p><p>在这本书中，单单法治概念的含义，哈耶克本人就罗列引用了 30 多本著作！可见当时哈耶克本人的学术水平相当高滴！</p><blockquote><ul><li>《法律与秩序》</li><li>《教会、国家与研究》</li><li>《新利维坦》</li><li>《美国的行政司法及法律的最高地位》</li><li>《宪政政治与民主》</li><li>《政治与行政》</li><li>《现代共同体的基础》</li><li>《对良好社会原则探索》</li><li>《宪政与变动中的世界》</li><li>《民主国家与集权国家》</li><li>《行政与法治》</li><li>《现代政治诸要素》</li><li>《法治：保守的伦敦律师公会与工会协会进行的研究》</li><li>《法律：有关民主之中的权威的理论的论文》</li><li>《个人主义与法律》</li><li>《宪法学》</li><li>《宪法之保卫者》</li><li>《法治国家，还是独裁？》</li><li>《政治学》《法治国家有效性的界限》</li><li>《法治国家还是威权国家？》</li><li>《自由主义作为一种意识形态的没落》</li><li>《波恩基本法中的社会法治国家概念》</li><li>《作为刑法最新发展的中心概念的法治国家》</li><li>《法、国家、经济》</li><li>《从法律国家到法官国家》</li><li>《瑞士联邦国家法》</li><li>《德国行政法的体制》</li><li>《瑞士联邦法院的宪法管辖权》</li><li>《法制国家民主制》</li><li>《美国与瑞士宪法管辖权的政治意识形态上与法律意识形态上的根据》</li><li>《作为国家根本法律秩序的宪法》</li><li>《瑞士法律中的公民自由》</li><li>《法治国家的秩序》</li><li>《1955年雅典国际法学家大会报告》</li></ul></blockquote><p>虽然这本书早在1960年就已出版，但其深刻的见解时至今日仍然盛行。他所倡导的经济和个人自由理论适用于很多当今的热议话题，从物价上涨到累进税制。在书中，作者对比了建立有限政府的益处和实施中央计划经济的弊端。限制政府权力将会有利于提升个体能动性和创造力，进而推动人类知识和文明的进步。哈耶克论证了法律法规、合法程序和宪法政府对自由的积极作用，并指出个人自由所面临的严峻的潜在威胁。以下是本书的几个要点：</p><ul><li>有限的政府通过激发人的个体主动性来推动社会的进步。</li><li>财产权利和个人自由这一宽泛的政治概念有着密切的联系。</li><li>只有那些与约定俗成的道德观念相符的法律才能经得住时间的考验。</li><li>多数裁定原则自然很有必要，但仅仅依靠它还不足以建立一个自由社会。</li><li>宪政是美国追求自由事业最有力的武器。</li><li>社会主义是一种失败的政府形式，但它至今依然影响着公共政策的制定。</li><li>通过收入再分配来缓解贫困会带来意想不到的负面效应，比如“福利国家”的出现。</li><li>基于市场状况的奖励制度比基于个人优点的奖励制度更加有效。</li><li>比起通货紧缩，政府更倾向于通货膨胀。但过度的膨胀会威胁到自由。</li><li>限制政府对教育的干涉有利于社会保持思想活力。</li></ul><p><img src="https://p.k8s.li/image-20210106235239532.png" alt=""></p><p>摘抄 <a href="https://t.co/t1GhiJgIsa" target="_blank" rel="noopener">自由宪章</a></p><h3 id="一想到还有百分之九十五的问题留给人类-我就放心了"><a href="#一想到还有百分之九十五的问题留给人类-我就放心了" class="headerlink" title="一想到还有百分之九十五的问题留给人类,我就放心了"></a>一想到还有百分之九十五的问题留给人类,我就放心了</h3><p><code>摘抄</code> <a href="https://t.co/HX1EXtz2oZ" target="_blank" rel="noopener">一想到还有百分之九十五的问题留给人类,我就放心了</a></p><h3 id="被讨厌的勇气"><a href="#被讨厌的勇气" class="headerlink" title="被讨厌的勇气"></a>被讨厌的勇气</h3><p>无意间在 <a href="https://sanshiliuxiao.top/talkSelf/20191212/" target="_blank" rel="noopener">椎咲良田|想不到啥标题</a> 发现了这本书。</p><blockquote><p>书里面有很多的观点一开始都挺让人难以接受的，就像那位去寻求哲人帮助的青年，不去接受哲人的观点，心里想着根本就不是哲人说的那样，决定要去好好反驳他。可是仔细想想，哲人说的话也算是蛮有道理的。整本书中哲人说的一些言论，如果单单只拆出一段或一句，就会觉得这个哲人是在强词夺理，可是他的话里面有着是有很多的前置条件，如何结合着一起看，那就会感觉不一样。</p></blockquote><p>先说一下我自己的感受吧，读完这本书确实改变了我一些根深蒂固的观念。我承认我有点极端心理，并且我很长时间把它归因于童年时期的家庭暴力，我觉着是老爸的暴脾气影响了我的性格，以至于性格偏激、寡言少语、不善社交、自卑内向等。很长很长一段时间我都把这一切归责于老爸对我的家庭暴力，长久不能释怀。就在今年过年时在家还和老爸争吵怪他小时候打我才导致我性格偏激。</p><p>直到读完这本书，我才改变了这种幼稚的想法。<strong>我们并非因为自身经历中的刺激——所谓的心理创伤——而痛苦，事实上我们会从经历中发现符合自己目的的因素。决定我们自身的不是过去的经历，而是我们自己赋予经历的意义。</strong>经历本身不会决定什么。我们给过去的经历“赋予了什么样的意义”，这直接决定了我们的生活。不可以从过去中找原因；要否定精神创伤；人不是受过去原因支配的存在，人是为了达成某种目的而采取行动的。</p><p><code>摘抄</code> <a href="https://t.co/o6cc1csJI2" target="_blank" rel="noopener">被讨厌的勇气</a></p><h3 id="布拉格精神"><a href="#布拉格精神" class="headerlink" title="布拉格精神"></a>布拉格精神</h3><p>本书的作者是这本书的译者同样也是《哈维尔文集》的译者崔卫平。提到布拉格就不得不提 <a href="https://zh.wikipedia.org/zh-hans/%E5%B8%83%E6%8B%89%E6%A0%BC%E4%B9%8B%E6%98%A5" target="_blank" rel="noopener">布拉格之春</a> </p><p>推荐阅读 <a href="http://www.liu-xiaobo.org/blog/archives/5381" target="_blank" rel="noopener">刘晓波：读《布拉格精神》——狱中读书笔记</a> 和 <a href="http://www.liu-xiaobo.org/blog/archives/12412" target="_blank" rel="noopener">刘晓波：在刀锋上行走——狱中读《布拉格精神》</a></p><h2 id="自然-科学"><a href="#自然-科学" class="headerlink" title="自然/科学"></a>自然/科学</h2><h3 id="病毒星球"><a href="#病毒星球" class="headerlink" title="病毒星球"></a>病毒星球</h3><p>极为简短的一本科普，大概用了两个小时的时间就读完了。主要科普了一下病的性质以及入侵人体细胞的机理等。感觉读起来海星吧，没有太多精彩的地方，就像回顾了一下高中生物学。</p><p><code>摘抄</code> <a href="https://t.co/Op5GTfaOch" target="_blank" rel="noopener">病毒星球</a></p><h3 id="病毒来袭"><a href="#病毒来袭" class="headerlink" title="病毒来袭"></a>病毒来袭</h3><p>感觉没《病毒星球》要好一些，总之推荐前一本。</p><p><code>摘抄</code> <a href="https://t.co/kfTZIY7Zt0" target="_blank" rel="noopener">病毒来袭</a></p><h3 id="血疫：埃博拉的故事"><a href="#血疫：埃博拉的故事" class="headerlink" title="血疫：埃博拉的故事"></a>血疫：埃博拉的故事</h3><p>疫情期间在家看完的书，也有同名的纪录片，推荐两者都看一下。</p><p><code>摘抄</code> <a href="https://kindle.502.li/" target="_blank" rel="noopener">血疫：埃博拉的故事</a></p><h3 id="远古的葱茏：古植物王国"><a href="#远古的葱茏：古植物王国" class="headerlink" title="远古的葱茏：古植物王国"></a>远古的葱茏：古植物王国</h3><p>这本书主要讲了植物的起源、光合作用、叶绿体、孢子生殖以及一些远古时期的生态环境等。总之对于咱这种对古生物学感兴趣的来说算是一顿科普盛宴，学到很多知识耶，极大得满足了咱的好奇心😂。</p><p><code>摘抄</code> <a href="https://t.co/5KOfa96qlr" target="_blank" rel="noopener">远古的葱茏：古植物王国</a></p><h3 id="古生物学简明教程"><a href="#古生物学简明教程" class="headerlink" title="古生物学简明教程"></a>古生物学简明教程</h3><p>课本教材，枯燥、只是了解了一下基本的概念，感觉我不适合读这种枯燥的课本(￣▽￣)”</p><p><code>摘抄</code> <a href="https://t.co/G6oMMnAAji" target="_blank" rel="noopener">古生物学简明教程</a></p><h3 id="朱钦士的个人博客"><a href="#朱钦士的个人博客" class="headerlink" title="朱钦士的个人博客"></a>朱钦士的个人博客</h3><p>这并不是一本书，而是我在 <a href="http://blog.sciencenet.cn/home.php?mod=space&uid=582158" target="_blank" rel="noopener">朱钦士 </a>博士的个人博客上复制下来整理成的电子书，在 kindle 上读起来比较方便。对于只具备高中生物知识得咱来说，读起朱院士写的文章还是有些吃力的，感觉这基本上就是论文的注释版。里面的一些学术用语有很多都不懂，只能自己搜索了解一下。讲到了真核生物的起源，以及动物细胞和植物细胞的起源。咱们人类（动物）是从单鞭毛的原生生物领鞭毛虫（Choanoflagellate）演化而来，而植物则由双鞭毛原生生物中的双星藻（Zygmematales）演化而来，原来咱们的祖先是只鞭毛虫😂？</p><p>摘抄 <a href="https://t.co/50HX5FvBPk" target="_blank" rel="noopener">朱钦士的个人博客</a></p><h3 id="生命通史"><a href="#生命通史" class="headerlink" title="生命通史"></a>生命通史</h3><p>生命通史这本书是今年花了相当长的时间来读完的，之前在 <a href="http://blog.sciencenet.cn/home.php?mod=space&uid=582158" target="_blank" rel="noopener">朱钦士 </a>博士的个人博客上读了很多文章一直与犹未尽。</p><p>真核细胞是怎样形成的呢，书中解释为：真核细胞是先获得线粒体，再发展出细胞核。线粒体的出现给真核生物带来充足能源的同时，也带来了内含子的入侵。为蛋白质编码的基因中内含子的出现，又迫使细胞形成细胞核以把DNA和核糖体分隔开来。这大概就是真核细胞出现的根本原因。其它的改变都是在这个基础上进行的。转录和蛋白质合成必须在空间上分开，而这正是细胞核的作用。细胞核的膜能够防止完整的核糖体进入细胞，而mRNA在剪接完成前，又不会离开细胞核，这样核糖体能够接触的，就只能是加工完毕的 mRNA。</p><p>读这本书只需要基本的高中生物和化学知识就能读懂。从分子生物学和基因角度解释一些宏观的生命现象，比如有氧呼吸电子的传递；线粒体和叶绿体如何工作；三羧酸循环；基因表达如何控制控制个体的形成等等，都分析的十分精彩，总之相当于一本生命科学的“源码分析”。</p><p>另外值得令人倾佩的是《生命通史》这本书并没有任何人的推荐序，没有花里胡哨的吹嘘只有严谨务实的学术知识，在这浮躁的年代，很少能见到这样的书了。这本书在我心中的地位远高于《人类简史》等畅销书，因为这真的是一本适合自己来读的书😀。</p><p><code>摘抄</code> <a href="https://t.co/6PBLon5t09" target="_blank" rel="noopener">朱钦士的个人博客</a></p><h3 id="上帝造人有多难：生命的密钥"><a href="#上帝造人有多难：生命的密钥" class="headerlink" title="上帝造人有多难：生命的密钥"></a>上帝造人有多难：生命的密钥</h3><p>读完了朱院士的博客上的文章，就像打开了我的好奇心潘多拉魔盒，越来越像知道关于生命科学的知识，就在 Amazon 上搜了一下他的书，还真的有一本，就 get 到啦。</p><blockquote><p>这是一本从分子细胞尺度上讲解生命奥秘的科普小书。用平实浅显的语言解释了复杂生命系统的一些基本知识。 让我了解了人体是由60万亿个细胞组成的复杂系统，蛋白质对生命体的重要意义，了解了所有生物从分子层面上是基本一致的、具有共同的祖先。书中解释了先有蛋再有鸡的结论，解释了对牛弹琴的科学依据。给这些“千古奇案”以“科学定论”。还有很多平时我们体会到了但是没有深想的生命现象，作者都给出了有意思的描述和解释。 最后一章解释了神经系统的复杂程度，让我从生物学意义上了解了时下大热的人工智能深度学习技术的生物学基础。 不过，最后一章在全书中占了大约四分之一的篇幅，个人感觉用力不均。我是跳着看了些片段。 然而瑕不掩瑜，对于生物学小白来说，会让你入迷的。感谢作者！</p></blockquote><p>看这本书和他的博客一样精彩，另外还出了另一本书《生命通史》，看了一下目录和他博客里写的内容及其相似，等到以后再买本纸质版的看。想起来了大学时曾读过的一本书《生命的跃升》，我觉着二者之间比较相似。</p><p><code>摘抄</code> <a href="https://t.co/tjOSuGPhu7" target="_blank" rel="noopener">上帝造人有多难：生命的密钥</a></p><h3 id="牛津通识读本：地球"><a href="#牛津通识读本：地球" class="headerlink" title="牛津通识读本：地球"></a>牛津通识读本：地球</h3><p>牛津通识读本系列的书籍大概有三十几本，在 Amazon 上 Kindle Unlimited 会员是可以免费借阅。基本上都是一些一两百页子。这本关于地球科普小册子简单地介绍了一下地球的地球的形成、内核、地磁场、火山运动等知识。总之读起来可以满足一下自己的好奇心啦😋</p><p><code>摘抄</code> <a href="https://t.co/ExJxAKtv8d" target="_blank" rel="noopener">牛津通识读本：地球</a></p><h3 id="七堂极简物理课"><a href="#七堂极简物理课" class="headerlink" title="七堂极简物理课"></a>七堂极简物理课</h3><p>虽然被捧得很好，但觉着没啥好看的……🙄</p><h3 id="鸟瞰古文明"><a href="#鸟瞰古文明" class="headerlink" title="鸟瞰古文明"></a>鸟瞰古文明</h3><p>这本书是朋友送的，也是 2020 年读过最喜欢的书，书中的插图相当精美</p><p>书中提到过庞贝古城，当时找了两期纪录片来看：</p><ul><li><a href="https://www.bilibili.com/video/BV1aK4y1e7k7" target="_blank" rel="noopener">【纪录片】庞贝古城 揭秘被冻结于时光中的人【双语特效字幕】【纪录片之家字幕组】</a></li><li><a href="https://www.bilibili.com/video/BV1jT4y1373W" target="_blank" rel="noopener">【纪录片】庞贝 尘埃落定【1080p】【双语特效字幕】【纪录片之家字幕组】</a></li></ul><blockquote><p>  130幅城市复原图，重现古文明全景</p><p>  借由细腻画笔，溯着时间之流，触碰千年前的繁华巨梦</p><p>  以地中海沿岸为中心，横跨九大地域，近百座建筑群跃然眼前</p><p>  它们是古代统治者雄心与抱负的见证</p><p>  也是我们理解古希腊、罗马、埃及文明的最佳途径</p><p>  🌟 所有伟大的城市，都是在信念与梦想中建构而成。</p><p>  它们并不只辉煌于历史，其光芒也照耀了后世前进之路。</p><p>  🌟 古代城市复原领域巨擘让-克劳德·戈尔万凭借集绘画、建筑与考古学于一身的天赋， 将那些化为尘土，颓成残垣的古老废墟重新修葺。</p></blockquote><p><img src="https://p.k8s.li/20200403_043253117_iOS.jpg" alt=""><br><img src="https://p.k8s.li/20200405_162332630_iOS.jpg" alt=""><br><img src="https://p.k8s.li/20200405_162437116_iOS.jpg" alt=""><br><img src="https://p.k8s.li/20200406_101134106_iOS.jpg" alt=""><br><img src="https://p.k8s.li/20200406_102610423_iOS.jpg" alt=""></p><h3 id="宇宙从一粒尘埃开始：9堂极简宇宙课"><a href="#宇宙从一粒尘埃开始：9堂极简宇宙课" class="headerlink" title="宇宙从一粒尘埃开始：9堂极简宇宙课"></a>宇宙从一粒尘埃开始：9堂极简宇宙课</h3><p>不错的天体物理学科普，是著名的全球畅销书作家布莱恩·考克斯和杰夫·福修的全新力作。这是一本关于宇宙历史的科普读物。全书分为宇宙的故事、太阳有多老、给地球称重、到恒星的距离、爱因斯坦引力论、大爆炸、给宇宙秤重、大爆炸之前发生了什么、我们的世界九部分组成。书中用到的方法耶十分有趣，例如利用帆布背包里装上两个GPS 接收器来测量太阳有多老；利用在布里斯托尔海峡的海平面上的一个浮标，来给地球的大小做一个大致的测量😂</p><p><code>摘抄</code> <a href="https://t.co/qDg3uQqKW5" target="_blank" rel="noopener">宇宙从一粒尘埃开始：9堂极简宇宙课</a></p><h3 id="宇宙从起源到未来"><a href="#宇宙从起源到未来" class="headerlink" title="宇宙从起源到未来"></a>宇宙从起源到未来</h3><p><code>摘抄</code> <a href="https://t.co/zDlbJOshP1" target="_blank" rel="noopener">宇宙从起源到未来</a></p><h3 id="Life-生命"><a href="#Life-生命" class="headerlink" title="Life 生命"></a>Life 生命</h3><p><code>摘抄</code> <a href="https://t.co/d1FD3UtnXV" target="_blank" rel="noopener">Life 生命</a></p><h3 id="复杂生命的起源"><a href="#复杂生命的起源" class="headerlink" title="复杂生命的起源"></a>复杂生命的起源</h3><p>这本书是从 Twitter 上发现的，2020 年 11 月份刚出版，Kindle 商店里有电子版，看到作者是<strong>尼克·莱恩</strong>时就想到之前读过他的《生命的跃升》，就毫不犹豫地买了花了一周的时间读完了。因为读过他的《生命的跃升》，在读读这本书的时候很多内容就似曾相识。</p><ul><li>线粒体果真是名副其实的“发电机”😂</li></ul><blockquote><p>  质子还是带电粒子，带一个单位的正电荷。所以把质子泵过一层封闭的膜产生了两个效果：第一，在膜的两边制造了质子的浓度差；第二，膜的两边形成了电位差，外部环境相对于内部是正电位，膜内膜外的电位差是150～200毫伏。不要小看这个数字，因为膜本身非常薄（厚度为6纳米左右），在这么短的距离上，这是非常强大的电势能场。你可以再次变回ATP的大小去体验一下。如果待在膜附近，你感受到的电场强度是每米三千万伏特，相当于一道闪电，或者是普通家用电的1,000倍。</p></blockquote><ul><li>在读《生命通史》的时候里面也谈到过真核细胞演化出细胞核的原因：</li></ul><blockquote><p>  细胞核膜就是这道障碍，可以把转录和转译两个过程分开。在细胞核中，基因被转录成RNA转录本；在细胞核外，核糖体会读取RNA，再转译成蛋白质。最重要的是，缓慢的剪接过程在细胞核内进行，在核糖体有机会接触到RNA之前已经处理完毕。这就是细胞核真正的意义：把干劲冲天的核糖体挡在外面。这就解释了为什么真核生物需要细胞核，而原核生物不需要。原核生物根本没有内含子的麻烦。</p></blockquote><blockquote class="twitter-tweet"><p lang="zh" dir="ltr"><a href="https://twitter.com/hashtag/%E9%89%B4%E4%B9%A6?src=hash&amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener">#鉴书</a> 终于出中文版了！我还没有读过，不知道翻译得怎样。原书的英文版是我读过的最棒的科普书之一，在我心目中的地位和《自私的基因》、《枪炮病菌与钢铁》和《无穷的开始》差不多。在我看来，这4本书是现代知识分子的必读书，缺一本你都不完整。 <a href="https://t.co/ohO7iID6be" target="_blank" rel="noopener">pic.twitter.com/ohO7iID6be</a></p>&mdash; immusoul (@ayuan1000) <a href="https://twitter.com/ayuan1000/status/1332641409510215680?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">November 28, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><p>另外推荐下面几期视频节目，也与这本书的内容有很大关系。</p><ul><li><a href="https://www.bilibili.com/video/BV185411h79H" target="_blank" rel="noopener">【鬼谷闲谈】在那充满毒与火的深渊中，科学家发现了生命本源的线索</a></li><li><a href="https://www.bilibili.com/video/BV1Qh411R7Zf" target="_blank" rel="noopener">【鬼谷闲谈】紫色地球：一个杀生以护生的故事</a></li><li><a href="https://www.bilibili.com/video/BV1NT4y1w7vD" target="_blank" rel="noopener">【鬼谷闲谈】一次改写生命演化的邂逅</a></li><li><a href="https://www.youtube.com/watch?v=GPYn1vJh1Q0" target="_blank" rel="noopener">科学声音：生命起源</a></li><li><a href="https://www.bilibili.com/video/BV1N54y1R7CM" target="_blank" rel="noopener">《宇宙时空之旅：未知世界》03：失落的生命之城</a> 墙裂推荐😊</li></ul><p>另外再推荐豆瓣小组上的篇文章 <a href="https://www.douban.com/group/topic/33656795/" target="_blank" rel="noopener">1978年化学诺奖：ATP、线粒体结构和有氧呼吸</a></p><p><code>摘抄</code> <a href="https://t.co/soPnC8gnbs" target="_blank" rel="noopener">复杂生命的起源</a></p><h3 id="生命的跃升"><a href="#生命的跃升" class="headerlink" title="生命的跃升"></a>生命的跃升</h3><p>这本书在大学的时候读过一遍，那时候是看的 <a href="https://www.bilibili.com/video/BV1wx41177Tm" target="_blank" rel="noopener">柴知道：六分钟速读《生命的跃升》</a> 才认识到这本书，在读完 </p><p>《复杂生命的起源》的起源后又决定重新回顾一下这本书，重读了一遍。</p><p><code>摘抄</code> <a href="https://t.co/50bSWvIOAd" target="_blank" rel="noopener">生命的跃升</a></p><p>关于作者尼克·莱恩，剽窃一段豆瓣上的简介：</p><blockquote><p>  尼克·莱恩（Nick Lane），演化生物学家，英国伦敦大学学院教授。他的研究方向为演化生物学与生物能量学，聚焦于生命的起源与复杂细胞的演化。他还是伦敦大学学院线粒体研究学会的创始成员，也是生命起源研究计划的项目领头人。2010年，他以《生命的跃升》荣获英国皇家学会科学图书奖。尼克本人因为在分子生物学研究上的卓越贡献，于2015年荣获英国生物化学学会奖。他不仅深耕自己的学术研究领域，还孜孜不倦地参与公众科学普及。2016年，尼克因为在科学传播上的深入付出而荣获英国皇家学会迈克尔·法拉第奖章。</p></blockquote><p>最近也在读他的<a href="https://search.books.com.tw/redirect/move/key/尼克‧連恩/area/mid/item/0010730616/page/1/idx/2/cat/001/pdf/1" target="_blank" rel="noopener">生命之源：能量、演化與複雜生命的起源</a>，台湾貓頭鷹出版出版的，大陆还没有，只能买繁体的纸质书来看。另外还有一本《<a href="https://search.books.com.tw/redirect/move/key/尼克‧連恩/area/mid/item/0010874343/page/1/idx/1/cat/001/pdf/1" target="_blank" rel="noopener">能量、性、死亡：粒線體與我們的生命(15周年新版)</a>》。这两本都能在某宝上代购买到，或者通过 <a href="https://www.books.com.tw/products/0010730616?sloc=main" target="_blank" rel="noopener">博客来</a> 代购买到。</p><p><img src="https://p.k8s.li/image-20210109225801483.png" alt=""></p><h3 id="消失的微生物：滥用抗生素引发的危机"><a href="#消失的微生物：滥用抗生素引发的危机" class="headerlink" title="消失的微生物：滥用抗生素引发的危机"></a>消失的微生物：滥用抗生素引发的危机</h3><p>当胎儿通过阴道的时候，后者就像一只富有弹性的手掌，紧紧地包裹住婴儿柔软的身体，抚摸过每一寸肌肤。就是在这个过程中，细菌转移发生了。婴儿的皮肤就像海绵，吸收了它周围的乳酸杆菌。胎儿的脑袋朝下，而且面对着母亲的背部，恰好贴合着产道。婴儿吸入的第一口汁液包含了母亲阴道里的微生物，也不排除有一定的肠道微生物。天然的分娩并不是一个无菌的过程，但是它从来都是这种状态——从我们最早的哺乳动物祖先算起，至少7000万年了。</p><p><code>摘抄</code> <a href="https://t.co/CpTb1LusIP" target="_blank" rel="noopener">消失的微生物：滥用抗生素引发的危机</a></p><h2 id="漫画-小说"><a href="#漫画-小说" class="headerlink" title="漫画/小说"></a>漫画/小说</h2><h3 id="心里测量者"><a href="#心里测量者" class="headerlink" title="心里测量者"></a>心里测量者</h3><p>读后感可以参见 <a href="https://blog.k8s.li/PSYCHO-PASS-booklist.html">PSYCHO-PASS 心理测量者小说读后感</a>，这部改编自动漫的小说基本上还原了整个第一部动画完整的剧情，总之也是关于一个如何构建人类社会题材的小说。小说中也提到了很多书籍，也有网友总结了一份心理测量者中提到的书籍，书单如下:</p><p>其中卢梭的书也是我看了这部小说之后才开始读的，还有一本是福柯的《规训与惩罚：监狱的诞生》，剩余价值那期被封杀的节目里罗新老师也提到过这本书。马克思·韦伯的书在《中国国家治理的制度逻辑：一个组织学研究》中提到不少，尤其是关于官僚政治的，而且马克思·韦伯还和前文提到的路德维希·冯·米塞斯也是一对学术上的好基友。</p><p><code>摘抄</code> <a href="https://t.co/gp1upTv3IK" target="_blank" rel="noopener">心里测量者</a></p><h3 id="费马最终定理"><a href="#费马最终定理" class="headerlink" title="费马最终定理"></a>费马最终定理</h3><p>日系狗粮小说🐕，第一次读这本书还是大三的时候，<del>那时候咱刚刚开始了人生的第一次初恋，并把这本书送给了前女友</del>🤣。同样的小说还有《数学女孩》，后者的评价很高，但想要通过小说来学习数学是痴心妄想啦。嘛，小说就是兴趣读物，给这些枯燥会色的数学公式增加一点色彩~~</p><p>虽然对于数学来讲，咱木子简直是个学脆😭，高考数学考了 60 几分，这也让咱与名牌大学失之交臂，只能去读第六级本科院校😑，多少有点遗憾吧。不过纳，对于那些枯燥无比的计算公式求积分解微分方程等，咱更喜欢知道数学这本学科背后的历史：想知道牛顿和莱布尼茨之间的撕逼大战，想知道伯努力家族的恩仇怨恨，想知道笛卡尔与公主的爱情故事，想知道欧拉奋笔疾书非凡的一生，想知道庞加莱猜想与<code>宇宙的形状</code>等等。这也是咱即便毕业离开大学之后，不再是一名学生但也是像学生时代的自己那样好奇心如此地旺盛😂</p><blockquote><p>『我一直觉得，费马、欧拉、哥德巴赫等人与现代人相比，他们具有格外旺盛的好奇心和丰富的想象力，并且充满了生机与活力。随着社会发展的日益成熟，好奇心和想象力不可避免地不断降低，但并不代表现代社会不再需要好奇心和想象力。』</p></blockquote><p><code>摘抄</code> <a href="https://t.co/UqDfbYRjs7" target="_blank" rel="noopener">费马最终定理</a></p><h3 id="来自新世界"><a href="#来自新世界" class="headerlink" title="来自新世界"></a>来自新世界</h3><p>先是看完的 TV 动画，又看的原创小说。虽然小说称之为是反乌托邦之作，但它与《1984》、《美丽新世界》这类书有着很大的不同。书中并没有符号化一个强势的政府形象，也没有绝对的”坏人“。</p><p><a href="https://t.co/JbLvSP4cP0" target="_blank" rel="noopener">来自新世界</a></p><h3 id="樱花庄的宠物女孩"><a href="#樱花庄的宠物女孩" class="headerlink" title="樱花庄的宠物女孩"></a>樱花庄的宠物女孩</h3><p>大学的时候看过 TV 动画，花了几个通宵时间又读完了这部小说。</p><h3 id="星际穿越"><a href="#星际穿越" class="headerlink" title="星际穿越"></a>星际穿越</h3><p>和朋友一块去看完星际穿越的电影后又补看的小说，总体上不错，高度还原了电影中的情节。</p><blockquote><p>  事实还不止于此。人类不是一群孤独的生物有机体，而是一个种族发展上百万年的最终结果，蕴含着上百万年的探索、神话、社群、或重要或荒谬的想法、诗歌、哲学、工程、科学。</p></blockquote><blockquote><p>  诚然，借助这件东西，他和布兰德教授能让数千个生物学意义上的人类降生于世，但他们两人就能真正替代错综交织的传承和归属——替代爱吗？这真的是在拯救人类吗？在森林被烧为平地之前抢救出一粒种子，并不意味着拯救了森林。繁复而独特的生态系统永远无法复制。解冻人类胚胎也算不上“拯救”人类。</p></blockquote><p>摘抄 <a href="https://t.co/Hmv8cWVB80" target="_blank" rel="noopener">星际穿越</a></p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;首先给各位关注我博客的小伙伴说声抱歉，已经很长时间（将近
        
      
    
    </summary>
    
    
      <category term="思考" scheme="https://blog.k8s.li/categories/%E6%80%9D%E8%80%83/"/>
    
    
      <category term="阅读" scheme="https://blog.k8s.li/tags/%E9%98%85%E8%AF%BB/"/>
    
      <category term="读书笔记" scheme="https://blog.k8s.li/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>轻量级容器优化型 Linux 发行版 Photon OS</title>
    <link href="https://blog.k8s.li/Photon-OS.html"/>
    <id>https://blog.k8s.li/Photon-OS.html</id>
    <published>2020-09-24T16:00:00.000Z</published>
    <updated>2020-09-24T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间捡垃圾东拼西凑搞了台 Homelab 👇玩玩 👉<a href="https://blog.k8s.li/homelab.html">《垃圾佬的 Homelab 折腾记录》</a> 。</p><p><img src="https://p.k8s.li/20200913_esxi_01.png" alt=""></p><p>总体来讲性价比高，Intel i5-6600T 的性能和 i5-6600 持平，比那种 8250U 之类的低压 U 要高很多，跑一堆虚拟机也不成问题，甚至跑个三 master + 两 node 的 kubernetes 集群也是可以😂。至于功耗，整机待机时不到 30W ，一天不到 1 度电，不用担心电费爆表了；至于价格，一颗 Intel i5-6600T  不到 450 块钱，还不香嘛🙃。</p><p>在 ESXi 运行着一些虚拟机，比如用 WireGuard 打通 VPS 之间的网络，运行在一个 alpine 虚拟机里作为网关机使用；比如使用 <a href="https://pi-hole.net/" target="_blank" rel="noopener">Pi-hole®</a> 来构建自己的 DNS 服务器，用来拦截屏蔽域名；比如运行 time-machine 服务用来定时备份 MacBook ；比如 Windows 虚拟机里运行着一些国产毒瘤软件😡；比如使用 <a href="https://docs.drone.io/" target="_blank" rel="noopener">Drone</a> 跑一套轻量级的 CI 流水线系统，总之可玩性非常高哦，只要你又时间瞎折腾，总能找点乐子玩😂。</p><h2 id="Linux-Container-OS"><a href="#Linux-Container-OS" class="headerlink" title="Linux Container OS ?"></a>Linux Container OS ?</h2><p>有了一台运行着 ESXi 的 Homelab ，今天就玩一下 Linux container OS ，即 Linux 容器  OS 、容器优化型 OS，这是一类专门针对运行容器定制化开发的 Linux 发行版，裁剪掉一些不必要的软件和内核模块，使系统更加轻量一些。虽然来说民用级的 Intel i5-6600T 性能也不算太差，但和 E3  小王子，E5 老大哥比还是差个十万八千里。因此为了节省一些 CPU 资源，减少虚拟化带来的开销，就选择了容器化运行一些应用，同时再为这些容器找一个轻量级的宿主机 OS ，这就是为什么想要使用 Linux container OS 的原因。</p><h3 id="GKE-的-Container-Optimized-OS"><a href="#GKE-的-Container-Optimized-OS" class="headerlink" title="GKE 的 Container-Optimized OS"></a>GKE 的 <a href="https://cloud.google.com/container-optimized-os/docs/" target="_blank" rel="noopener">Container-Optimized OS</a></h3><p>Kubernetes 的亲爸爸 Google 家的 <a href="https://cloud.google.com/kubernetes-engine" target="_blank" rel="noopener">Google Kubernetes Engine</a> 即 GKE 集群中的每个节点都是使用 <a href="https://cloud.google.com/container-optimized-os/docs/" target="_blank" rel="noopener">Container-Optimized OS</a> 来运行工作负载，不过仅仅是针对 GCE 来进行优化的，可能在 OpenStack 或者 vSphere 上运行不起来，(瞎猜😂。</p><blockquote><p>  Container-Optimized OS 是适用于 <a href="https://cloud.google.com/compute" target="_blank" rel="noopener">Compute Engine</a> 虚拟机的操作系统映像，专为运行 Docker 容器而优化。借助 Container-Optimized OS，您可以快速、高效、安全地在 Google Cloud Platform 上启动 Docker 容器。Container-Optimized OS 由 Google 维护，基于 <a href="https://www.chromium.org/chromium-os" target="_blank" rel="noopener">Chromium OS</a> 开放源代码项目。</p></blockquote><p>特点就是不同于其他的 Linux 发行版，这个是基于 <a href="https://www.chromium.org/chromium-os" target="_blank" rel="noopener">Chromium OS</a> 定制化开发的，对内核版本选用的也比较激进，一般是 <code>4.19.112+</code> 或者 <code>5.x</code> 版本，这样你就不用再担心像 CentOS 7.x 系列那样各种内核 bug 了。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">items:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Node</span></span><br><span class="line">  <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">nodeInfo:</span></span><br><span class="line">      <span class="attr">architecture:</span> <span class="string">amd64</span></span><br><span class="line">      <span class="attr">bootID:</span> <span class="string">0c517083-aaf6-75fc4b2204ba</span></span><br><span class="line">      <span class="attr">containerRuntimeVersion:</span> <span class="string">docker://19.3.1</span></span><br><span class="line">      <span class="attr">kernelVersion:</span> <span class="number">4.19</span><span class="number">.112</span><span class="string">+</span></span><br><span class="line">      <span class="attr">kubeProxyVersion:</span> <span class="string">v1.16.13-gke.1</span></span><br><span class="line">      <span class="attr">kubeletVersion:</span> <span class="string">v1.16.13-gke.1</span></span><br><span class="line">      <span class="attr">machineID:</span> <span class="string">33a96ff3203d88c0a542</span></span><br><span class="line">      <span class="attr">operatingSystem:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">osImage:</span> <span class="string">Container-Optimized</span> <span class="string">OS</span> <span class="string">from</span> <span class="string">Google</span></span><br><span class="line">      <span class="attr">systemUUID:</span> <span class="string">33a96ff33d88c0a542</span></span><br></pre></td></tr></table></figure><p>Chromium OS 就是 Google 基于 Linux 内核开发的操作系统，所以 Google 也有这个实力针对自家的 GCP 云平台进行定制化开发个 OS 出来，专门给 kubernetes 集群运行使用，定制化开发的好处就是可以带来更多的新特性，二不受制于上游的 Linux 发行版的限制。比如不久前 Google 宣布将使用 <a href="https://cilium.io/" target="_blank" rel="noopener">Cilium</a> 作为 GKE 的下一代数据面，<a href="https://cloud.google.com/blog/products/containers-kubernetes/bringing-ebpf-and-cilium-to-google-kubernetes-engine" target="_blank" rel="noopener">New GKE Dataplane V2 increases security and visibility for containers</a> ，而 Cilium 这项技术是依赖于对 eBPF 技术，而 eBPF 又依赖于内核特性的支持。</p><h3 id="AWS-的-Bottlerocket-OS"><a href="#AWS-的-Bottlerocket-OS" class="headerlink" title="AWS 的 Bottlerocket OS"></a>AWS 的 <a href="https://github.com/bottlerocket-os/bottlerocket" target="_blank" rel="noopener">Bottlerocket OS</a></h3><p>这个是 AWS 最近开源专门针对  EC2 进行优化的 Linux Container OS，和 GKE 一样，只是针对于自家的 AWS 公有云，由于是最近刚刚推出的，还没来得及关注，所以就不介绍了。同 GKE 的 Container-Optimized OS 一样，一般公有云定制化开发的 Container OS 仅仅只针对自家的云平台。</p><blockquote><h3 id="Optimized-performance-through-AWS-integrations"><a href="#Optimized-performance-through-AWS-integrations" class="headerlink" title="Optimized performance through AWS integrations"></a>Optimized performance through AWS integrations</h3><p>  AWS provided builds of Bottlerocket are optimized to run on Amazon EC2 and include support for the latest Amazon EC2 instance capabilities. They also have built-in integrations with AWS services for container orchestration, registries, and observability.</p></blockquote><h3 id="CoreOS-Container-Linux"><a href="#CoreOS-Container-Linux" class="headerlink" title="CoreOS Container Linux"></a>CoreOS Container Linux</h3><p>来自 CoreOS 团队的 CoreOS Container Linux ，它应该是最古老的 Linux Container OS ，早在 2013 年 10 月就已经 release 第一个版本，那时候的 docker 还没有在 0.x.x 版本。</p><blockquote><p>  <a href="https://github.com/coreos/manifest/releases/tag/v94.0.0" target="_blank" rel="noopener">v94.0.0</a></p><ul><li>Git is now included by default as a number of people use it for shipping around assets, code, etc like a distributed rsync</li><li>Docker is upgraded to 0.6.3</li><li>xz is included to support new compression types</li><li>Custom OEMs can be provided via the cpio on PXE images</li></ul></blockquote><p>它没有像 yum 或 apt 这样的包管理器来安装软件，在 CoreOS 中你不需要安装软件，因为所有的应用程序都要使用 docker 来打包。</p><ul><li>最小化的操作系统： 占用内存很少，比典型的服务器版本 Linux 少占 40%的内存。</li><li>易于升级： CoreOS 采用双系统分区（主动分区/被动分区）设计而不是采用传统的通过升级包来升级系统，这使得每次升级更加快速，可靠和易于回滚。这一点有点像 Android 的 A/B 分区？</li><li>集成 Docker： CoreOS 默认集成 Docker 并作了很好的支持和优化，省去用户安装，配置，优化 Docker 的时间，极大地方便了用户。</li><li>易于集群化： CoreOS 本身提供了大型 Docker 容器集群的整体解决方案，通过内置的 fleet 工具在多台系统中部署容器并进行集群化管理。同时通过提供 Discovery Service，便于动态部署和管理集群，解决方案比较成熟。</li><li>自动化的大规模部署： CoreOS 自身提供的解决方案能够自动地大规模批量部署并操作系统，极大地减少用户工作量。</li><li>使用 systemd 做为系统服务管理工具，性能比较好，systemd 有现代化的日志功能，同时采用 socket 式与 D-Bus 总线式激活服务.</li></ul><p>不过 CoreOS 早在今年四月份就已经 EOF 了，<a href="https://getfedora.org/coreos/" target="_blank" rel="noopener">Fedora CoreOS</a> 成为 CoreOS 的继任者：</p><blockquote><p>  As we’ve <a href="https://groups.google.com/d/msg/coreos-user/zgqkG88DS3U/PFP9yrKbAgAJ" target="_blank" rel="noopener">previously announced</a>, <a href="https://getfedora.org/coreos/" target="_blank" rel="noopener">Fedora CoreOS</a> is the official successor to CoreOS Container Linux. Fedora CoreOS is a <a href="https://fedoramagazine.org/fedora-coreos-out-of-preview/" target="_blank" rel="noopener">new Fedora Edition</a> built specifically for running containerized workloads securely and at scale. It combines the provisioning tools and automatic update model of Container Linux with the packaging technology, OCI support, and SELinux security of Atomic Host. For more on the Fedora CoreOS philosophy, goals, and design, see the <a href="https://fedoramagazine.org/introducing-fedora-coreos/" target="_blank" rel="noopener">announcement of the preview release</a> and the <a href="https://docs.fedoraproject.org/en-US/fedora-coreos/" target="_blank" rel="noopener">Fedora CoreOS documentation</a>.</p></blockquote><h3 id="红帽的-RHCOS"><a href="#红帽的-RHCOS" class="headerlink" title="红帽的 RHCOS"></a>红帽的 <a href="https://docs.openshift.com/container-platform/4.1/architecture/architecture-rhcos.html" target="_blank" rel="noopener">RHCOS</a></h3><p>来自红帽子家的 <a href="https://docs.openshift.com/container-platform/4.1/architecture/architecture-rhcos.html" target="_blank" rel="noopener">Red Hat Enterprise Linux CoreOS (RHCOS)</a>，是基于不过这个 OS 仅仅适用于它自家的 <a href="https://docs.openshift.com/" target="_blank" rel="noopener">OpenShift</a>，而且容器运行时仅支持 CRI-O。</p><blockquote><p>  At the moment, CRI-O is only available as a container engine within OpenShift Container Platform clusters.</p></blockquote><p>因为 CoreOS 团队现如今已经被 Red Hat® 收购了，正如在 <a href="https://access.redhat.com/documentation/zh-cn/openshift_container_platform/4.2/html/architecture/architecture-rhcos" target="_blank" rel="noopener">OpenShift 文档</a> 中提到的： Red Hat Enterprise Linux CoreOS (RHCOS) 代表了下一代单用途容器操作系统技术。RHCOS 由创建了 Red Hat Enterprise Linux Atomic Host 和 CoreOS Container Linux 的同一开发团队打造，它将 Red Hat Enterprise Linux (RHEL) 的质量标准与 Container Linux 的自动化远程升级功能结合在一起。</p><h3 id="RancherOS"><a href="#RancherOS" class="headerlink" title="RancherOS"></a>RancherOS</h3><p>RancherOS 是 Rancher 团队所维护的开源项目，也是对标 CoreOS 一样，专门用来运行容器，并且可以运行在生产环境（至少官方做了这么样的承诺，咱也没在生产用过，不好说。在 RancherOS 中所有的进程（包括系统所有的服务，比如 udev 和 syslog）都是用 docker 来管理，这一点要比 CoreOS 更加激进一些，而 CoreOS 还是使用传统 Linux 发行版中的 systemd 来管理系统中的服务。RancherOS 通过移除传统 Linux 发行版中不必要的服务和库来最小化系统，使他专注单一的功能，即运行 docker 容器。不过之前体验了一番，占用资源比较多😂，好像并没有太大的优势（</p><p><code>Everything in RancherOS is a Docker container.</code> 感觉这个要比 CoreOS 更加容器化，甚至使用 docker 取代了 systemd 来管理系统的各种服务。系统启动后运行两个 docker 服务进程，一个是系统 docker ，在此之上在运行系统服务容器，和用户层面的 docker 。不过看一下下面的这张图你就会明白。总的来讲 RancherOS 是使用 docker 来管理整个系统的服务的，包括用户层面的 docker 。</p><p><img src="https://p.k8s.li/rancheroshowitworks.png" alt=""></p><h3 id="VMware-的-Photon-OS"><a href="#VMware-的-Photon-OS" class="headerlink" title="VMware 的 Photon OS"></a>VMware 的 <a href="https://vmware.github.io/photon/" target="_blank" rel="noopener">Photon OS</a></h3><p>今天的主角，VMware  开源的 Photon OS，这个 OS 你可能没听说过，但 VMware 开源的 Harbor 想必很熟悉，而 Harbor 的基础镜像使用的就是他家的 Photon OS😂。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root [ /harbor ]# cat /etc/os-release</span><br><span class="line"><span class="attr">NAME</span>=<span class="string">"VMware Photon OS"</span></span><br><span class="line"><span class="attr">VERSION</span>=<span class="string">"2.0"</span></span><br><span class="line"><span class="attr">ID</span>=photon</span><br><span class="line"><span class="attr">VERSION_ID</span>=<span class="number">2.0</span></span><br><span class="line"><span class="attr">PRETTY_NAME</span>=<span class="string">"VMware Photon OS/Linux"</span></span><br><span class="line"><span class="attr">ANSI_COLOR</span>=<span class="string">"1;34"</span></span><br><span class="line"><span class="attr">HOME_URL</span>=<span class="string">"https://vmware.github.io/photon/"</span></span><br><span class="line"><span class="attr">BUG_REPORT_URL</span>=<span class="string">"https://github.com/vmware/photon/issues"</span></span><br></pre></td></tr></table></figure><p>在 Photon OS 的构建脚本 <a href="https://github.com/vmware/photon/blob/master/build.py" target="_blank" rel="noopener">build.py</a> 中可以看到它构建的产物支持 ISO 和 docker 镜像，以及众多公有云的虚拟机格式，两者都是来自相同的源码，根据构建出来的是形式不同，所包含的软件也不同。因为裁剪掉了一些不必要的系统服务， docker 镜像格式的要更精简一些。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">targetList = &#123;</span><br><span class="line">        "image":["iso", "ami", "gce", "azure", "rpi3", "ova", "ova_uefi", "all", "src-iso",</span><br><span class="line">                "photon-docker-image", "k8s-docker-images", "all-images", "minimal-iso", "rt-iso"],</span><br><span class="line"></span><br><span class="line">        "rpmBuild": ["packages", "packages-minimal", "packages-initrd", "packages-docker",</span><br><span class="line">                "updated-packages", "tool-chain-stage1", "tool-chain-stage2", "check",</span><br><span class="line">                "ostree-repo", "generate-yaml-files", "create-repo", "distributed-build"],</span><br><span class="line"></span><br><span class="line">        "buildEnvironment": ["packages-cached", "sources", "sources-cached", "publish-rpms",</span><br><span class="line">                "publish-x-rpms", "publish-rpms-cached", "publish-x-rpms-cached", "photon-stage"]</span><br></pre></td></tr></table></figure><p>总的来讲，上面提到的几种容器优化型 OS 中 ，Photon OS 比较开放一些，虽然来说是针对于自家 vSphere 进行优化的，但其他公有云和私有云也是支持，甚至还支持树莓派🍓！所以个人用户想拿来玩玩，还是不错滴。尤其是针对咱这种玩 ESXi 软路由的垃圾佬，在 Photon OS 上跑一些容器应用，再适合不过了。</p><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><table><thead><tr><th align="center">Providers</th><th align="center">Name</th><th align="center">STAR</th><th align="center">FORK</th></tr></thead><tbody><tr><td align="center">Google</td><td align="center"><a href="https://github.com/GoogleCloudPlatform/cos-customizer" target="_blank" rel="noopener">Container-Optimized OS</a></td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">Amazon</td><td align="center"><a href="https://github.com/bottlerocket-os/bottlerocket" target="_blank" rel="noopener">Bottlerocket OS</a></td><td align="center">4.8K</td><td align="center">185</td></tr><tr><td align="center">CoreOS</td><td align="center">CoreOS Container Linux</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">Red Hat</td><td align="center">RHCOS</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">Rancher</td><td align="center"><a href="https://github.com/rancher/os" target="_blank" rel="noopener">Rancher OS</a></td><td align="center">6k</td><td align="center">625</td></tr><tr><td align="center">Flatcar</td><td align="center"><a href="https://github.com/flatcar-linux/Flatcar" target="_blank" rel="noopener">Flatcar Linux</a></td><td align="center">117</td><td align="center">3</td></tr><tr><td align="center">VMware</td><td align="center"><a href="https://github.com/vmware/photon" target="_blank" rel="noopener">Photon OS</a></td><td align="center">2.1k</td><td align="center">591</td></tr></tbody></table><table><thead><tr><th align="center">Providers</th><th align="center">Name</th><th align="center">Runtime</th><th align="center">Support Platform</th></tr></thead><tbody><tr><td align="center">Google</td><td align="center">Container-Optimized OS</td><td align="center">docker</td><td align="center">GCP</td></tr><tr><td align="center">Amazon</td><td align="center">Bottlerocket OS</td><td align="center">docker</td><td align="center">AWS</td></tr><tr><td align="center">CoreOS</td><td align="center">CoreOS Container Linux</td><td align="center">docker</td><td align="center">AWS/GCP/OpenStack/VMware<BR>Alibaba Cloud/Azure/DigitalOcean</td></tr><tr><td align="center">Red Hat</td><td align="center">RHCOS</td><td align="center">CRI-O</td><td align="center">AWS/vSphere/Bare Metal</td></tr><tr><td align="center">Rancher</td><td align="center">Rancher OS</td><td align="center">docker</td><td align="center">AWS/GCP/OpenStack/VMware<BR>Alibaba Cloud/Azure/DigitalOcean</td></tr><tr><td align="center">Flatcar</td><td align="center">Flatcar Linux</td><td align="center">docker</td><td align="center">AWS/GCP/OpenStack/VMware<BR>Alibaba Cloud/Azure/DigitalOcean</td></tr><tr><td align="center">VMware</td><td align="center">Photon OS</td><td align="center">docker</td><td align="center">AWS/GCE/Azure/OpenStack<br>vSphere/bare metal/Raspberry Pi 3</td></tr></tbody></table><p>目前来讲 Photon OS 作为 Harbor 的基础镜像，在容器方面比较突出一些，但作为容器的宿主机 OS ，还有很长的路要走。由于我是使用的 VMware 家的 ESXi 虚拟化，那么选择他家的 Photon OS 是最好的喽，而且 Photon OS 是针对 ESXi 做过优化的，内核都是针对 ESXi 虚拟化进行了定制化的开发，所以理论上选择 Photon OS 应该是最合适的。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="Download-Format"><a href="#Download-Format" class="headerlink" title="Download Format"></a><a href="https://github.com/vmware/photon/wiki/Downloading-Photon-OS" target="_blank" rel="noopener">Download Format</a></h3><table><thead><tr><th>Format</th><th>Description</th></tr></thead><tbody><tr><td>ISO Image</td><td>Contains everything needed to install either the minimal or full installation of Photon OS. The bootable ISO has a manual installer or can be used with PXE/kickstart environments for automated installations.</td></tr><tr><td>OVA</td><td>Pre-installed minimal environment, customized for VMware hypervisor environments. These customizations include a highly sanitized and optimized kernel to give improved boot and runtime performance for containers and Linux applications. Since an OVA is a complete virtual machine definition, we’ve made available a Photon OS OVA that has virtual hardware version 11; this will allow for compatibility with several versions of VMware platforms or allow for the latest and greatest virtual hardware enhancements.</td></tr><tr><td>Amazon AMI</td><td>Pre-packaged and tested version of Photon OS made ready to deploy in your Amazon EC2 cloud environment. Previously, we’d published documentation on how to create an Amazon compatible instance, but, now we’ve done the work for you.</td></tr><tr><td>Google GCE Image</td><td>Pre-packaged and tested Google GCE image that is ready to deploy in your Google Compute Engine Environment, with all modifications and package requirements for running Photon OS in GCE.</td></tr><tr><td>Azure VHD</td><td>Pre-packaged and tested Azure HD image that is ready to deploy in your Microsoft Azure Cloud, with all modifications and package requirements for running Photon OS in Azure.</td></tr><tr><td>Raspberry Pi3 Image</td><td>Pre-packaged and tested Raspberry Pi3 Image (Version 3.0 onwards) on ARM64 architecture.</td></tr></tbody></table><p>Photon OS 提供了多种安装方式，其中 ISO 是通用性的，就和安装其他 Linux 发行版的过程差不多，OVA 是虚拟机模板，可以导入到 VMware 虚拟化平台上使用，省区安装的步骤，比较方便。OVA 虚拟机模板的版本为 11 ，根据 <a href="https://kb.vmware.com/s/article/1003746" target="_blank" rel="noopener">Virtual machine hardware versions</a> 中的定义，需要 ESXi 6.0 Fusion 7.x Workstation 11.x Player 7.x 版本以上的虚拟化支持。</p><table><thead><tr><th><strong>Virtual Hardware Version</strong></th><th><strong>Products</strong></th></tr></thead><tbody><tr><td>18</td><td>ESXi 7.0.1</td></tr><tr><td>17</td><td>ESXi 7.0.0</td></tr><tr><td>16</td><td>Fusion 11.x Workstation Pro 15.x Workstation Player 15.x</td></tr><tr><td>15</td><td>VMware Cloud on AWS ESXi 6.7 U2</td></tr><tr><td>14</td><td>ESXi 6.7 Fusion 10.x Workstation Pro 14.x Workstation Player 14.x</td></tr><tr><td>13</td><td>ESXi 6.5</td></tr><tr><td>12</td><td>Fusion 8.x Workstation Pro 12.x Workstation Player 12.x</td></tr><tr><td>11</td><td>ESXi 6.0 Fusion 7.x Workstation 11.x Player 7.x</td></tr><tr><td>10</td><td>ESXi 5.5 Fusion 6.x Workstation 10.x Player 6.x</td></tr></tbody></table><p>另外还支持 <code>Raspberry Pi 3</code> ，不过需要拿源码自行编译镜像，然后刷到树莓派上，你吃灰的树莓派又有用途啦😂。</p><p><a href="https://github.com/vmware/photon/wiki/Downloading-Photon-OS" target="_blank" rel="noopener">下载方式</a> 👇</p><h3 id="Photon-OS-3-0-Revision-2-Update3-Binaries"><a href="#Photon-OS-3-0-Revision-2-Update3-Binaries" class="headerlink" title="Photon OS 3.0 Revision 2 Update3 Binaries"></a>Photon OS 3.0 Revision 2 Update3 Binaries</h3><p>Aug 14, 2020 An update to 3.0 revision 2 Update3 binaries are now available.</p><table><thead><tr><th>Download</th><th>Size</th><th>md5 checksum</th></tr></thead><tbody><tr><td><a href="https://packages.vmware.com/photon/3.0/Rev3/iso/photon-3.0-a383732.iso" target="_blank" rel="noopener">Full ISO x86_64</a></td><td>5.2G</td><td>2dd9f18c5162a7367f2463f4a9bb4890</td></tr><tr><td><a href="https://packages.vmware.com/photon/3.0/Rev3/iso/photon-minimal-3.0-a383732.iso" target="_blank" rel="noopener">Minimal ISO x86_64</a></td><td>299M</td><td>0119f0f275f246fd382d419ff41898a4</td></tr><tr><td><a href="https://packages.vmware.com/photon/3.0/Rev3/iso/photon-rt-3.0-a383732.iso" target="_blank" rel="noopener">ISO x86_64 Real-Time flavour</a></td><td>489M</td><td>d2bfce95b54a29174b5beaef9962dbc1</td></tr><tr><td><a href="https://packages.vmware.com/photon/3.0/Rev3/ova/photon-hw11-3.0-a383732.ova" target="_blank" rel="noopener">OVA-hw11</a></td><td>188M</td><td>ba52abd88c5b22cd4498cf0e88457f28</td></tr><tr><td><a href="https://packages.vmware.com/photon/3.0/Rev3/ova/photon-hw13_uefi-3.0-a383732.ova" target="_blank" rel="noopener">OVA-hw13_uefi</a></td><td>214M</td><td>95614f3b08c1a93306ababcc826572df</td></tr></tbody></table><p>在此使用 OVA-hw11 格式的 OVA 虚拟机模板，后面那个带 uefi 的需要设置虚拟机为 EFI 模式启动，比较麻烦。</p><ul><li>创建虚拟机的时候使用 OVA 文件导入</li></ul><p><img src="https://p.k8s.li/20200922-esxi_ova_01.png" alt=""></p><ul><li>默认的用户名为 <code>root</code> ，密码为 <code>changeme</code>，登录之后再输入一遍 <code>changeme</code>，然后修改为新的密码。</li></ul><p><img src="https://p.k8s.li/20200922-esxi_photonos-01.png" alt=""></p><h2 id="系统信息"><a href="#系统信息" class="headerlink" title="系统信息"></a>系统信息</h2><ul><li>内核版本为 <code>4.19.132-5.ph3-esx</code>，4.19 是个 LTS 版本的内核，结尾的 <code>esx</code> 则代表着为 <code>ESXi</code> 虚拟化定制的内核。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Linux photon-machine 4.19.132-5.ph3-esx #1-photon SMP Wed Aug 12 21:02:13 UTC 2020 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure><ul><li>rpm 包数量仅仅为 146 个，一般的 CentOS 发行版自带的 rpm 包数量为 300 个左右。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# rpm -qa | wc</span><br><span class="line">    146     146    4307</span><br></pre></td></tr></table></figure><ul><li>系统进程信息，还是采用 systemd 来管理进程</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# systemctl status</span><br><span class="line">● photon-machine</span><br><span class="line">    State: running</span><br><span class="line">     Jobs: 0 queued</span><br><span class="line">   Failed: 0 units</span><br><span class="line">    Since: Tue 2020-09-22 08:07:29 UTC; 10min ago</span><br><span class="line">   CGroup: /</span><br><span class="line">           ├─user.slice</span><br><span class="line">           │   ├─session-c2.scope</span><br><span class="line">           │   │ ├─413 sshd: root@pts/0</span><br><span class="line">           │   │ ├─420 -bash</span><br><span class="line">           │   │ ├─443 systemctl status</span><br><span class="line">           │   │ └─444 systemctl status</span><br><span class="line">           │   └─user@0.service</span><br><span class="line">           │     └─init.scope</span><br><span class="line">           │       ├─393 /lib/systemd/systemd --user</span><br><span class="line">           │       └─394 (sd-pam)</span><br><span class="line">           ├─init.scope</span><br><span class="line">           │ └─1 /lib/systemd/systemd</span><br><span class="line">           └─system.slice</span><br><span class="line">             ├─systemd-networkd.service</span><br><span class="line">             │ └─245 /lib/systemd/systemd-networkd</span><br><span class="line">             ├─systemd-udevd.service</span><br><span class="line">             │ └─124 /lib/systemd/systemd-udevd</span><br><span class="line">             ├─vgauthd.service</span><br><span class="line">             │ └─159 /usr/bin/VGAuthService -s</span><br><span class="line">             ├─systemd-journald.service</span><br><span class="line">             │ └─97 /lib/systemd/systemd-journald</span><br><span class="line">             ├─sshd.service</span><br><span class="line">             │ └─352 /usr/sbin/sshd -D</span><br><span class="line">             ├─vmtoolsd.service</span><br><span class="line">             │ └─161 /usr/bin/vmtoolsd</span><br><span class="line">             ├─systemd-resolved.service</span><br><span class="line">             │ └─247 /lib/systemd/systemd-resolved</span><br><span class="line">             ├─dbus.service</span><br><span class="line">             │ └─157 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only</span><br><span class="line">             ├─systemd-timesyncd.service</span><br><span class="line">             │ └─151 /lib/systemd/systemd-timesyncd</span><br><span class="line">             └─systemd-logind.service</span><br><span class="line">               └─158 /lib/systemd/systemd-logind</span><br></pre></td></tr></table></figure><ul><li>磁盘根目录只使用了不到 600M</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">&#x2F;dev&#x2F;root        16G  577M   15G   4% &#x2F;</span><br></pre></td></tr></table></figure><ul><li>内存也只使用了 43Mi，启动 dockerd 之后内存占用 108Mi，换成 containerd 将会小一些。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          2.0Gi        43Mi       1.8Gi       0.0Ki       103Mi       1.8Gi</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 dockerd 守护进程之后内存占用 108Mi</span></span><br><span class="line">root@photon-machine [ ~ ]# free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          2.0Gi       108Mi       1.6Gi       0.0Ki       298Mi       1.8Gi</span><br></pre></td></tr></table></figure><ul><li>内核模块的数量也比较少 30 个左右，大部分都是一些网络相关的内核模块。常规的 Linux 发行版的内核模块往往在 60 个以上。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# lsmod</span><br><span class="line">Module                  Size  Used by</span><br><span class="line">xt_conntrack           16384  2</span><br><span class="line">ip6table_mangle        16384  0</span><br><span class="line">ip6table_nat           16384  0</span><br><span class="line">nf_nat_ipv6            16384  1 ip6table_nat</span><br><span class="line">iptable_mangle         16384  0</span><br><span class="line">iptable_nat            16384  0</span><br><span class="line">nf_nat_ipv4            16384  1 iptable_nat</span><br><span class="line">nf_nat                 28672  2 nf_nat_ipv6,nf_nat_ipv4</span><br><span class="line">ip6table_filter        16384  1</span><br><span class="line">ip6_tables             24576  3 ip6table_filter,ip6table_nat,ip6table_mangle</span><br><span class="line">iptable_filter         16384  1</span><br><span class="line">xt_LOG                 16384  0</span><br><span class="line">nf_conntrack           90112  4 xt_conntrack,nf_nat,nf_nat_ipv6,nf_nat_ipv4</span><br><span class="line">nf_defrag_ipv6         20480  1 nf_conntrack</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">mousedev               20480  0</span><br><span class="line">vfat                   20480  1</span><br><span class="line">fat                    61440  1 vfat</span><br><span class="line">evdev                  20480  1</span><br><span class="line">vmwgfx                253952  1</span><br><span class="line">psmouse                90112  0</span><br><span class="line">drm_kms_helper        106496  1 vmwgfx</span><br><span class="line">ttm                    86016  1 vmwgfx</span><br><span class="line">drm                   323584  4 vmwgfx,drm_kms_helper,ttm</span><br><span class="line">sr_mod                 24576  0</span><br><span class="line">i2c_core               40960  2 drm_kms_helper,drm</span><br><span class="line">cdrom                  49152  1 sr_mod</span><br><span class="line">rdrand_rng             16384  0</span><br><span class="line">rng_core               16384  1 rdrand_rng</span><br><span class="line">ipv6                  368640  16 nf_nat_ipv6,ip6table_mangle</span><br><span class="line">root@photon-machine [ ~ ]# lsmod | wc</span><br><span class="line">     31     109    1273</span><br></pre></td></tr></table></figure><ul><li>系统自带的 docker 版本为 <code>19.03.10</code>，存储驱动使用的是 <code>overlay2</code></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">Client:</span><br><span class="line"> Debug Mode: false</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Containers: 0</span><br><span class="line">  Running: 0</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 0</span><br><span class="line"> Images: 0</span><br><span class="line"> Server Version: 19.03.10</span><br><span class="line"> Storage Driver: overlay2</span><br><span class="line">  Backing Filesystem: extfs</span><br><span class="line">  Supports d_type: true</span><br><span class="line">  Native Overlay Diff: true</span><br><span class="line"> Logging Driver: json-file</span><br><span class="line"> Cgroup Driver: cgroupfs</span><br><span class="line"> Plugins:</span><br><span class="line">  Volume: local</span><br><span class="line">  Network: bridge host ipvlan macvlan null overlay</span><br><span class="line">  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog</span><br><span class="line"> Swarm: inactive</span><br><span class="line"> Runtimes: runc</span><br><span class="line"> Default Runtime: runc</span><br><span class="line"> Init Binary: docker-init</span><br><span class="line"> containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339</span><br><span class="line"> runc version: d736ef14f0288d6993a1845745d6756cfc9ddd5a</span><br><span class="line"> init version: fec3683</span><br><span class="line"> Security Options:</span><br><span class="line">  apparmor</span><br><span class="line">  seccomp</span><br><span class="line">   Profile: default</span><br><span class="line"> Kernel Version: 4.19.132-5.ph3-esx</span><br><span class="line"> Operating System: VMware Photon OS/Linux</span><br><span class="line"> OSType: linux</span><br><span class="line"> Architecture: x86_64</span><br><span class="line"> CPUs: 1</span><br><span class="line"> Total Memory: 1.951GiB</span><br><span class="line"> Name: photon-machine</span><br><span class="line"> ID: HXBT:Z4LZ:4HZM:3YII:U7ZA:RVOH:Z7CL:L4FA:YGA4:Y2V6:DSVR:NWPD</span><br><span class="line"> Docker Root Dir: /var/lib/docker</span><br><span class="line"> Debug Mode: false</span><br><span class="line"> Registry: https://index.docker.io/v1/</span><br><span class="line"> Labels:</span><br><span class="line"> Experimental: false</span><br><span class="line"> Insecure Registries:</span><br><span class="line">  127.0.0.0/8</span><br><span class="line"> Live Restore Enabled: false</span><br><span class="line"> Product License: Community Engine</span><br></pre></td></tr></table></figure><h2 id="系统管理"><a href="#系统管理" class="headerlink" title="系统管理"></a>系统管理</h2><h3 id="网络管理"><a href="#网络管理" class="headerlink" title="网络管理"></a>网络管理</h3><ul><li>查看网卡状态，可使用自带的 <code>networkctl</code> 命令行工具，像 ifconfig、ip、ss 等命令都已经默认安装。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">root@photon-machine [ /mnt/RPMS ]# networkctl status eth0</span><br><span class="line">● 2: eth0</span><br><span class="line">       Link File: /usr/lib/systemd/network/99-default.link</span><br><span class="line">    Network File: /etc/systemd/network/99-dhcp-en.network</span><br><span class="line">            Type: ether</span><br><span class="line">           State: routable (configured)</span><br><span class="line">            Path: pci-0000:0b:00.0</span><br><span class="line">          Driver: vmxnet3</span><br><span class="line">          Vendor: VMware</span><br><span class="line">           Model: VMXNET3 Ethernet Controller</span><br><span class="line">      HW Address: 00:0c:29:74:13:16 (VMware, Inc.)</span><br><span class="line">         Address: 192.168.0.235</span><br><span class="line">                  fe80::20c:29ff:fe74:1316</span><br><span class="line">         Gateway: 192.168.0.1 (NETGEAR)</span><br><span class="line">             DNS: 119.29.29.29</span><br><span class="line">                  223.6.6.6</span><br><span class="line">        CLIENTID: ffb6220feb00020000ab113bc2c88225c0d29b</span><br><span class="line">    Connected To: n/a on port 00:e0:4c:68:54:12</span><br><span class="line">                  n/a on port 00:e0:4c:68:54:13</span><br><span class="line">                  n/a on port 00:e0:4c:68:54:15</span><br></pre></td></tr></table></figure><ul><li>系统安装时默认使用的 DHCP 获取 IP ，可以使用 systemd 来设置静态 IP</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 首先修改 DHCP 的 systemd 文件，关闭 DHCP</span></span><br><span class="line">sed -i 's/yes/no/' /etc/systemd/network/99-dhcp-en.network</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建静态 IP 的 systemd 文件</span></span><br><span class="line">cat &gt; /etc/systemd/network/10-static-en.network &lt;&lt; "EOF"</span><br><span class="line"></span><br><span class="line">[Match]</span><br><span class="line">Name=eth0</span><br><span class="line"></span><br><span class="line">[Network]</span><br><span class="line">Address=198.168.0.235/24</span><br><span class="line">Gateway=198.168.0.1</span><br><span class="line">DNS=192.168.0.100</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改以下文件权限为 644 ，不然启动的时候会报错提示权限问题</span></span><br><span class="line">chmod 644 /etc/systemd/network/10-static-en.network</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启一下网络</span></span><br><span class="line">systemctl restart systemd-networkd</span><br></pre></td></tr></table></figure><ul><li>挂载 NFS 文件系统需要安装 <code>nfs-utils</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tdnf install nfs-utils -y</span><br><span class="line">mount 192.168.0.100:/nfs /mnt/nfs</span><br></pre></td></tr></table></figure><h3 id="包管理"><a href="#包管理" class="headerlink" title="包管理"></a>包管理</h3><p>Photon OS 使用的是 yum/tdnf 作为包管理器，使用方法和 RedHat 系的发行版基本相同，repo 主要有以下几个：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ls /etc/yum.repos.d/</span><br><span class="line">lightwave.repo</span><br><span class="line">photon-extras.repo</span><br><span class="line">photon-iso.repo</span><br><span class="line">photon-updates.repo</span><br><span class="line">photon.repo</span><br></pre></td></tr></table></figure><h3 id="源码编译"><a href="#源码编译" class="headerlink" title="源码编译"></a>源码编译</h3><h2 id="运行容器"><a href="#运行容器" class="headerlink" title="运行容器"></a>运行容器</h2><h3 id="Pi-hole"><a href="#Pi-hole" class="headerlink" title="Pi-hole"></a>Pi-hole</h3><blockquote><p>  Pi-hole 是一款开源且免费的 DNS 沉洞服务器（DNS sinkhole），能够在不安装任何客户端侧软件的前提下为设备提供网络内容屏蔽服务，非常轻量易用。搭配上家中吃灰已久的树莓派，我们就能够轻松打造属于自己的广告屏蔽助手。<br>  在<a href="https://pi-hole.net/" target="_blank" rel="noopener">官网</a>的介绍中，Pi-hole 主要具有以下优点：</p><ul><li>易于安装和配置（号称 10 分钟安装配置一条龙）。</li><li>全平台，广告屏蔽服务可作用于任何设备，包括PC、手机、平板电脑。</li><li>轻量，对硬件要求极低。</li><li>功能稳定且强大，能轻松 hold 住百万级别的请求。</li><li>提供了美观的 Web 数据监控仪表盘。</li><li>开源且免费。</li></ul></blockquote><ul><li>首先需要关闭 systemd 自带的 DNS 服务，不然 Pi-hole 坚挺的 53 端口会被占用</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop systemd-resolved</span><br><span class="line">systemctl disable systemd-resolved</span><br></pre></td></tr></table></figure><ul><li>安装 docker-compose，修改 docker-compose.yaml 文件</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3"</span></span><br><span class="line"><span class="comment"># More info at https://github.com/pi-hole/docker-pi-hole/ and https://docs.pi-hole.net/</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">pihole:</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">pihole</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">pihole/pihole:latest</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"53:53/tcp"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"53:53/udp"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"67:67/udp"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"80:80/tcp"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"443:443/tcp"</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">TZ:</span> <span class="string">'Asia/Shanghai'</span></span><br><span class="line">      <span class="attr">WEBPASSWORD:</span> <span class="string">'changeme'</span></span><br><span class="line">    <span class="comment"># Volumes store your data between container upgrades</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">'./etc-pihole/:/etc/pihole/'</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">'./etc-dnsmasq.d/:/etc/dnsmasq.d/'</span></span><br><span class="line">    <span class="comment"># Recommended but not required (DHCP needs NET_ADMIN)</span></span><br><span class="line">    <span class="comment">#   https://github.com/pi-hole/docker-pi-hole#note-on-capabilities</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">unless-stopped</span></span><br></pre></td></tr></table></figure><ul><li>docker-compose up 走起！</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">root@PhotonOS [ /opt/docker/pihole ]# docker-compose up</span><br><span class="line">Creating network "pihole_default" with the default driver</span><br><span class="line">Creating pihole ... done</span><br><span class="line">Attaching to pihole</span><br><span class="line">pihole    | [s6-init] making user provided files available at /var/run/s6/etc...exited 0.</span><br><span class="line">pihole    | [s6-init] ensuring user provided files have correct perms...exited 0.</span><br><span class="line">pihole    | [fix-attrs.d] applying ownership &amp; permissions fixes...</span><br><span class="line">pihole    | [fix-attrs.d] 01-resolver-resolv: applying...</span><br><span class="line">pihole    | [fix-attrs.d] 01-resolver-resolv: exited 0.</span><br><span class="line">pihole    | [fix-attrs.d] done.</span><br><span class="line">pihole    | [cont-init.d] executing container initialization scripts...</span><br><span class="line">pihole    | [cont-init.d] 20-start.sh: executing...</span><br><span class="line">pihole    |  ::: Starting docker specific checks &amp; setup for docker pihole/pihole</span><br><span class="line">  [✓] Update local cache of available packages</span><br><span class="line">pihole    |   [i] Existing PHP installation detected : PHP version 7.0.33-0+deb9u8</span><br><span class="line">pihole    |</span><br><span class="line">pihole    |   [i] Installing configs from /etc/.pihole...</span><br><span class="line">pihole    |   [i] Existing dnsmasq.conf found... it is not a Pi-hole file, leaving alone!</span><br><span class="line">  [✓] Copying 01-pihole.conf to /etc/dnsmasq.d/01-pihole.conf</span><br><span class="line">pihole    | chown: cannot access '': No such file or directory</span><br><span class="line">pihole    | chmod: cannot access '': No such file or directory</span><br><span class="line">pihole    | chown: cannot access '/etc/pihole/dhcp.leases': No such file or directory</span><br><span class="line">pihole    | ::: Pre existing WEBPASSWORD found</span><br><span class="line">pihole    | Using default DNS servers: 8.8.8.8 &amp; 8.8.4.4</span><br><span class="line">pihole    | DNSMasq binding to default interface: eth0</span><br><span class="line">pihole    | Added ENV to php:</span><br><span class="line">pihole    |                     "PHP_ERROR_LOG" =&gt; "/var/log/lighttpd/error.log",</span><br><span class="line">pihole    |                     "ServerIP" =&gt; "0.0.0.0",</span><br><span class="line">pihole    |                     "VIRTUAL_HOST" =&gt; "0.0.0.0",</span><br><span class="line">pihole    | Using IPv4 and IPv6</span><br><span class="line">pihole    | ::: Preexisting ad list /etc/pihole/adlists.list detected ((exiting setup_blocklists early))</span><br><span class="line">pihole    | https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts</span><br><span class="line">pihole    | https://mirror1.malwaredomains.com/files/justdomains</span><br><span class="line">pihole    | ::: Testing pihole-FTL DNS: FTL started!</span><br><span class="line">pihole    | ::: Testing lighttpd config: Syntax OK</span><br><span class="line">pihole    | ::: All config checks passed, cleared for startup ...</span><br><span class="line">pihole    |  ::: Docker start setup complete</span><br><span class="line">pihole    |   [i] Neutrino emissions detected...</span><br><span class="line">  [✓] Pulling blocklist source list into range</span><br><span class="line">pihole    |</span><br><span class="line">  [✓] Preparing new gravity database</span><br><span class="line">pihole    |   [i] Target: https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts</span><br><span class="line">pihole    |   [i] Received 55654 domains</span><br><span class="line">pihole    |   [i] Target: https://mirror1.malwaredomains.com/files/justdomains</span><br><span class="line">  [✓] Status: No changes detected</span><br><span class="line">pihole    |   [i] Received 26854 domains</span><br><span class="line">  [✓] Storing downloaded domains in new gravity database</span><br><span class="line">  [✓] Building tree</span><br><span class="line">  [✓] Swapping databases</span><br><span class="line">pihole    |   [i] Number of gravity domains: 82508 (82465 unique domains)</span><br><span class="line">pihole    |   [i] Number of exact blacklisted domains: 0</span><br><span class="line">pihole    |   [i] Number of regex blacklist filters: 0</span><br><span class="line">pihole    |   [i] Number of exact whitelisted domains: 0</span><br><span class="line">pihole    |   [i] Number of regex whitelist filters: 0</span><br><span class="line">  [✓] Cleaning up stray matter</span><br><span class="line">pihole    |</span><br><span class="line">pihole    |   [✓] DNS service is running</span><br><span class="line">pihole    |   [✓] Pi-hole blocking is Enabled</span><br><span class="line">pihole    |   Pi-hole version is v5.1.2 (Latest: v5.1.2)</span><br><span class="line">pihole    |   AdminLTE version is v5.1.1 (Latest: v5.1.1)</span><br><span class="line">pihole    |   FTL version is v5.2 (Latest: v5.2)</span><br><span class="line">pihole    | [cont-init.d] 20-start.sh: exited 0.</span><br><span class="line">pihole    | [cont-init.d] done.</span><br><span class="line">pihole    | [services.d] starting services</span><br><span class="line">pihole    | Starting pihole-FTL (no-daemon) as root</span><br><span class="line">pihole    | Starting lighttpd</span><br><span class="line">pihole    | Starting crond</span><br><span class="line">pihole    | [services.d] done.</span><br></pre></td></tr></table></figure><ul><li>打开浏览器，输入 <code>http://ip:port/admin</code> 即可进入 Pi-hole 的后台管理页面，在这里可以查看到 DNS 解析的详细记录，关于 Pi-hole 的使用可以参考一些大佬的博客，比如 <a href="https://wzyboy.im/post/1372.html" target="_blank" rel="noopener">搭建 Pi-Hole 为网上冲浪保驾护航</a>。</li></ul><p><img src="https://p.k8s.li/20200925-pihole.png" alt=""></p><p>如果想要让内网的机器都走 Pi-hole 来进行 DNS ，可以将路由器的 DHCP 的  DNS 的 IP 设置为 Pi-hole 的 IP。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://cloud.google.com/blog/products/containers-kubernetes/bringing-ebpf-and-cilium-to-google-kubernetes-engine" target="_blank" rel="noopener">New GKE Dataplane V2 increases security and visibility for containers</a></li><li><a href="https://moelove.info/2020/09/02/%E8%A2%AB-Google-%E9%80%89%E6%8B%A9%E7%9A%84%E4%B8%8B%E4%B8%80%E4%BB%A3%E6%95%B0%E6%8D%AE%E9%9D%A2-Cilium-%E6%98%AF%E4%BB%80%E4%B9%88/" target="_blank" rel="noopener">被 Google 选择的下一代数据面 Cilium 是什么</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;前段时间捡垃圾东拼西凑搞了台 Homelab 👇玩玩
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://blog.k8s.li/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="容器" scheme="https://blog.k8s.li/tags/%E5%AE%B9%E5%99%A8/"/>
    
      <category term="PhotonOS" scheme="https://blog.k8s.li/tags/PhotonOS/"/>
    
      <category term="Linux" scheme="https://blog.k8s.li/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>给阵列卡刷个机，IR 模式转 IT 模式</title>
    <link href="https://blog.k8s.li/lsi-9211-4i-ir-to-it.html"/>
    <id>https://blog.k8s.li/lsi-9211-4i-ir-to-it.html</id>
    <published>2020-09-07T16:00:00.000Z</published>
    <updated>2020-09-07T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="刷机？"><a href="#刷机？" class="headerlink" title="刷机？"></a>刷机？</h2><p>不久前捡垃圾搞了一台低功耗 Homelab 主机玩玩，由于主板 SATA 口的限制，不能使用大于 2TB 的硬盘，对于咱梦想着这种拥有几十 TB 存储来存放老婆的死肥宅来说，2TB 怎么够了。于是想要突破限制，再给 Homelab 主机增加一块 6TB 的磁盘。于是，在洋垃圾堆里花了 50 块钱捡了这块阵列卡👇。</p><p><img src="https://p.k8s.li/20200830_9211-4i-01.jpg" alt=""></p><p>买的这块阵列卡型号是 <a href="https://lenovopress.com/tips0831-serveraid-h1110" target="_blank" rel="noopener">ServeRAID H1110 SAS/SATA Controller for IBM System x </a> ，卖家说是 <code>IBM H1110</code> ，其实都差不多啦。由于是第一次玩儿阵列卡，对这种型号也不是很熟悉，之后刷了新的固件又变成了 <code>LSI 9211-4i</code> 。</p><h2 id="翻车？"><a href="#翻车？" class="headerlink" title="翻车？"></a>翻车？</h2><p>收到货后，迫不及待地将存满老婆的硬盘接到阵列卡上，开机的时候，一直卡在阵列卡 BIOS 初始化页面很久很久。顿时觉着，完蛋翻车了，正准备去怼一波卖家，阵列卡启动等了五六分钟后进入了久违的  ESXi 的启动页面。这尼玛，坑我啊，你一个巴掌大的阵列卡启动竟然需要五分钟？内心一万匹草泥马奔腾而过。</p><p><img src="https://p.k8s.li/20200830_9211-4i-02.png" alt=""></p><h2 id="IR-模式？"><a href="#IR-模式？" class="headerlink" title="IR 模式？"></a>IR 模式？</h2><p>在网上看来一下大佬们的评论，说阵列卡 IR 模式的启动速度要慢一些？然后又找到了 <a href="https://wiki2.xbits.net:4430/hardware:lsi:h1110-it-firmware" target="_blank" rel="noopener">IBM H1110卡刷为LSI 9211-4i IT固件</a> ，里面提到的可以将 IR 模式刷为 IT 直通模式。至于 IR 模式和 IT 模式，自己太菜没找到确切的资料。大概可以理解为 IR 模式适用于使用阵列卡组 RAID 阵列，而 IT 模式就是所谓的直通模式，不适用 RAID ，只使用阵列卡的磁盘控制器？相当于主板上的 SATA 接口。何况我这个是小主机，里面也塞不下那么多的磁盘，所以阵列卡使用 IT 直通模式无疑是最好的选择。</p><p><img src="https://p.k8s.li/20200828_9211-4i-03.jpg" alt=""></p><h2 id="万物皆可刷？"><a href="#万物皆可刷？" class="headerlink" title="万物皆可刷？"></a>万物皆可刷？</h2><p>参照大佬们的博客，咱也要体验一把刷<del>机</del>卡的痛快了，毕竟折腾这些没用的玩意儿也是咱的一大乐趣。</p><blockquote><p>  我青年时代就刷过：诺基亚、摩托罗拉、三星、黑莓、Lumia、HTC，我还刷过：路由器、交换机、阵列卡、电视盒子……</p></blockquote><p>安卓<del>基</del>机佬们想必对 twrp 再熟悉不过了，它是我们刷机，刷各种 ROM 包最常用的系统，相当于 Windows 中的 PE 系统，对系统分区刷上 ROM 来达到刷机的目的。刷阵列卡的固件和刷机也差不多，也是需要一个底层的系统进去对阵列卡上的存储芯片进行操作。最常见的就是 Dos 和 EFI Shell ，由于 Dos 年代久远，且我的主板对 EFI 支持比较友好，在进行刷机的时候为了稳妥起见选择 EFI shell。</p><h3 id="记录-SAS-地址"><a href="#记录-SAS-地址" class="headerlink" title="记录 SAS 地址"></a>记录 SAS 地址</h3><p>在刷阵列卡之前要线记录下 SAS 的 Address ，进入到阵列卡的 BIOS 中会有这个信息。</p><h3 id="找好固件和文档"><a href="#找好固件和文档" class="headerlink" title="找好固件和文档"></a>找好固件和文档</h3><p>由于我要刷入的固件不是阵列卡原厂的固件，只找到了现成的固件，直接就拿来用了，应该问题不大。而且刷入的流程也是比较简答。<a href="https://wiki2.xbits.net:4430/hardware:lsi:h1110-it-firmware" target="_blank" rel="noopener">IBM H1110卡刷为LSI 9211-4i IT固件</a> :</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 备份原卡信息和sbr</span></span><br><span class="line">MegaCli.exe -AdpAllInfo -aAll -ApplogFile bak.txt</span><br><span class="line">MegaRec.exe -readsbr 0 orig.sbr</span><br><span class="line"><span class="meta">#</span><span class="bash">擦写sbr和flash一遍能刷入LSI原厂固件</span></span><br><span class="line">MegaRec -writesbr 0 sbrempty.bin</span><br><span class="line">MegaRec -cleanflash 0</span><br><span class="line"><span class="meta">#</span><span class="bash">重启再次进入DOS</span></span><br><span class="line">reboot</span><br><span class="line"><span class="meta">#</span><span class="bash">刷入对应IT固件和ROM</span></span><br><span class="line">sas2flsh -o -f 2114it.bin -b mptsas2.rom</span><br><span class="line"><span class="meta">#</span><span class="bash">恢复原来的SAS地址</span></span><br><span class="line">sas2flsh -o -sasadd xxxxxxxx</span><br><span class="line"><span class="meta">#</span><span class="bash">查看最新状态</span></span><br><span class="line">sas2flsh -list</span><br><span class="line"><span class="meta">#</span><span class="bash">重启，完成</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><p>一些官方的文档<a href="https://www.broadcom.cn/support/knowledgebase/1211161495925/flash-upgrading-firmware-on-lsi-sas-hbas-upgraded-firmware-on-92" target="_blank" rel="noopener">Flash upgrading firmware on LSI SAS HBAs; Upgraded firmware on 9211-8i to P8, now duplicated drives</a>：</p><blockquote><p>  Advanced users:</p><p>  To delete the firmware and BIOS in your 9211, then reflash it, follow these steps:</p><ol><li><p>Check to see if there is an also an onboard SATA controller with disk in the system before running the commands below.<br>Run sas2flsh -listall<br>If you see only the 9211, then run the commands as shown below.<br>If you see two controllers (e.g. c0 and c1, then add -c 1 to all of the commands below–&gt; sas2flsh -c 1 -o -e 6</p></li><li><p>Record the SAS address of the 9211 in case you need it later.  To display it, type:<br>sas2flsh -list</p><p>and write down the SAS address.  You can run the is DOS, Windows, Linux, etc.</p></li><li><p>Download 9211_8i_Package_for_P9_Firmware_BIOS_on_MSDOS_and_Windows.zip for the 9211-8i</p></li><li><p>Boot to DOS (create a DOS bootable USB stick from <a href="http://www.bootdisk.com" target="_blank" rel="noopener">http://www.bootdisk.com</a> or <a href="http://www.gocoding.com" target="_blank" rel="noopener">www.gocoding.com</a>).</p></li><li><p>Run from DOS sas2flsh -o -e 6 (this will erase the controller firmware and BIOS).</p></li><li><p>Turn the system off.</p></li><li><p>Turn the system on and boot to DOS (note:  the BIOS won’t post, as you will reflash it in step 8 below).</p></li><li><p>Run from DOS, with files sas2flsh.exe, the .bin and .rom files in the same directory:</p><p>For IR firmware:  sas2flsh -f 9211IRP9.bin -b mptsas2.rom<br>For IT firmware:  sas2flsh -f 9211itp9.bin -b mptsas2.rom</p><p>Note:  you will need to rename 9211-8i_IR_P9.bin to 9211IRP9.bin and 9211-8i-IT_ph9.bin to 9211itp9.bin</p></li><li><p>The controller will now work normally, with the P9 firmware and BIOS.</p></li><li><p>Check to make sure you have a SAS address:<br>sas2flsh -list<br>If you see the same SAS address that you had in step 2, then you are done.<br>If you don’t see the same SAS address, or you don’t see a SAS address, type:<br>sas2flsh -o -sasadd <SAS address></p></li></ol></blockquote><p>上面提到的都是基于 Dos 系统上操作的，不过我试了一下都翻车了🤣</p><h3 id="制作-EFI-shell-系统"><a href="#制作-EFI-shell-系统" class="headerlink" title="制作 EFI shell 系统"></a>制作 EFI shell 系统</h3><p>如果主板支持 EFI 的话，建议使用 EFI shell 刷入固件，在 Dos 下会有些奇怪的问题。</p><p>按照 <a href="https://superuser.com/questions/1057446/how-do-i-boot-to-uefi-shell" target="_blank" rel="noopener">How do I “Boot to UEFI shell”?</a> 中提到的：</p><blockquote><p>It depends on whether your UEFI has a shell builtin. If it does, there should be an option in its settings / boot menu for you to launch it. Some motherboard also provide an option to launch a shell from the EFI System Partition (ESP). You should consult the manual of your motherboard for the path it will look for (the instruction is often vague though). Usually they are looking for a file named <code>Shell.efi</code> in the ESP root folder.</p><p>Another way is to launch it just like you launch any other EFI binary (e.g. bootloader). Since it’s not really accessible to register a EFI binary to your UEFI or put the shell binary to your ESP in Windows, so the easiest way is probably to put it as <code>\EFI\Boot\bootx64.efi</code> <strong>(also put the <code>update.nsh</code> you need to run and the files it requires under <code>\EFI\Boot\</code>)</strong> in a FAT(32)-formatted USB drive (It shouldn’t matter whether it’s MBR or GPT as long as your UEFI is standard-conforming enough). <strong>Then reboot and boot the USB in UEFI mode from your UEFI boot menu.</strong></p><p>You can obtain the EFI shell binary from the EDK2 project repo:</p><ul><li><p><a href="https://github.com/tianocore/edk2/releases/download/edk2-stable202002/ShellBinPkg.zip" target="_blank" rel="noopener">version 2</a></p></li><li><p><a href="https://github.com/tianocore/edk2/blob/UDK2018/EdkShellBinPkg/FullShell/X64/Shell_Full.efi?raw=true" target="_blank" rel="noopener">version 1 (no longer updated, only for old UEFI that does not work with v2)</a></p><p>(<strong>Note:</strong> some older EFI tools like [sas2flash.efi](<a href="https://www.broadcom.com/site-search?q=Installer" target="_blank" rel="noopener">https://www.broadcom.com/site-search?q=Installer</a> for UEFI) only work with such an old EFI shell (which works on current mainboards with current UEFI))</p></li></ul></blockquote><p>首先需要一个 U 盘，对容量没有闲置，几十兆足够，把分区格式化为 FAT32 文件系统格式，然后下载一个 EFI shell 的 efi 文件 <a href="https://github.com/tianocore/edk2/blob/UDK2018/EdkShellBinPkg/FullShell/X64/Shell_Full.efi?raw=true" target="_blank" rel="noopener">version 1 </a>，把该文件保存在 FAT32 分区下的 <code>\EFI\Boot\bootx64.efi</code> 路径下。</p><blockquote><p>  Download from Github Tianocore the precompiled UEFI version 1 Shell: <a href="https://github.com/tianocore/edk2/tree/master/EdkShellBinPkg/FullShell/X64" target="_blank" rel="noopener">Shell_Full.efi</a>. (Only v1 is applicable, later versions are not compatible with the flash tool and end up with the message: “InitShellApp: Application not started from Shell”.)</p></blockquote><p>由于刷固件的工具 <code>sas2flash.efi</code> 只和 EFI shell v1 版本的兼容，我第一次刷的时候时使用的 v2 版本，提示 <code>“InitShellApp: Application not started from Shell”</code> 错误😂</p><p>然后还需要把固件 <code>2114it.bin</code> ，以及刷固件用到的工具 <code>sas2flash.efi</code> 放入到 FAT32 跟目录下，其中固件根据阵列卡的型号不同需要自行找到相应的固件版本，我这个虽然是 IBM H1110 型号的，但是可以刷成 LSI 9211 的，所以就没去找原厂的固件。</p><h3 id="进入-EFI-shell-刷入新的固件"><a href="#进入-EFI-shell-刷入新的固件" class="headerlink" title="进入 EFI shell 刷入新的固件"></a>进入 EFI shell 刷入新的固件</h3><p>从 <a href="https://www.ixsystems.com/community/threads/how-to-flash-lsi-9211-8i-using-efi-shell.50902/" target="_blank" rel="noopener">How-to: Flash LSI 9211-8i using EFI shell</a> 大佬那里复制粘贴过来的的教程：</p><blockquote><ol><li>Insert the controller card in a PCIe slot. (I’ve used the slot Nr. 3. In case of troubles recognizing the card in your desktop PC try different slots.)</li><li>Boot the PC and prepare the USB stick:</li><li>In the USB stick create and format a FAT or FAT32 partition &gt;= 10 MB. (I’ve created 500 MB FAT32 partition. I wouldn’t recommend large partitions, who knows if the EFI shell will read every big partition.)</li><li>Create the sub-folders for EFI boot. In the web there are two different structures: <code>/boot/efi</code> and <code>/efi/boot</code>. For time saving I’ve created both groups, it works.</li><li>Download from Broadcom following packages: <a href="https://docs.broadcom.com/docs/12350820" target="_blank" rel="noopener">Installer_P20_for_UEFI</a> and <a href="https://docs.broadcom.com/docs/12350530" target="_blank" rel="noopener">9211-8i_Package_P20_IR_IT_Firmware_BIOS_for_MSDOS_Windows</a> and extract them on your PC’s HDD.</li><li>Copy from the downloaded packages three files to the USB stick root folder:</li><li>from the first package the file <code>sas2flash.efi</code> (it is in sub-folder <code>/sas2flash_efi_ebc_rel/</code>);</li><li>from the second package: <code>2118it.bin</code> (it is in sub-folder <code>/Firmware/HBA_9211_8i_IT/</code>) and <code>mptsas2.rom</code> (it is in sub-folder <code>/sasbios_rel/</code>).</li><li>Download from Github Tianocore the precompiled UEFI version 1 Shell: <a href="https://github.com/tianocore/edk2/tree/master/EdkShellBinPkg/FullShell/X64" target="_blank" rel="noopener">Shell_Full.efi</a>. (Only v1 is applicable, later versions are not compatible with the flash tool and end up with the message: “InitShellApp: Application not started from Shell”.)</li><li>Rename the <code>Shell_Full.efi</code> in <code>ShellX64.efi</code> and copy this file to following three USB stick destinations: root folder, <code>/boot/efi/</code>, <code>/efi/boot/</code>. (Again, there are different advices, for time saving it easier to use all three choices.)</li><li>The creative part is completed, it’s time for action. Restart the PC and enter the BIOS. If you use ASUS UEFI BIOS Utility in advanced mode, mouse click on the Exit (not by using keyboard “Esc”), in the next dialog select “Launch EFI Shell from filesystem device”. Other BIOS should behave similarly.</li><li>Next you should see starting shell execution, ending with a prompt: “Shell&gt;” (not the “2.0 Shell&gt;”!).</li><li>Type the command: <code>map –b</code> (+Enter) for listing of available disks. Locate which one is your USB stick. In my case it is the fs6:<br>“fs6 :Removable HardDisk - … USB(…)”</li><li>You can break further execution of the map command by <code>q</code>.</li><li>Switch to the located USB stick by command <code>fsN:</code> (+Enter) (N=6 – in my example = “fs6:”, set N to your USB stick ID).</li><li><code>Dir</code> shows the file list:<br>2118IT.BIN<br>MPTSAS2.ROM<br>sas2flash.efi<DIR> BOOT<DIR> EFIShellX64.efi</li><li>The action can start. During it the power shall not be brocken!</li><li>Erase the controller flash memory: <code>sas2flash.efi -o -e 6</code>.</li><li>Write the new firmware to the flash: <code>sas2flash.efi -o -f 2118it.bin -b mptsas2.rom</code>.</li><li>After a while you’ll see the success message. You can restart the PC and check if the controller BIOS reports the new “IT”-firmware.</li><li>The card is ready to use.</li></ol></blockquote><ul><li>使用 <code>map -b</code> 命令查看 U 盘的路径，一般为 <code>fsX</code> 然后按下 <code>fs0:</code> 路径就切换到了 U 盘的 FAT32 分区下。</li></ul><p><img src="https://p.k8s.li/20200828_9211-4i-04.jpg" alt=""></p><ul><li>然后使用 <code>sas2flash.efi -o -e 6</code> 命令清空阵列卡的  <code>flash memory</code>。</li><li>接着使用 <code>sas2flsh -o -f 2114it.bin -b mptsas2.rom</code> 命令刷入新的固件。</li></ul><p><img src="https://p.k8s.li/20200828_9211-4i-05.jpg" alt=""></p><ul><li>恢复 SAS 地址 <code>sas2flsh -o -sasadd xxxxxxxx</code> </li></ul><p>操作完以上步骤后就可以重启了</p><h2 id="IT-模式？"><a href="#IT-模式？" class="headerlink" title="IT 模式？"></a>IT 模式？</h2><p>刷完之后阵列卡的型号就莫名其妙地变成了 <code>LSI® SAS 9211-4i PCI Express® to 6Gb/s Serial Attached SCSI (SAS) Host Bus Adapter</code> ，固件的版本也变成了  IT 模式，开机的速度比以前快了很多，只需要不到 5s 就自检完成进入 ESXi 的启动流程，终于告别原先的龟速启动了。</p><p><img src="https://p.k8s.li/20200828_9211-4i-06.jpg" alt=""></p><p>在 ESXi 中，阵列卡也被识别为了 <code>LSI2004</code> ，看来是没问题了，插上硬盘也都是识别出来了。</p><p><img src="https://p.k8s.li/20200908_9211-4i-07.png" alt=""></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>由于是是第一次给阵列卡刷固件，在网上找到了写资料可以做参考。</p><ul><li><a href="https://wiki2.xbits.net:4430/hardware:lsi:h1110-it-firmware" target="_blank" rel="noopener">IBM H1110卡刷为LSI 9211-4i IT固件</a></li><li><a href="https://www.tfir.io/easiest-way-to-flash-lsi-sas-9211-8i-on-motherboards-without-efi-shell/" target="_blank" rel="noopener">Easiest Way To Flash LSI SAS 9211-8i on Motherboards without EFI Shell</a></li><li><a href="https://www.broadcom.cn/support/knowledgebase/1211161495925/flash-upgrading-firmware-on-lsi-sas-hbas-upgraded-firmware-on-92" target="_blank" rel="noopener">Flash upgrading firmware on LSI SAS HBAs; Upgraded firmware on 9211-8i to P8, now duplicated drives</a></li><li><a href="chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=https%3A%2F%2Fdocs.broadcom.com%2Fdoc%2F12353332">LSI® SAS 9211-4i PCI Express® to 6Gb/s Serial Attached SCSI (SAS) Host Bus Adapter </a></li><li><a href="https://www.ixsystems.com/community/threads/how-to-flash-lsi-9211-8i-using-efi-shell.50902/" target="_blank" rel="noopener">How-to: Flash LSI 9211-8i using EFI shell</a></li><li><a href="https://github.com/bsodmike/s5clouds8-lsi9211-8i-IR-to-IT-EFI-bootable-usb" target="_blank" rel="noopener">s5clouds8-lsi9211-8i-IR-to-IT-EFI-bootable-usb</a></li><li><a href="https://superuser.com/questions/1057446/how-do-i-boot-to-uefi-shell" target="_blank" rel="noopener">How do I “Boot to UEFI shell”?</a></li><li><a href="https://forums.laptopvideo2go.com/topic/29059-sas2008-lsi92409211-firmware-files/" target="_blank" rel="noopener">SAS2008 (LSI9240/9211) Firmware files</a></li><li><a href="https://www.servethehome.com/ibm-serveraid-m1015-part-4/" target="_blank" rel="noopener">IBM ServeRAID M1015 Part 4: Cross flashing to a LSI9211-8i in IT or IR mode</a></li><li><a href="https://web.archive.org/web/20200423162708/http://brycv.com/blog/2012/flashing-it-firmware-to-lsi-sas9211-8i/" target="_blank" rel="noopener">Flashing IT Firmware to the LSI SAS9211-8i HBA</a></li><li><a href="https://forum.openmediavault.org/index.php?thread/2310-ibm-m1015-ir-vs-it/" target="_blank" rel="noopener">IBM M1015 - IR vs. IT</a></li><li><a href="https://marcan.st/2016/05/crossflashing-the-fujitsu-d2607/" target="_blank" rel="noopener">Crossflashing the Fujitsu D2607</a></li><li><a href="https://kc.mcafee.com/corporate/index?page=content&id=KB90801&locale=en_US" target="_blank" rel="noopener">How to create a bootable USB media to access the default EFI shell</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;刷机？&quot;&gt;&lt;a href=&quot;#刷机？&quot;
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://blog.k8s.li/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="刷机" scheme="https://blog.k8s.li/tags/%E5%88%B7%E6%9C%BA/"/>
    
      <category term="阵列卡" scheme="https://blog.k8s.li/tags/%E9%98%B5%E5%88%97%E5%8D%A1/"/>
    
  </entry>
  
  <entry>
    <title>垃圾佬的 Homelab 折腾记录</title>
    <link href="https://blog.k8s.li/homelab.html"/>
    <id>https://blog.k8s.li/homelab.html</id>
    <published>2020-08-20T16:00:00.000Z</published>
    <updated>2021-04-17T01:11:01.098Z</updated>
    
    <content type="html"><![CDATA[<h2 id="捡垃圾"><a href="#捡垃圾" class="headerlink" title="捡垃圾"></a>捡垃圾</h2><p>来自 <a href="https://space.bilibili.com/1292029" target="_blank" rel="noopener">@awpak78 </a>的图👇</p><p><img src="https://p.k8s.li/20200801_150112.jpg" alt=""></p><p>作为一名运维工程师，白天在工地上搬砖养家糊口，晚上下班回家后就开始折腾一堆破铜烂铁自娱自乐😂。最近东拼西凑花了 2000 来块钱捡垃圾整了台 HomeLab 玩玩，折腾一些没用的东西🙃</p><p>其实很早之前就想搞一台低功耗的 HomeLab 主机玩儿了，最早开始选择的是 Dell T1700 SFF + E3-1271V3 +32GB DDR3，但是呢，E3 V3 系列是 Intel 第四代  CPU ，1150 芯片组无法从 M.2 启动，磁盘速度只能达到 SATA III 也就是顶多 600 MB/s 的读写速度，而目前随便一块支持  PCI-e M.2 NVMe 的主板普遍都能达到 3000MB/s 了。所以这一点来讲 E3 V3 已经不值得捡了。而且我想把我台式机上 SN750 500GB 换到这台机器上，所以还是要选择一个支持 PCI-e M.2 NVMe 的主板。</p><table><thead><tr><th align="center">硬件</th><th>配置</th><th align="center">价格</th></tr></thead><tbody><tr><td align="center">CPU</td><td>Intel(R) Core(TM) i5-6600T CPU @ 2.70GHz 35w</td><td align="center">480</td></tr><tr><td align="center">主板</td><td>Dell OptiPlex 7040 准系统：Intel ®Q170</td><td align="center">400</td></tr><tr><td align="center">内存</td><td>镁光 DDR4 16GB 2666MHz</td><td align="center">310</td></tr><tr><td align="center">显卡</td><td>英特尔® 核芯显卡 530</td><td align="center">0</td></tr><tr><td align="center">机箱</td><td>Dell OptiPlex 7040 准系统</td><td align="center">0</td></tr><tr><td align="center">电源</td><td>Dell OptiPlex 7040 准系统：290W 开关电源</td><td align="center">0</td></tr><tr><td align="center">UPS</td><td>某杂牌 UPS 650VA360W</td><td align="center">160</td></tr><tr><td align="center">固态</td><td>三星 970PRO 512GB</td><td align="center">820</td></tr><tr><td align="center">总价</td><td></td><td align="center">2170</td></tr></tbody></table><h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><p>至于 6600T 的性能，在 500 块钱的价位内 35W低功耗的 6600T 还算可以能接受，为什么不买 7200U 这种低压 U 呢？，一是低压 U 的装机成本太高，而且性价比很低，我还要在上面跑一堆虚拟机，低压 U 恐怕扛不住，所以一开始就放弃了低压 U 的装机方案。</p><p><img src="https://p.k8s.li/HomeLab-1.jpg" alt=""></p><h3 id="主板"><a href="#主板" class="headerlink" title="主板"></a>主板</h3><p>由于 Dell SFF 系列的机箱是定制的，和普通的主板不太一样，也只有这样才能塞进这么小的空间，对于 MFF 系列的则更小一点。对于这种小机箱而言，拥有 2个 PCI-e*4 和一个 PIC-e*16 是相当不错了，PCI-e*4可以装一个阵列卡个一个四网口的网卡，PIC-e*16又可以装一个低功耗的刀卡显卡。等到以后台式机升级的硬件的时候再把台式机上的 GT1030 亮机卡放上去。三个 SATA 一个 M.2 有点捉襟见肘，机箱空间就那么点，口子多了硬盘也塞不下呀😂。</p><table><thead><tr><th>Model:</th><th><a href="https://www.dell.com/support/manuals/us/en/04/optiplex-7040-desktop/opti7040_sff_om/specifications?guid=guid-f058d593-d332-479e-9d55-6c6031fa6cba&lang=en-us" target="_blank" rel="noopener"><em>Dell OptiPlex 7040 SFF</em></a></th></tr></thead><tbody><tr><td>Form factor:</td><td>Small Form Factor</td></tr><tr><td>CPU options:</td><td>Intel Gen6 i3/i5/i7</td></tr><tr><td>Chipset:</td><td><a href="https://ark.intel.com/content/www/us/en/ark/products/90587/intel-q170-chipset.html" target="_blank" rel="noopener">Intel Q170</a></td></tr><tr><td>RAM slots:</td><td>(4x) DIMM DDR4-2133</td></tr><tr><td>Max RAM:</td><td>64 GB</td></tr><tr><td>USB Ports:</td><td>(6x) USB3.0; (4x) USB2.0;</td></tr><tr><td>Video Ports:</td><td>(2x) Display Port 1.2; HDMI 1.4;</td></tr><tr><td>Other Ports:</td><td>Serial; (2x) PS2; RJ45; Headset; Line-Out;</td></tr><tr><td>Optional Ports:</td><td>VGA; Media Card Reader;</td></tr><tr><td>SATA:</td><td>(3x) SATA 3.0*</td></tr><tr><td>PCIe:</td><td>PCIe 3.0 x16 (low profile); PCIe 3.0 x4 (low profile);</td></tr><tr><td>M.2 slots:</td><td>M.2 2280 M-key (PCIe 3.0 x4, SATA 3.0)</td></tr><tr><td>Drive bays:</td><td>3.5-inch/(2x)2.5-inch; 5.25-inch (slim);</td></tr><tr><td>Hard Drive:</td><td>max 2TB; RAID 0 &amp; 1;</td></tr><tr><td>PSU:</td><td>180 W</td></tr><tr><td>Weight:</td><td>6.00 kg (13.22 lb)</td></tr></tbody></table><ul><li>从 <a href="https://www.hardware-corner.net/guides/difference-optiplex-3040-vs-5040-vs-7040/" target="_blank" rel="noopener">The difference between Dell OptiPlex 3040 vs. 5040 vs. 7040</a> 偷来的一张图片👇</li></ul><p><img src="https://p.k8s.li/OptiPlex_5040SFF_motherboard.jpg" alt=""></p><h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>两条 8GB DDR4 内从从我台式机上拆下来的，又花了 300 块钱买了个镁光的 16GB DDR4 装了上去，迫于 我的台式机 B350M-K 的缩水板只有两个内存插槽而且支持到 32GB，暂时装一个 16GB 的吧，能以后再装一个上去。</p><h3 id="固态"><a href="#固态" class="headerlink" title="固态"></a>固态</h3><p>其实本来的预算三星 970PRO 512GB没打算买，是我在找 Dell OptiPlex 7040 时意外碰到的一个老哥，而且这块固态是德亚的，还算靠谱一些，于是剁手买了这个块固态。970PRO 系列的都是 MLC 的颗粒的固态硬盘，通 SM961 一样是属于传家宝系列😂，但是 SM961 淘宝上水太深，清零盘占据多数，所以不建议买。</p><p>正好把这块 970PRO 换到我的台式机上，把台式机上的 SN750 512GB 换到 HomeLab 机器上，给 ESXi 上的虚拟机用。在玩儿虚拟化的时候深有感触，宿主机的磁盘是机械硬盘的话，上面的虚拟机达到一定数量时，虚拟机会很卡，所以玩 ESXi 虚拟化，有块固态的体验是非常爽滴😋。</p><h2 id="装机"><a href="#装机" class="headerlink" title="装机"></a>装机</h2><p>其实装机很快，由于是买的 Dell OptiPlex 7040 准系统，所以只需要把 CPU 、内存、硬盘装上去就完事儿了。</p><p>收到准系统后发现没有带 M.2 螺丝，只能临时拿胶带粘糊上去，勉强撑了两天，后来买了个螺丝和散热片完美地解决了。</p><p><img src="https://p.k8s.li/HomeLab-5.jpg" alt=""></p><p>从以前旧笔记本淘汰下来的 2TB 5400RPM 的石头盘，已经出现坏道了，临时当个下载盘吧，在它还没彻底崩盘之前再压榨一下它吧😂。后面打算再添加一块12TB的氦气盘当仓库盘和备份数据使用，有了 UPS 和这台主机 7*24 小时开机也没啥问题了。</p><p><img src="https://p.k8s.li/HomeLab-3.jpg" alt=""></p><p>后面那台是我的台式机，也是去年这时候买的，两者比较起来 SFF 的型号确实小很多。Dell 的这种主机还有一种 MFF 型号的，那种更小一些，差不多比路由器大一些而已，不过扩展性不好，而且还需要外置电源，也就没考虑，不过现在想想有点后悔了，当初应该多加点钱买 SFF 的，不过还好也能接受，只不过体积大了些，搬家的时候不太方便。</p><p><img src="https://p.k8s.li/HomeLab-4.jpg" alt=""></p><h2 id="ESXi"><a href="#ESXi" class="headerlink" title="ESXi"></a>ESXi</h2><p>装完机器之后就开始装 ESXi ，对于虚拟化，ESXi 算是比较熟悉的了，听说 Proxmox VE 也不错🤔，等到后面硬盘到了再折腾一下 Proxmox VE。看到隔壁 <a href="https://wzyboy.im/post/1293.html" target="_blank" rel="noopener">Proxmox VE：优秀的自建虚拟化方案</a> 愈发想玩玩了。</p><blockquote><p>  贯彻「不重复造轮子」的原则，当前版本的 PVE 基于成熟稳定的 Debian 9 “Stretch” 构建。在熟悉和使用 PVE 的过程中，我越发喜欢它「不重复造轮子」的特性。相较之前用过的其他虚拟化方案，PVE 的内部构造和工作原理对我来说不再是一个黑盒，我可以清晰地观测到它在干什么——比如要迁移一台虚拟机到另一个节点，我就可以通过 <code>ps</code> 观察到它启动了一个 <code>dd</code> 进程，对接 <code>ssh</code> 管道，将磁盘数据通过网络复制到目标机器——这种仿佛透明手表一样能看到内部工作原理的感觉真是太棒了！</p></blockquote><p>从 VMware 家下载好 <code>VMware-VMvisor-Installer-7.0.0-15843807.x86_64.iso</code> 镜像，找了两个 U 盘，一个用于 ESXi 的安装盘，一个用于 ESXi 的系统盘，其中一个 U 盘还是我用读卡器+16GB内存卡拼凑而成的，目的是为了把 ESXi 装到 U 盘里方便迁移数据之类的，之后在网上找一个神 KEY 激活一下（🤫小声</p><p><img src="https://p.k8s.li/HomeLab-6.jpg" alt=""></p><h3 id="Ubuntu-20-04"><a href="#Ubuntu-20-04" class="headerlink" title="Ubuntu 20.04"></a>Ubuntu 20.04</h3><p>当作网关机使用，和我所有的 云主机打通网络，使用 WireGuard 组成一个小内网，关于 WireGuard 的使用建议阅读大佬写得博客 <a href="https://fuckcloudnative.io/posts/wireguard-docs-practice/" target="_blank" rel="noopener">WireGuard 教程：WireGuard 的搭建使用与配置详解</a> 以及 <a href="https://fuckcloudnative.io/posts/wireguard-docs-theory/" target="_blank" rel="noopener">WireGuard 教程：WireGuard 的工作原理</a>。</p><p>顺带用 <a href="https://github.com/Aniverse/ZBench" target="_blank" rel="noopener">ZBench</a> 测了一下虚拟机的磁盘性能，还算勉强说的过去，实际上 SN750 512GB 只有 2GB 左右的缓存，写满换粗之后，写入的性能会直线下降到 800MB/s，读的性能倒是可以达到 3200MB/s 以上，或许是主板的限制，没能达到理想的读写性能。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">--------------------------------------------------------------------------</span><br><span class="line">CPU model            : Intel(R) Core(TM) i5-6600T CPU @ 2.70GHz</span><br><span class="line">Number of cores      : 4</span><br><span class="line">CPU frequency        : 2712.000 MHz</span><br><span class="line">Total size of Disk   : 33.3 GB (7.7 GB Used)</span><br><span class="line">Total amount of Mem  : 3935 MB (306 MB Used)</span><br><span class="line">Total amount of Swap : 3934 MB (0 MB Used)</span><br><span class="line">System uptime        : 4 days, 19 hour 47 min</span><br><span class="line">Load average         : 0.13, 0.08, 0.03</span><br><span class="line">OS                   : Ubuntu 20.04 LTS</span><br><span class="line">Arch                 : x86_64 (64 Bit)</span><br><span class="line">Kernel               : 5.4.0-42-generic</span><br><span class="line">Virt                 : vmware</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">I/O speed(1st run)   :1.3 GB/s</span><br><span class="line">I/O speed(2nd run)   :1.3 GB/s</span><br><span class="line">I/O speed(3rd run)   :1.3 GB/s</span><br></pre></td></tr></table></figure><h3 id="PhotonOS"><a href="#PhotonOS" class="headerlink" title="PhotonOS"></a>PhotonOS</h3><p>这个是系统在我另一篇博客 <a href="https://blog.k8s.li/container-linux-os.html">Container Linux OS 从入坑到爬出来</a> 里提到过，Photon OS™ 是针对 VMware vSphere® 虚拟化平台进行内核优化的容器专用操作系统，就和 CoreOS 一样。十分适合专门用来运行容器，当作 Kubernetes 集群中的工作负载来使用。</p><ul><li>系统初始化启动之后内存仅仅使用了 45Mi</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          2.0Gi        45Mi       1.8Gi       0.0Ki        93Mi       1.8Gi</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure><ul><li>启动 docker 进程之后的占用情况，也仅仅 109Mi</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          2.0Gi       109Mi       1.6Gi       0.0Ki       238Mi       1.8Gi</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure><ul><li>使用 OVA 虚拟机模板启动后的虚拟机，磁盘仅仅占用了 515MB ，确实是相当轻量化，这还是包含了 docker。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/root        16G  515M   15G   4% /</span><br><span class="line">devtmpfs        998M     0  998M   0% /dev</span><br><span class="line">tmpfs          1000M     0 1000M   0% /dev/shm</span><br><span class="line">tmpfs          1000M  532K  999M   1% /run</span><br><span class="line">tmpfs          1000M     0 1000M   0% /sys/fs/cgroup</span><br><span class="line">tmpfs          1000M     0 1000M   0% /tmp</span><br><span class="line">/dev/sda2        10M  2.2M  7.9M  22% /boot/efi</span><br><span class="line">tmpfs           200M     0  200M   0% /run/user/0</span><br></pre></td></tr></table></figure><p>总之，PhotonOS 是个很轻量的 OS ，适合专门用来运行一些容器化的服务，这正好符合我的需求。别问我为什么不用 CoreOS ，CoreOS 已经凉了。</p><h3 id="Alpine-NFS"><a href="#Alpine-NFS" class="headerlink" title="Alpine NFS"></a>Alpine NFS</h3><p>把我一块磁盘直通给这个虚拟机，主要用来给 k8s 集群中的 Pod 挂载 PVC 持久化存储使用。</p><h3 id="Debian"><a href="#Debian" class="headerlink" title="Debian"></a>Debian</h3><p>主要是用来运行 K8s 集群，目前只有一个  master 和一个 node 玩玩儿，跑了一些自用的服务。</p><h3 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h3><p>当下载机使用，外加运行一些不得不使用的国产毒瘤软件😡</p><h2 id="额外硬件"><a href="#额外硬件" class="headerlink" title="额外硬件"></a>额外硬件</h2><p>捡垃圾的乐趣就在于越折腾越好玩，于是又开始打算折腾一些</p><h3 id="UPS"><a href="#UPS" class="headerlink" title="UPS"></a>UPS</h3><p>由于最近房东家里经常断电，有时一天断电八九次，每次断电我都担心着硬盘里的老婆们会不会挂掉，索性还是买了 UPS ，在马云家看了看，带给 NAS 自动断电的 UPS 普遍在 400块钱以上，而且我这个还是个假的 NAS ，UPS 上的 USB 口不一定支持我的主机。最后为了节省一下预算花儿 160 块钱买了个不支持 USB 的 UPS ，但是又不能没有这个功能，因为家里的 220V 市电断电之后，UPS 的电量只能给主机续命 10~20min 左右，UPS 的电量用完之后就嗝屁了，照阳还是断电。所以在 UPS 用尽电量还是没有来电之前，一定要想办法把主机通过 poweroff 的方式安全优雅滴关机。</p><p>首先要考虑的是怎么知道 220V 市电断电了，起初想有没有个 220V 的传感器，我去，有点难度还是算了吧。最后一想，可以通过 ping 房东家光猫的方式。我的路由器和主机等设备连接 UPS ，房东家的光猫并没有连接 UPS ，我在路由器上设置一个定时任务，每分钟去 ping 房东家的光猫，没有 ping 通说明就是断电了，也有可能是网线被拔掉了，但概率很小。<code>! ping -c 8 A &amp;&amp; ssh B &quot;poweroff&quot;</code> 一行简单的命令就满足了我的需求，</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line">echo "start" &gt;&gt; /tmp/power_status</span><br><span class="line">if ! ping -c 32 192.168.1.1</span><br><span class="line">then</span><br><span class="line">    sleep 300</span><br><span class="line">    ping -c 32 192.168.1.1 &amp;&amp; exit 0</span><br><span class="line">    sshpass -p "pwd" ssh root@192.168.0.210 "net rpc shutdown -I 192.168.0.240 -U admin%poweroff"</span><br><span class="line">    sshpass -p "pwd" ssh root@192.168.0.200 "sh -c /suspend_vm.sh"</span><br><span class="line">    echo "220v poweroff" &gt;&gt; /tmp/power_status</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>对于 ESXi 上的虚拟机，还是采用了挂起的方式，将虚拟机的内存状态保存在数据存储的磁盘里，这样重新开启虚拟机后就能恢复到之前的状态，这一点有点像 Windows 的休眠。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line">for vm in $(/sbin/vmdumper -l | grep -v Alpine |  awk '&#123;print $1&#125;' | sed 's/wid=//g')</span><br><span class="line">do</span><br><span class="line">     /sbin/vmdumper $&#123;vm&#125; suspend_vm</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="网管交换机"><a href="#网管交换机" class="headerlink" title="网管交换机"></a>网管交换机</h3><p>当我从台式机向 ESXI 里的虚拟机传输文件的时候，发现网络速度最快只能达到 700Mbits/sec ，看来应该是路由器的性能瓶颈，于是想着升级一下网络设备，把 R6300V2 路由器当作 AP 来用，将流量都汇聚到网管交换机上。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[  4] local 192.168.0.240 port 50718 connected to 192.168.0.123 port 5201</span><br><span class="line">[ ID] Interval           Transfer     Bandwidth</span><br><span class="line">[  4]   0.00-1.00   sec  83.8 MBytes   702 Mbits/sec</span><br><span class="line">[  4]   1.00-2.00   sec  83.4 MBytes   700 Mbits/sec</span><br><span class="line">[  4]   2.00-3.00   sec  83.6 MBytes   701 Mbits/sec</span><br><span class="line">[  4]   3.00-4.00   sec  82.9 MBytes   695 Mbits/sec</span><br><span class="line">[  4]   4.00-5.00   sec  83.8 MBytes   702 Mbits/sec</span><br><span class="line">[  4]   5.00-6.00   sec  83.6 MBytes   701 Mbits/sec</span><br><span class="line">[  4]   6.00-7.00   sec  83.5 MBytes   701 Mbits/sec</span><br><span class="line">[  4]   7.00-8.00   sec  83.8 MBytes   703 Mbits/sec</span><br><span class="line">[  4]   8.00-9.00   sec  83.8 MBytes   702 Mbits/sec</span><br><span class="line">[  4]   9.00-10.00  sec  83.8 MBytes   702 Mbits/sec</span><br><span class="line">[  4]  10.00-11.00  sec  83.8 MBytes   703 Mbits/sec</span><br><span class="line">[  4]  11.00-12.00  sec  83.8 MBytes   703 Mbits/sec</span><br><span class="line">[  4]  12.00-13.00  sec  83.9 MBytes   703 Mbits/sec</span><br><span class="line">[  4]  13.00-14.00  sec  83.8 MBytes   703 Mbits/sec</span><br><span class="line">[  4]  14.00-15.00  sec  83.8 MBytes   703 Mbits/sec</span><br><span class="line">[  4]  15.00-16.00  sec  83.9 MBytes   704 Mbits/sec</span><br><span class="line">[  4]  16.00-17.00  sec  83.4 MBytes   699 Mbits/sec</span><br><span class="line">[  4]  17.00-18.00  sec  83.9 MBytes   703 Mbits/sec</span><br><span class="line">[  4]  18.00-19.00  sec  83.6 MBytes   702 Mbits/sec</span><br><span class="line">[  4]  19.00-20.00  sec  83.8 MBytes   702 Mbits/sec</span><br><span class="line">[  4]  20.00-21.00  sec  83.9 MBytes   704 Mbits/sec</span><br><span class="line">[  4]  21.00-22.00  sec  83.8 MBytes   703 Mbits/sec</span><br><span class="line">[  4]  22.00-23.00  sec  83.9 MBytes   704 Mbits/sec</span><br><span class="line">[  4]  23.00-24.00  sec  83.9 MBytes   703 Mbits/sec</span><br><span class="line">[  4]  24.00-25.00  sec  83.9 MBytes   703 Mbits/sec</span><br><span class="line">[  4]  25.00-25.20  sec  16.6 MBytes   698 Mbits/sec</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">╭─debian@debian ~</span><br><span class="line">╰─$ qperf 192.168.0.123 -t 30 -vvu tcp_lat udp_lat tcp_bw udp_bw conf</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  98.7 us</span><br><span class="line">    msg_size  =     1 bytes</span><br><span class="line">    time      =    30 sec</span><br><span class="line">    timeout   =     5 sec</span><br><span class="line">udp_lat:</span><br><span class="line">    latency   =  98 us</span><br><span class="line">    msg_size  =   1 bytes</span><br><span class="line">    time      =  30 sec</span><br><span class="line">    timeout   =   5 sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  87.9 MB/sec</span><br><span class="line">    msg_size  =    64 KiB (65,536)</span><br><span class="line">    time      =    30 sec</span><br><span class="line">    timeout   =     5 sec</span><br><span class="line">udp_bw:</span><br><span class="line">    send_bw   =  56.7 MB/sec</span><br><span class="line">    recv_bw   =  56.7 MB/sec</span><br><span class="line">    msg_size  =    32 KiB (32,768)</span><br><span class="line">    time      =    30 sec</span><br><span class="line">    timeout   =     5 sec</span><br><span class="line">conf:</span><br><span class="line">    loc_node   =  debian</span><br><span class="line">    loc_cpu    =  16 Cores: AMD Ryzen 7 1700 Eight-Core   3.0GHz</span><br><span class="line">    loc_os     =  Linux 4.4.0-18362</span><br><span class="line">    loc_qperf  =  0.4.11</span><br><span class="line">    rem_node   =  gateway</span><br><span class="line">    rem_cpu    =  4 Cores: Intel Core i5-6600T @ 2.70GHz</span><br><span class="line">    rem_os     =  Linux 5.4.0-42-generic</span><br><span class="line">    rem_qperf  =  0.4.11</span><br></pre></td></tr></table></figure><p>准备买 GS108E V2 或者 GS105E V2，</p><h3 id="四网口网卡"><a href="#四网口网卡" class="headerlink" title="四网口网卡"></a>四网口网卡</h3><p>为了折腾一下网卡直通、端口汇聚、overlay 网络卸载等特性，后面还要添加一块 <a href="https://www.intel.cn/content/www/cn/zh/products/docs/network-io/ethernet/10-25-40-gigabit-adapters/ethernet-i350-server-adapter-brief.html" target="_blank" rel="noopener">intel I350 T4 V2</a> ，闲鱼上的价格也不是很贵。</p><p><img src="https://p.k8s.li/20200822195450798.png" alt=""></p><h3 id="阵列卡"><a href="#阵列卡" class="headerlink" title="阵列卡"></a>阵列卡</h3><p>由于主板的 SATA 接口最大只支持到 2TB ，为了扩展一下存储，只能额外添加一块阵列卡了，由于主板的 PCIe 有限，而且这么大点的机箱最多也就能塞下 1 块 3.5 寸硬盘和 3 块 2.5 寸硬盘，所以找一块入门级的阵列卡就够了，最终花了 50 块钱捡了一块 <a href="https://lenovopress.com/tips0831-serveraid-h1110" target="_blank" rel="noopener">ServeRAID H1110 SAS/SATA Controller</a> 阵列卡，看来一下手册里的参数，大概也能暂时满足我的需求。</p><blockquote><ul><li>Four internal 6 Gbps SAS/SATA ports</li><li>One x4 mini-SAS internal connector (SFF-8087)</li><li>6 Gbps throughput per port</li><li>Based on LSI SAS2004 6 Gbps RAID on Chip (ROC) controller</li><li>x4 PCI Express 2.0 host interface</li><li>Supports RAID 0, 1, 1E, and 10</li><li>Connects to up to four SAS or SATA drives</li><li>SAS and SATA drives are supported, but the mixing of SAS and SATA in the same integrated volume is not supported</li><li>Supports simple-swap SATA and hot-swap SAS and SATA drives</li><li>Supports up to two integrated volumes</li><li>Supports up to two global hot-spare drives</li><li>Supports drive sizes greater than 2 TB for RAID 0, 1E, and 10 (not RAID 1)</li><li>Fixed stripe size of 64 KB</li><li>Compliant with Disk Data Format (DDF)</li><li>S.M.A.R.T. support</li></ul></blockquote><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>懒得写了</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;捡垃圾&quot;&gt;&lt;a href=&quot;#捡垃圾&quot;
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://blog.k8s.li/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="捡垃圾" scheme="https://blog.k8s.li/tags/%E6%8D%A1%E5%9E%83%E5%9C%BE/"/>
    
      <category term="NAS" scheme="https://blog.k8s.li/tags/NAS/"/>
    
  </entry>
  
</feed>
